{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWQC8iCE2_-o"
      },
      "source": [
        "\n",
        "\n",
        "# **Final Submission**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYdEI31whyE-"
      },
      "source": [
        "For the capstone project I choose to compare the actual models using some of transfer learning using the VGG16 and Resnet to compare with an aritificial neural network implemented from scratch as the dataset selected for this task is small.\n",
        "Morover as it can see in the project notebook, one of the transfer learning model, the resnet, did not perform so well with scores less than 0.50, as VGG16 did not too, eventhought the resnet model implementation was adapted to the data input that we have to see if the resnet can converge and show some valid performance at least but it did not.\n",
        "On the other hand our ANN model , the model3 we keep training and modifying to increase its performance it performs better and using the Bayessian Optimization to tune the learning rate hyperparameter, we could great a far better metrics as an accuracy greater than 0.95\n",
        "And finally we compare the 3 models in this notebook to choose the best performance one that it was the ANN.\n",
        "**Note:** We will mount our drive and import our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDM89XHyCxrA"
      },
      "source": [
        "## **Mounting the Drive**\n",
        "\n",
        "**NOTE:**  **We use colab pro for speed up the training of the models and compare the performance evaluation.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi  #identifying the GPU available in Colab\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTDvoCCRutoW",
        "outputId": "e2846c0a-b3cd-4e63-b8e5-a235d012f861"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 31 04:45:46 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xHeStTSuqmf",
        "outputId": "b55605cc-a2d6-47e8-9cd9-c7db3521e49d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JQi_degJC3dm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76086d1a-4a38-47be-8f6f-779a09387efa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UC8-yLUUCcWh"
      },
      "source": [
        "## **Importing the Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "30fd2144"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "#if device_name != '/device:GPU:0':\n",
        "#  print(\n",
        "#      '\\n\\nThis error most likely means that this notebook is not '\n",
        "#      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "#      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "#  raise SystemError('GPU device not found')\n",
        "\n",
        "\n",
        "# Importing Deep Learning Libraries\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D, LeakyReLU\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCqJk2XpCnJi"
      },
      "source": [
        "### **Let us load the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sMfr4tK04C0o"
      },
      "outputs": [],
      "source": [
        "# Storing the path of the data file from the Google drive\n",
        "path = '/content/drive/MyDrive/Facial_emotion_images.zip'\n",
        "\n",
        "# The data is provided as a zip file so we need to extract the files from the zip file\n",
        "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4e89d1c7"
      },
      "outputs": [],
      "source": [
        "picture_size = 48\n",
        "folder_path = \"Facial_emotion_images/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boQi7epI3Lsu"
      },
      "source": [
        "## **Transfer Learning Architecture**\n",
        "\n",
        "In this section, we will use the Learning architecture that worked the best performance between the other as resnet and VGG16 to see how they perform. For the pre-trained models, it was selected these 2 as they are good for visual imaging but only vgg16 could deliver some stable result but not enough."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7NKTPgdEsgt"
      },
      "source": [
        "### **Creating our Data Loaders for Transfer Learning Architectures**\n",
        "\n",
        "In this section, we are creating data loaders that we will use as inputs to our Neural Network. We will use DataImageGenerator from Keras, we will have to go with color_mode = 'rgb' as this is the required format for the transfer learning architectures and we modify the batch_size and the img_size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d97fee2d",
        "outputId": "b45766ff-ff9d-4e56-f530-7f608215018d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15109 images belonging to 4 classes.\n",
            "Found 4977 images belonging to 4 classes.\n",
            "Found 128 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "batch_size  = 48\n",
        "img_size = 48\n",
        "\n",
        "datagen_train = ImageDataGenerator(horizontal_flip = True,\n",
        "                                    brightness_range = (0., 2.),\n",
        "                                    rescale = 1./255,\n",
        "                                    shear_range = 0.3)\n",
        "\n",
        "train_set = datagen_train.flow_from_directory(folder_path + \"train\",\n",
        "                                              target_size = (img_size, img_size),\n",
        "                                              color_mode = 'rgb',\n",
        "                                              batch_size = batch_size,\n",
        "                                              class_mode = 'categorical',\n",
        "                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n",
        "                                              shuffle = True)\n",
        "\n",
        "##datagen_validation = # Write your code here\n",
        "\n",
        "datagen_validation = ImageDataGenerator(horizontal_flip = True,\n",
        "                                    brightness_range=(0.,2.),\n",
        "                                    rescale=1./255,\n",
        "                                    shear_range=0.3)  # Write your code here\n",
        "\n",
        "#validation_set = # Write your code here\n",
        "\n",
        "validation_set = datagen_validation.flow_from_directory(folder_path + \"validation\",\n",
        "                                              target_size = (img_size, img_size),\n",
        "                                              color_mode = 'rgb', # Provide your chosen color_mode here ,\n",
        "                                              batch_size = batch_size,\n",
        "                                              class_mode = 'categorical',\n",
        "                                              shuffle = True)  # Write your code here\n",
        "\n",
        "\n",
        "##datagen_test = # Write your code here\n",
        "\n",
        "datagen_test = ImageDataGenerator(horizontal_flip = True,\n",
        "                                    brightness_range=(0.,2.),\n",
        "                                    rescale=1./255,\n",
        "                                    shear_range=0.3) # Write your code here\n",
        "\n",
        "##test_set = # Write your code here\n",
        "\n",
        "test_set = datagen_test.flow_from_directory(folder_path + \"test\",\n",
        "                                              target_size = (img_size, img_size),\n",
        "                                              color_mode = 'rgb', # Provide your chosen color_mode here ,\n",
        "                                              batch_size = batch_size,\n",
        "                                              class_mode = 'categorical',\n",
        "                                              shuffle = True) # Write your code here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaUYQdkf7pDG"
      },
      "source": [
        "## **VGG16 and Resnet Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThCSNrWC4HW0"
      },
      "source": [
        "### **Importing the VGG16 Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c83c83e",
        "outputId": "a9b05757-ee2a-41d5-ea61-dadaf3b27fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "######################################################\n",
        "\n",
        "# Clearing backend\n",
        "\n",
        "from tensorflow.keras import backend\n",
        "\n",
        "backend.clear_session()\n",
        "# Fixing the seed for random number generators\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#######################################################\n",
        "\n",
        "vgg = VGG16(include_top = False, weights = 'imagenet', input_shape = (48, 48, 3))\n",
        "vgg.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X76HMyZX4edM"
      },
      "source": [
        "### **Model Building**\n",
        "\n",
        "* In this model, we will import till the **'block5_pool'** layer of the VGG16 model. We can scroll down in the model summary and look for 'block5_pool'. We will choose any other layer as well.\n",
        "* Then we will add a Flatten layer, which receives the output of the 'block5_pool' layer as its input.\n",
        "* We will add a few Dense layers and use 'relu' activation function on them.\n",
        "* You may use Dropout and BatchNormalization layers as well.\n",
        "* Then we will add our last dense layer, which must have 4 neurons and a 'softmax' activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b123bc6",
        "outputId": "36762385-8530-43e3-b758-3fbe33ec84b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,848,068\n",
            "Trainable params: 132,868\n",
            "Non-trainable params: 14,715,200\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "transfer_layer = vgg.get_layer('block5_pool')\n",
        "vgg.trainable = False\n",
        "\n",
        "# Add classification layers on top of it\n",
        "#____________\n",
        "\n",
        "# Flattenning the output from the 3rd block of the VGG16 model\n",
        "x = Flatten()(transfer_layer.output)\n",
        "\n",
        "# Adding a Dense layer with 256 neurons\n",
        "x = Dense(256, activation = 'relu')(x)\n",
        "\n",
        "\n",
        "# Add a DropOut layer with Drop out ratio of 0.3\n",
        "#____________\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "\n",
        "\n",
        "# Add a Batch Normalization layer\n",
        "#____________\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Adding the final dense layer with 4 neurons and use 'softmax' activation\n",
        "pred = Dense(4, activation='softmax')(x)\n",
        "\n",
        "vggmodel = Model(vgg.input, pred) # Initializing the model\n",
        "\n",
        "vggmodel.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6vK7u7w8GsM"
      },
      "source": [
        "### **Compiling and Training the VGG16 Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86b249f1"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"./vggmodel.h5\", monitor = 'val_loss', verbose = 1, save_best_only = True, mode = 'max')\n",
        "\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss',\n",
        "                          min_delta = 0,\n",
        "                          patience = 3,\n",
        "                          verbose = 1,\n",
        "                          restore_best_weights = True\n",
        "                          )\n",
        "\n",
        "reduce_learningrate = ReduceLROnPlateau(monitor = 'val_loss',\n",
        "                              factor = 0.2,\n",
        "                              patience = 3,\n",
        "                              verbose = 1,\n",
        "                              min_delta = 0.000001)\n",
        "\n",
        "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n",
        "\n",
        "epochs = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** **For training different learning rates were selected to compare the performance, we tried with 0.005, 0.0002, 0.0008 and 0.00075**"
      ],
      "metadata": {
        "id": "FfgcBmuDYubI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PN6ghMOGGgf"
      },
      "outputs": [],
      "source": [
        "# Writing code to compile the vggmodel. Using categorical crossentropy as the loss function, Adam Optimizer with 0.001 learning rate, and set metrics to 'accuracy'.\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.00075)\n",
        "vggmodel.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "backend.clear_session()"
      ],
      "metadata": {
        "id": "Egf29K6Zdn2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "893285ee",
        "outputId": "e2ad8311-a20f-4db7-d301-7338351ece5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "50/50 [==============================] - 7s 126ms/step - loss: 1.0653 - accuracy: 0.5362 - val_loss: 1.2920 - val_accuracy: 0.4125\n",
            "Epoch 2/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0484 - accuracy: 0.5496 - val_loss: 1.3213 - val_accuracy: 0.3875\n",
            "Epoch 3/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0718 - accuracy: 0.5392 - val_loss: 1.2618 - val_accuracy: 0.4179\n",
            "Epoch 4/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0810 - accuracy: 0.5308 - val_loss: 1.2820 - val_accuracy: 0.4092\n",
            "Epoch 5/200\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 1.0684 - accuracy: 0.5317 - val_loss: 1.2630 - val_accuracy: 0.4142\n",
            "Epoch 6/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0769 - accuracy: 0.5367 - val_loss: 1.2534 - val_accuracy: 0.4162\n",
            "Epoch 7/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0706 - accuracy: 0.5263 - val_loss: 1.2797 - val_accuracy: 0.4075\n",
            "Epoch 8/200\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0662 - accuracy: 0.5342 - val_loss: 1.2630 - val_accuracy: 0.4083\n",
            "Epoch 9/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0704 - accuracy: 0.5213 - val_loss: 1.2799 - val_accuracy: 0.4075\n",
            "Epoch 10/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0578 - accuracy: 0.5396 - val_loss: 1.2779 - val_accuracy: 0.4187\n",
            "Epoch 11/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0806 - accuracy: 0.5242 - val_loss: 1.2809 - val_accuracy: 0.4208\n",
            "Epoch 12/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0486 - accuracy: 0.5475 - val_loss: 1.2685 - val_accuracy: 0.4154\n",
            "Epoch 13/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0483 - accuracy: 0.5633 - val_loss: 1.2742 - val_accuracy: 0.4117\n",
            "Epoch 14/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0450 - accuracy: 0.5329 - val_loss: 1.2598 - val_accuracy: 0.4246\n",
            "Epoch 15/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0511 - accuracy: 0.5300 - val_loss: 1.2667 - val_accuracy: 0.4096\n",
            "Epoch 16/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0486 - accuracy: 0.5396 - val_loss: 1.2401 - val_accuracy: 0.4375\n",
            "Epoch 17/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0473 - accuracy: 0.5283 - val_loss: 1.2775 - val_accuracy: 0.4242\n",
            "Epoch 18/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.1018 - accuracy: 0.5270 - val_loss: 1.2932 - val_accuracy: 0.4021\n",
            "Epoch 19/200\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 1.0635 - accuracy: 0.5292 - val_loss: 1.2750 - val_accuracy: 0.4046\n",
            "Epoch 20/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0432 - accuracy: 0.5546 - val_loss: 1.2682 - val_accuracy: 0.4158\n",
            "Epoch 21/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0483 - accuracy: 0.5517 - val_loss: 1.2783 - val_accuracy: 0.4183\n",
            "Epoch 22/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0621 - accuracy: 0.5270 - val_loss: 1.2721 - val_accuracy: 0.4238\n",
            "Epoch 23/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0758 - accuracy: 0.5304 - val_loss: 1.2937 - val_accuracy: 0.4029\n",
            "Epoch 24/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0677 - accuracy: 0.5321 - val_loss: 1.2987 - val_accuracy: 0.3921\n",
            "Epoch 25/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0483 - accuracy: 0.5375 - val_loss: 1.3150 - val_accuracy: 0.3733\n",
            "Epoch 26/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0774 - accuracy: 0.5229 - val_loss: 1.2589 - val_accuracy: 0.4129\n",
            "Epoch 27/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0724 - accuracy: 0.5263 - val_loss: 1.2536 - val_accuracy: 0.4254\n",
            "Epoch 28/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0551 - accuracy: 0.5350 - val_loss: 1.3078 - val_accuracy: 0.4112\n",
            "Epoch 29/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0848 - accuracy: 0.5067 - val_loss: 1.2587 - val_accuracy: 0.4308\n",
            "Epoch 30/200\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0739 - accuracy: 0.5317 - val_loss: 1.2514 - val_accuracy: 0.4192\n",
            "Epoch 31/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0424 - accuracy: 0.5358 - val_loss: 1.2829 - val_accuracy: 0.4087\n",
            "Epoch 32/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0546 - accuracy: 0.5483 - val_loss: 1.2759 - val_accuracy: 0.4308\n",
            "Epoch 33/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0352 - accuracy: 0.5517 - val_loss: 1.2604 - val_accuracy: 0.4208\n",
            "Epoch 34/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0728 - accuracy: 0.5233 - val_loss: 1.2792 - val_accuracy: 0.3963\n",
            "Epoch 35/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0706 - accuracy: 0.5358 - val_loss: 1.2736 - val_accuracy: 0.4079\n",
            "Epoch 36/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0508 - accuracy: 0.5408 - val_loss: 1.3218 - val_accuracy: 0.3783\n",
            "Epoch 37/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0345 - accuracy: 0.5392 - val_loss: 1.3008 - val_accuracy: 0.3967\n",
            "Epoch 38/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0379 - accuracy: 0.5487 - val_loss: 1.2855 - val_accuracy: 0.4096\n",
            "Epoch 39/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0799 - accuracy: 0.5158 - val_loss: 1.2687 - val_accuracy: 0.4129\n",
            "Epoch 40/200\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0415 - accuracy: 0.5483 - val_loss: 1.2480 - val_accuracy: 0.4229\n",
            "Epoch 41/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0635 - accuracy: 0.5308 - val_loss: 1.2407 - val_accuracy: 0.4271\n",
            "Epoch 42/200\n",
            "50/50 [==============================] - 6s 121ms/step - loss: 1.0397 - accuracy: 0.5525 - val_loss: 1.2514 - val_accuracy: 0.4338\n",
            "Epoch 43/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0242 - accuracy: 0.5617 - val_loss: 1.2877 - val_accuracy: 0.4154\n",
            "Epoch 44/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0713 - accuracy: 0.5254 - val_loss: 1.3228 - val_accuracy: 0.3658\n",
            "Epoch 45/200\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0576 - accuracy: 0.5329 - val_loss: 1.3162 - val_accuracy: 0.4000\n",
            "Epoch 46/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0522 - accuracy: 0.5333 - val_loss: 1.2573 - val_accuracy: 0.4246\n",
            "Epoch 47/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0397 - accuracy: 0.5496 - val_loss: 1.3273 - val_accuracy: 0.3917\n",
            "Epoch 48/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0653 - accuracy: 0.5296 - val_loss: 1.2754 - val_accuracy: 0.4229\n",
            "Epoch 49/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0777 - accuracy: 0.5153 - val_loss: 1.2690 - val_accuracy: 0.4167\n",
            "Epoch 50/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0657 - accuracy: 0.5254 - val_loss: 1.2498 - val_accuracy: 0.4125\n",
            "Epoch 51/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0311 - accuracy: 0.5450 - val_loss: 1.2602 - val_accuracy: 0.4029\n",
            "Epoch 52/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0490 - accuracy: 0.5442 - val_loss: 1.2693 - val_accuracy: 0.4146\n",
            "Epoch 53/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0350 - accuracy: 0.5442 - val_loss: 1.2998 - val_accuracy: 0.4162\n",
            "Epoch 54/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0466 - accuracy: 0.5425 - val_loss: 1.2896 - val_accuracy: 0.4058\n",
            "Epoch 55/200\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0635 - accuracy: 0.5492 - val_loss: 1.2983 - val_accuracy: 0.4108\n",
            "Epoch 56/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0502 - accuracy: 0.5512 - val_loss: 1.2790 - val_accuracy: 0.4167\n",
            "Epoch 57/200\n",
            "50/50 [==============================] - 6s 118ms/step - loss: 1.0497 - accuracy: 0.5446 - val_loss: 1.2351 - val_accuracy: 0.4283\n",
            "Epoch 58/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0577 - accuracy: 0.5421 - val_loss: 1.2471 - val_accuracy: 0.4308\n",
            "Epoch 59/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0622 - accuracy: 0.5312 - val_loss: 1.2867 - val_accuracy: 0.4233\n",
            "Epoch 60/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0543 - accuracy: 0.5537 - val_loss: 1.3140 - val_accuracy: 0.4304\n",
            "Epoch 61/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0398 - accuracy: 0.5467 - val_loss: 1.2731 - val_accuracy: 0.4179\n",
            "Epoch 62/200\n",
            "50/50 [==============================] - 6s 119ms/step - loss: 1.0408 - accuracy: 0.5500 - val_loss: 1.2989 - val_accuracy: 0.4079\n",
            "Epoch 63/200\n",
            "50/50 [==============================] - 6s 120ms/step - loss: 1.0576 - accuracy: 0.5317 - val_loss: 1.2974 - val_accuracy: 0.3938\n",
            "Epoch 64/200\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0451 - accuracy: 0.5454"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-dcbcfd34f2e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history_vgg_model =  vggmodel.fit(train_set,\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1443\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1446\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1756\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1757\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1758\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "history_vgg_model =  vggmodel.fit(train_set,\n",
        "        steps_per_epoch=50,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_set,\n",
        "        validation_steps=50\n",
        "        )# Writing code to fit your model. Use train_set as the training data and validation_set as the validation data. Train the model for 200 epochs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un-19jPckK07"
      },
      "source": [
        "### **Evaluating the VGG16 model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "t6Y_bSLCkcvr",
        "outputId": "16260a1a-7870-473d-c4df-c41236ac40bd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Code to evaluate model performance on the test set\n",
        "# Plotting the accuracies\n",
        "\n",
        "dict_hist = history_vgg_model.history\n",
        "\n",
        "list_ep = [i for i in range(1, 201)]\n",
        "\n",
        "plt.figure(figsize = (8, 8))\n",
        "\n",
        "plt.plot(list_ep, dict_hist['accuracy'], ls = '--', label = 'accuracy')\n",
        "\n",
        "plt.plot(list_ep, dict_hist['val_accuracy'], ls = '--', label = 'val_accuracy')\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWux9QaohrjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "800439a2-7f69-49da-cd97-3b68a1030c05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 106ms/step\n"
          ]
        }
      ],
      "source": [
        "test_pred_vgg16 = vggmodel.predict(test_set)\n",
        "test_pred_vgg16_classes = np.argmax(test_pred_vgg16, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vggmodel.save('/content/drive/MyDrive/Models')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V1YWS47AaHe",
        "outputId": "401d7cce-b6a3-42d5-9906-2123268558fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcbNl8f2zS8A",
        "outputId": "4c529fb4-d10f-4b33-f0c0-15907efee84b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1, 2, 1, 3, 0, 1, 3, 0, 2, 0, 2, 3, 2, 1, 0, 0, 1, 2, 2, 3,\n",
              "       1, 1, 0, 1, 0, 1, 0, 3, 1, 2, 2, 0, 1, 3, 0, 2, 1, 1, 3, 3, 2, 2,\n",
              "       0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 1, 0, 1, 3, 0, 2, 2, 1, 1, 1, 3,\n",
              "       2, 1, 0, 3, 2, 3, 3, 3, 0, 1, 1, 3, 0, 2, 2, 2, 0, 2, 0, 1, 1, 3,\n",
              "       1, 3, 0, 1, 3, 1, 0, 2, 1, 0, 3, 3, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
              "       3, 1, 0, 2, 1, 2, 1, 0, 2, 1, 3, 0, 1, 1, 3, 3, 0, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "test_pred_vgg16_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "lWE9DAjdh_yE",
        "outputId": "a0e0123e-2b1c-4910-badf-56618a11d86a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.24      0.28      0.26        32\n",
            "           1       0.19      0.22      0.20        32\n",
            "           2       0.24      0.22      0.23        32\n",
            "           3       0.25      0.19      0.21        32\n",
            "\n",
            "    accuracy                           0.23       128\n",
            "   macro avg       0.23      0.23      0.23       128\n",
            "weighted avg       0.23      0.23      0.23       128\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "true_classes_vgg16 = test_set.classes\n",
        "class_labels_vgg16 = list(test_set.class_indices.keys())\n",
        "\n",
        "# Printing the classification report\n",
        "\n",
        "print(classification_report(true_classes_vgg16, test_pred_vgg16_classes))\n",
        "\n",
        "# Plotting the heatmap using confusion matrix\n",
        "\n",
        "cm = confusion_matrix(true_classes_vgg16, test_pred_vgg16_classes)\n",
        "\n",
        "plt.figure(figsize = (8, 5))\n",
        "\n",
        "sns.heatmap(cm, annot = True,  fmt = '.0f')\n",
        "\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuTi6OAx8q_r"
      },
      "source": [
        "**Observations and Insights:** **For the VGG model now tested with 3 channel the performance not improve as we got as an average of 0.41 in the accuracy, it was tested again with one channel but the accuracy was close to the same, so the VGG model did not make any major improve at the end, so the vgg model for this set will not be considered as a final model solution. It was supposed to use the vgg model if improved to mix with the model3 to arrive to a final classification but the vgg model did not improve.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ResNet Custom Model Implementation**\n",
        "**In this part of the notebook it is implemented a resnet architecture based on the He et al. paper and adapted from a previous implementation to see if the resnet can converge and give a better performance. The input are processed as rgb for the input data for the model and as a grayscale too**"
      ],
      "metadata": {
        "id": "G4QG8WuTQknS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras import Model\n",
        "#from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.layers import Add, GlobalAveragePooling2D, Dense, Flatten, Conv2D, Lambda,\tInput, BatchNormalization, Activation\n",
        "from tensorflow.keras.optimizers import schedules, SGD\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint"
      ],
      "metadata": {
        "id": "df_c3AZcOz56"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size  = 32\n",
        "img_size = 32\n",
        "\n",
        "datagen_train = ImageDataGenerator(horizontal_flip = True,\n",
        "                                    brightness_range = (0., 2.),\n",
        "                                    rescale = 1./255,\n",
        "                                    shear_range = 0.3)\n",
        "\n",
        "train_set = datagen_train.flow_from_directory(folder_path + \"train\",\n",
        "                                              target_size = (img_size, img_size),\n",
        "                                              color_mode = 'grayscale',\n",
        "                                              batch_size = batch_size,\n",
        "                                              class_mode = 'categorical',\n",
        "                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n",
        "                                              shuffle = True)\n",
        "\n",
        "##datagen_validation = #\n",
        "\n",
        "datagen_validation = ImageDataGenerator(horizontal_flip = True,\n",
        "                                    brightness_range=(0.,2.),\n",
        "                                    rescale=1./255,\n",
        "                                    shear_range=0.3)  #\n",
        "\n",
        "#validation_set = #\n",
        "\n",
        "validation_set = datagen_validation.flow_from_directory(folder_path + \"validation\",\n",
        "                                              target_size = (img_size, img_size),\n",
        "                                              color_mode = 'grayscale', # Providing chosen color_mode here ,\n",
        "                                              batch_size = batch_size,\n",
        "                                              class_mode = 'categorical',\n",
        "                                              shuffle = True)  #\n",
        "\n",
        "\n",
        "##datagen_test = #\n",
        "\n",
        "datagen_test = ImageDataGenerator(horizontal_flip = True,\n",
        "                                    brightness_range=(0.,2.),\n",
        "                                    rescale=1./255,\n",
        "                                    shear_range=0.3) #\n",
        "\n",
        "##test_set = #\n",
        "\n",
        "test_set = datagen_test.flow_from_directory(folder_path + \"test\",\n",
        "                                              target_size = (img_size, img_size),\n",
        "                                              color_mode = 'grayscale', # Providing chosen color_mode here ,\n",
        "                                              batch_size = batch_size,\n",
        "                                              class_mode = 'categorical',\n",
        "                                              shuffle = True) #\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9fqObz8TF-q",
        "outputId": "fa7d76a2-3cad-4b8b-bd39-44be812c5a91"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 15109 images belonging to 4 classes.\n",
            "Found 4977 images belonging to 4 classes.\n",
            "Found 128 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_configuration():\n",
        "\t\"\"\"\n",
        "\t\tGet configuration variables for the model.\n",
        "\t\"\"\"\n",
        "\n",
        "\t# Load dataset for computing dataset size\n",
        "#\n",
        "\n",
        "\t# Generic config\n",
        "\twidth, height, channels = 32, 32, 1\n",
        "\tbatch_size = 32\n",
        "\tnum_classes = 4\n",
        "\tvalidation_split = 0.2\n",
        "\tverbose = 1\n",
        "\tn = 3\n",
        "\tinit_fm_dim = 16\n",
        "\tshortcut_type = \"identity\" # or: projection\n",
        "\n",
        "\t# Dataset size\n",
        "\ttrain_size = (1 - validation_split) * 20000\n",
        "\tval_size = (validation_split) * 20000\n",
        "\n",
        "\t# Number of steps per epoch is dependent on batch size\n",
        "\tmaximum_number_iterations = 64000\n",
        "\tsteps_per_epoch = 50\n",
        "\tval_steps_per_epoch = tensorflow.math.floor(val_size / batch_size)\n",
        "\tepochs = 250\n",
        "\n",
        "\t# Defining loss function\n",
        "\tloss = tensorflow.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "\t# Learning rate config per the He et al. paper\n",
        "\tboundaries = [32000, 48000]\n",
        "\tvalues = [0.005, 0.001, 0.0001]\n",
        "\tlr_schedule = schedules.PiecewiseConstantDecay(boundaries, values)\n",
        "\n",
        "\t# Set layer init\n",
        "\tinitializer = tensorflow.keras.initializers.HeNormal()\n",
        "\n",
        "\t# Define optimizer\n",
        "\toptimizer_momentum = 0.9\n",
        "\toptimizer_additional_metrics = [\"accuracy\"]\n",
        "\toptimizer = SGD(learning_rate=lr_schedule, momentum=optimizer_momentum)\n",
        "\n",
        "\t# Load Tensorboard callback\n",
        "\ttensorboard = TensorBoard(\n",
        "\t  log_dir=os.path.join(os.getcwd(), \"logs\"),\n",
        "\t  histogram_freq=1,\n",
        "\t  write_images=True\n",
        "\t)\n",
        "\n",
        "\t# Save a model checkpoint after every epoch\n",
        "\tcheckpoint = ModelCheckpoint(\n",
        "\t\tos.path.join(os.getcwd(), \"model_checkpoint\"),\n",
        "\t\tsave_freq=\"epoch\"\n",
        "\t)\n",
        "\n",
        "\t# Add callbacks to list\n",
        "\tcallbacks = [\n",
        "\t  tensorboard,\n",
        "\t  checkpoint\n",
        "\t]\n",
        "\n",
        "\t# Create config dictionary\n",
        "\tconfig = {\n",
        "\t\t\"width\": width,\n",
        "\t\t\"height\": height,\n",
        "\t\t\"dim\": channels,\n",
        "\t\t\"batch_size\": batch_size,\n",
        "\t\t\"num_classes\": num_classes,\n",
        "\t\t\"validation_split\": validation_split,\n",
        "\t\t\"verbose\": verbose,\n",
        "\t\t\"stack_n\": n,\n",
        "\t\t\"initial_num_feature_maps\": init_fm_dim,\n",
        "\t\t\"training_ds_size\": train_size,\n",
        "\t\t\"steps_per_epoch\": steps_per_epoch,\n",
        "\t\t\"val_steps_per_epoch\": val_steps_per_epoch,\n",
        "\t\t\"num_epochs\": epochs,\n",
        "\t\t\"loss\": loss,\n",
        "\t\t\"optim\": optimizer,\n",
        "\t\t\"optim_learning_rate_schedule\": lr_schedule,\n",
        "\t\t\"optim_momentum\": optimizer_momentum,\n",
        "\t\t\"optim_additional_metrics\": optimizer_additional_metrics,\n",
        "\t\t\"initializer\": initializer,\n",
        "\t\t\"callbacks\": callbacks,\n",
        "\t\t\"shortcut_type\": shortcut_type\n",
        "\t}\n",
        "\n",
        "\treturn config"
      ],
      "metadata": {
        "id": "OhApbJgaO0RT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(x, number_of_filters, match_filter_size=False):\n",
        "\t\"\"\"\n",
        "\t\tResidual block with\n",
        "\t\"\"\"\n",
        "\t# Retrieve initializer\n",
        "\tconfig = model_configuration()\n",
        "\tinitializer = config.get(\"initializer\")\n",
        "\n",
        "\t# Create skip connection\n",
        "\tx_skip = x\n",
        "\n",
        "\t# Perform the original mapping\n",
        "\tif match_filter_size:\n",
        "\t\tx = Conv2D(number_of_filters, kernel_size=(3, 3), strides=(2,2),\\\n",
        "\t\t\tkernel_initializer=initializer, padding=\"same\")(x_skip)\n",
        "\telse:\n",
        "\t\tx = Conv2D(number_of_filters, kernel_size=(3, 3), strides=(1,1),\\\n",
        "\t\t\tkernel_initializer=initializer, padding=\"same\")(x_skip)\n",
        "\tx = BatchNormalization(axis=3)(x)\n",
        "\tx = Activation(\"relu\")(x)\n",
        "\tx = Conv2D(number_of_filters, kernel_size=(3, 3),\\\n",
        "\t\tkernel_initializer=initializer, padding=\"same\")(x)\n",
        "\tx = BatchNormalization(axis=3)(x)\n",
        "\n",
        "\t# Perform matching of filter numbers if necessary\n",
        "\tif match_filter_size and config.get(\"shortcut_type\") == \"identity\":\n",
        "\t\tx_skip = Lambda(lambda x: tensorflow.pad(x[:, ::2, ::2, :], tensorflow.constant([[0, 0,], [0, 0], [0, 0], [number_of_filters//4, number_of_filters//4]]), mode=\"CONSTANT\"))(x_skip)\n",
        "\telif match_filter_size and config.get(\"shortcut_type\") == \"projection\":\n",
        "\t\tx_skip = Conv2D(number_of_filters, kernel_size=(1,1),\\\n",
        "\t\t\tkernel_initializer=initializer, strides=(2,2))(x_skip)\n",
        "\n",
        "\t# Add the skip connection to the regular mapping\n",
        "\tx = Add()([x, x_skip])\n",
        "\n",
        "\t# Nonlinearly activate the result\n",
        "\tx = Activation(\"relu\")(x)\n",
        "\n",
        "\t# Return the result\n",
        "\treturn x"
      ],
      "metadata": {
        "id": "YrlC6_L_P2RF"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResidualBlocks(x):\n",
        "\t\"\"\"\n",
        "\t\tSet up the residual blocks.\n",
        "\t\"\"\"\n",
        "\t# Retrieve values\n",
        "\tconfig = model_configuration()\n",
        "\n",
        "\t# Set initial filter size\n",
        "\tfilter_size = config.get(\"initial_num_feature_maps\")\n",
        "\n",
        "\t# Paper: \"Then we use a stack of 6n layers (...)\n",
        "\t#\twith 2n layers for each feature map size.\"\n",
        "\t# 6n/2n = 3, so there are always 3 groups.\n",
        "\tfor layer_group in range(3):\n",
        "\n",
        "\t\t# Each block in our code has 2 weighted layers,\n",
        "\t\t# and each group has 2n such blocks,\n",
        "\t\t# so 2n/2 = n blocks per group.\n",
        "\t\tfor block in range(config.get(\"stack_n\")):\n",
        "\n",
        "\t\t\t# Perform filter size increase at every\n",
        "\t\t\t# first layer in the 2nd block onwards.\n",
        "\t\t\t# Apply Conv block for projecting the skip\n",
        "\t\t\t# connection.\n",
        "\t\t\tif layer_group > 0 and block == 0:\n",
        "\t\t\t\tfilter_size *= 2\n",
        "\t\t\t\tx = residual_block(x, filter_size, match_filter_size=True)\n",
        "\t\t\telse:\n",
        "\t\t\t\tx = residual_block(x, filter_size)\n",
        "\n",
        "\t# Return final layer\n",
        "\treturn x"
      ],
      "metadata": {
        "id": "aEalt8pvP96x"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_base(shp):\n",
        "\t\"\"\"\n",
        "\t\tBase structure of the model, with residual blocks\n",
        "\t\tattached.\n",
        "\t\"\"\"\n",
        "\t# Get number of classes from model configuration\n",
        "\tconfig = model_configuration()\n",
        "\tinitializer = model_configuration().get(\"initializer\")\n",
        "\n",
        "\t# Define model structure\n",
        "\t# logits are returned because Softmax is pushed to loss function.\n",
        "\tinputs = Input(shape=shp)\n",
        "\tx = Conv2D(config.get(\"initial_num_feature_maps\"), kernel_size=(3,3),\\\n",
        "\t\tstrides=(1,1), kernel_initializer=initializer, padding=\"same\")(inputs)\n",
        "\tx = BatchNormalization()(x)\n",
        "\tx = Activation(\"relu\")(x)\n",
        "\tx = ResidualBlocks(x)\n",
        "\tx = GlobalAveragePooling2D()(x)\n",
        "\tx = Flatten()(x)\n",
        "\toutputs = Dense(config.get(\"num_classes\"), kernel_initializer=initializer)(x)\n",
        "\n",
        "\treturn inputs, outputs"
      ],
      "metadata": {
        "id": "nGu_panwQA4B"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_model():\n",
        "\t\"\"\"\n",
        "\t\tInitialize a compiled ResNet model.\n",
        "\t\"\"\"\n",
        "\t# Get shape from model configuration\n",
        "\tconfig = model_configuration()\n",
        "\n",
        "\t# Get model base\n",
        "\tinputs, outputs = model_base((config.get(\"width\"), config.get(\"height\"),\\\n",
        "\t\tconfig.get(\"dim\")))\n",
        "\n",
        "\t# Initialize and compile model\n",
        "\tmodel = Model(inputs, outputs, name=config.get(\"name\"))\n",
        "\tmodel.compile(loss=config.get(\"loss\"),\\\n",
        "\t\t\t\t  optimizer=config.get(\"optim\"),\\\n",
        "\t\t\t\t  \tmetrics=config.get(\"optim_additional_metrics\"))\n",
        "\n",
        "\t# Print model summary\n",
        "\tmodel.summary()\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "fbhocVg2QDo_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_batches, validation_batches):\n",
        "\t\"\"\"\n",
        "\t\tTrain an initialized model.\n",
        "\t\"\"\"\n",
        "\n",
        "\t# Get model configuration\n",
        "\tconfig = model_configuration()\n",
        "\n",
        "\t# Fit data to model\n",
        "\tmodel.fit(train_batches,\n",
        "\t          batch_size=config.get(\"batch_size\"),\n",
        "\t          epochs=config.get(\"num_epochs\"),\n",
        "\t          verbose=config.get(\"verbose\"),\n",
        "\t          callbacks=config.get(\"callbacks\"),\n",
        "\t          steps_per_epoch=config.get(\"steps_per_epoch\"),\n",
        "\t          validation_data=validation_batches,\n",
        "\t          validation_steps=config.get(\"val_steps_per_epoch\"))\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "ugxPsgizQDtA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_batches):\n",
        "\t\"\"\"\n",
        "\t\tEvaluate a trained model.\n",
        "\t\"\"\"\n",
        "\t# Evaluate model\n",
        "\tscore = model.evaluate(test_batches, verbose=0)\n",
        "\tprint(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
      ],
      "metadata": {
        "id": "XBxAmxwUQLYM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_process():\n",
        "\t\"\"\"\n",
        "\t\tRun the training process for the ResNet model.\n",
        "\t\"\"\"\n",
        "\n",
        "\t# Get dataset\n",
        "\t#train_batches, validation_batches, test_batches = preprocessed_dataset()\n",
        "\n",
        "\ttrain_batches = train_set\n",
        "\tvalidation_batches = validation_set\n",
        "\ttest_batches = test_set\n",
        "\n",
        "\t# Initialize ResNet\n",
        "\tresnet = init_model()\n",
        "\n",
        "\t# Train ResNet model\n",
        "\ttrained_resnet = train_model(resnet, train_batches, validation_batches)\n",
        "\n",
        "\t# Evalute trained ResNet model post training\n",
        "\tevaluate_model(trained_resnet, test_batches)"
      ],
      "metadata": {
        "id": "MJLaMhOYQLas"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################\n",
        "\n",
        "# Clearing backend\n",
        "\n",
        "from tensorflow.keras import backend\n",
        "\n",
        "backend.clear_session()\n",
        "\n",
        "\n",
        "#######################################################"
      ],
      "metadata": {
        "id": "a2I5up6F-nby"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\t# Initialize ResNet\n",
        "\tresnet = init_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GeUvMVfZmYr",
        "outputId": "d72c5e1f-a3d3-4fa0-bd13-3fb7400a32c8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 32, 16)   160         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 32, 32, 16)  64          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 32, 32, 16)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 16)   2320        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 32, 32, 16)   0           ['batch_normalization_2[0][0]',  \n",
            "                                                                  'activation[0][0]']             \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 32, 32, 16)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 32, 32, 16)   0           ['batch_normalization_4[0][0]',  \n",
            "                                                                  'activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 32, 32, 16)   0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 16)   0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 16)   0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 16, 16, 32)   4640        ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 32)   9248        ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " lambda (Lambda)                (None, 16, 16, 32)   0           ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 32)   0           ['batch_normalization_8[0][0]',  \n",
            "                                                                  'lambda[0][0]']                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 32)   0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 32)   9248        ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 32)  128         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 16, 16, 32)   0           ['batch_normalization_10[0][0]', \n",
            "                                                                  'activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 16, 16, 32)   0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  128         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 32)  128         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 16, 16, 32)   0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 16, 32)   0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 8, 8, 64)     18496       ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 8, 8, 64)    256         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 8, 8, 64)    256         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " lambda_1 (Lambda)              (None, 8, 8, 64)     0           ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 8, 8, 64)     0           ['batch_normalization_14[0][0]', \n",
            "                                                                  'lambda_1[0][0]']               \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 8, 8, 64)     0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 8, 8, 64)    256         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 8, 8, 64)    256         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 8, 8, 64)     0           ['batch_normalization_16[0][0]', \n",
            "                                                                  'activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 8, 8, 64)     0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 8, 8, 64)    256         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 8, 8, 64)    256         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 8, 8, 64)     0           ['batch_normalization_18[0][0]', \n",
            "                                                                  'activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 8, 8, 64)     0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 64)          0           ['activation_18[0][0]']          \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 64)           0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 4)            260         ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 271,108\n",
            "Trainable params: 269,732\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\ttrain_batches = train_set\n",
        "\tvalidation_batches = validation_set\n",
        "\ttest_batches = test_set"
      ],
      "metadata": {
        "id": "A-cr9PveZtBb"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_resnet = train_model(resnet, train_batches, validation_batches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNR8V2MKZfam",
        "outputId": "e02d7da0-0d82-4bed-c278-4fba9f2f36f6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.4671 - accuracy: 0.2666"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 26s 398ms/step - loss: 1.4634 - accuracy: 0.2694 - val_loss: 1.7447 - val_accuracy: 0.2657\n",
            "Epoch 2/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.4194 - accuracy: 0.2966"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 344ms/step - loss: 1.4194 - accuracy: 0.2981 - val_loss: 1.5226 - val_accuracy: 0.2040\n",
            "Epoch 3/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.4255 - accuracy: 0.2870"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 325ms/step - loss: 1.4261 - accuracy: 0.2844 - val_loss: 1.5688 - val_accuracy: 0.1912\n",
            "Epoch 4/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.4035 - accuracy: 0.2850"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 322ms/step - loss: 1.4035 - accuracy: 0.2850 - val_loss: 1.3435 - val_accuracy: 0.3753\n",
            "Epoch 5/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.3494 - accuracy: 0.3531"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 309ms/step - loss: 1.3494 - accuracy: 0.3531 - val_loss: 1.3379 - val_accuracy: 0.3545\n",
            "Epoch 6/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.3399 - accuracy: 0.3544"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 303ms/step - loss: 1.3399 - accuracy: 0.3544 - val_loss: 1.3283 - val_accuracy: 0.3630\n",
            "Epoch 7/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.3172 - accuracy: 0.3531"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 353ms/step - loss: 1.3172 - accuracy: 0.3531 - val_loss: 1.5081 - val_accuracy: 0.2643\n",
            "Epoch 8/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.3223 - accuracy: 0.3491"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 355ms/step - loss: 1.3232 - accuracy: 0.3503 - val_loss: 1.3742 - val_accuracy: 0.2492\n",
            "Epoch 9/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.2454 - accuracy: 0.4131"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 340ms/step - loss: 1.2454 - accuracy: 0.4131 - val_loss: 1.3788 - val_accuracy: 0.2490\n",
            "Epoch 10/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.2662 - accuracy: 0.4011"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 323ms/step - loss: 1.2623 - accuracy: 0.4019 - val_loss: 1.6205 - val_accuracy: 0.2693\n",
            "Epoch 11/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.2611 - accuracy: 0.4069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 309ms/step - loss: 1.2592 - accuracy: 0.4094 - val_loss: 1.8464 - val_accuracy: 0.2220\n",
            "Epoch 12/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.2694 - accuracy: 0.3963"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 349ms/step - loss: 1.2694 - accuracy: 0.3963 - val_loss: 1.2651 - val_accuracy: 0.3647\n",
            "Epoch 13/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.2167 - accuracy: 0.4394"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 301ms/step - loss: 1.2139 - accuracy: 0.4400 - val_loss: 1.3368 - val_accuracy: 0.4090\n",
            "Epoch 14/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.2118 - accuracy: 0.4337"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 302ms/step - loss: 1.2111 - accuracy: 0.4338 - val_loss: 1.3081 - val_accuracy: 0.4083\n",
            "Epoch 15/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.1815 - accuracy: 0.4606"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 303ms/step - loss: 1.1815 - accuracy: 0.4606 - val_loss: 1.5632 - val_accuracy: 0.2735\n",
            "Epoch 16/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.1765 - accuracy: 0.4556"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 311ms/step - loss: 1.1765 - accuracy: 0.4556 - val_loss: 1.6524 - val_accuracy: 0.2587\n",
            "Epoch 17/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.1648 - accuracy: 0.4783"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 307ms/step - loss: 1.1626 - accuracy: 0.4787 - val_loss: 1.3637 - val_accuracy: 0.3175\n",
            "Epoch 18/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.1087 - accuracy: 0.4955"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 327ms/step - loss: 1.1153 - accuracy: 0.4938 - val_loss: 1.2169 - val_accuracy: 0.4437\n",
            "Epoch 19/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.1355 - accuracy: 0.4881"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 336ms/step - loss: 1.1355 - accuracy: 0.4881 - val_loss: 1.3521 - val_accuracy: 0.4270\n",
            "Epoch 20/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0810 - accuracy: 0.5175"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 368ms/step - loss: 1.0810 - accuracy: 0.5175 - val_loss: 1.6168 - val_accuracy: 0.2625\n",
            "Epoch 21/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.1091 - accuracy: 0.5006"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 351ms/step - loss: 1.1119 - accuracy: 0.5000 - val_loss: 1.2839 - val_accuracy: 0.4733\n",
            "Epoch 22/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.1155 - accuracy: 0.4919"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 350ms/step - loss: 1.1155 - accuracy: 0.4919 - val_loss: 1.5438 - val_accuracy: 0.3060\n",
            "Epoch 23/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.1180 - accuracy: 0.5051"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 311ms/step - loss: 1.1176 - accuracy: 0.5069 - val_loss: 1.4099 - val_accuracy: 0.3338\n",
            "Epoch 24/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.1200 - accuracy: 0.4943"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 314ms/step - loss: 1.1159 - accuracy: 0.4963 - val_loss: 1.4285 - val_accuracy: 0.3503\n",
            "Epoch 25/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0607 - accuracy: 0.5366"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 308ms/step - loss: 1.0607 - accuracy: 0.5366 - val_loss: 1.5907 - val_accuracy: 0.3002\n",
            "Epoch 26/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.1065 - accuracy: 0.5319"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 325ms/step - loss: 1.1042 - accuracy: 0.5319 - val_loss: 1.3659 - val_accuracy: 0.4635\n",
            "Epoch 27/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.0762 - accuracy: 0.5172"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 307ms/step - loss: 1.0726 - accuracy: 0.5188 - val_loss: 1.1560 - val_accuracy: 0.4685\n",
            "Epoch 28/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0272 - accuracy: 0.5569"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 320ms/step - loss: 1.0272 - accuracy: 0.5569 - val_loss: 1.3841 - val_accuracy: 0.3380\n",
            "Epoch 29/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0610 - accuracy: 0.5294"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 375ms/step - loss: 1.0610 - accuracy: 0.5294 - val_loss: 1.1891 - val_accuracy: 0.4767\n",
            "Epoch 30/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.0321 - accuracy: 0.5351"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 331ms/step - loss: 1.0365 - accuracy: 0.5331 - val_loss: 1.1992 - val_accuracy: 0.4690\n",
            "Epoch 31/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9988 - accuracy: 0.5797"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 332ms/step - loss: 0.9984 - accuracy: 0.5794 - val_loss: 1.1229 - val_accuracy: 0.4645\n",
            "Epoch 32/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0038 - accuracy: 0.5650"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 334ms/step - loss: 1.0038 - accuracy: 0.5650 - val_loss: 1.1301 - val_accuracy: 0.4630\n",
            "Epoch 33/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.0016 - accuracy: 0.5691"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 310ms/step - loss: 1.0022 - accuracy: 0.5677 - val_loss: 1.1752 - val_accuracy: 0.4720\n",
            "Epoch 34/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 1.0479 - accuracy: 0.5281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 336ms/step - loss: 1.0452 - accuracy: 0.5319 - val_loss: 1.4543 - val_accuracy: 0.4440\n",
            "Epoch 35/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9525 - accuracy: 0.5912"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 340ms/step - loss: 0.9505 - accuracy: 0.5919 - val_loss: 1.1653 - val_accuracy: 0.5182\n",
            "Epoch 36/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9435 - accuracy: 0.5888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 333ms/step - loss: 0.9435 - accuracy: 0.5888 - val_loss: 1.2242 - val_accuracy: 0.5153\n",
            "Epoch 37/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9859 - accuracy: 0.5644"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 314ms/step - loss: 0.9874 - accuracy: 0.5638 - val_loss: 1.1481 - val_accuracy: 0.4462\n",
            "Epoch 38/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 1.0020 - accuracy: 0.5587"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 349ms/step - loss: 1.0020 - accuracy: 0.5587 - val_loss: 1.1812 - val_accuracy: 0.4342\n",
            "Epoch 39/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9765 - accuracy: 0.5600"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 326ms/step - loss: 0.9765 - accuracy: 0.5600 - val_loss: 1.1840 - val_accuracy: 0.4787\n",
            "Epoch 40/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9483 - accuracy: 0.6001"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 355ms/step - loss: 0.9461 - accuracy: 0.6006 - val_loss: 1.0942 - val_accuracy: 0.4742\n",
            "Epoch 41/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9922 - accuracy: 0.5906"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 314ms/step - loss: 0.9922 - accuracy: 0.5906 - val_loss: 1.1798 - val_accuracy: 0.4935\n",
            "Epoch 42/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9816 - accuracy: 0.5753"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 336ms/step - loss: 0.9798 - accuracy: 0.5750 - val_loss: 1.1657 - val_accuracy: 0.5275\n",
            "Epoch 43/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9616 - accuracy: 0.5881"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 347ms/step - loss: 0.9616 - accuracy: 0.5881 - val_loss: 1.3663 - val_accuracy: 0.4227\n",
            "Epoch 44/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9376 - accuracy: 0.5772"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 336ms/step - loss: 0.9405 - accuracy: 0.5744 - val_loss: 1.2478 - val_accuracy: 0.4947\n",
            "Epoch 45/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9472 - accuracy: 0.5976"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 331ms/step - loss: 0.9472 - accuracy: 0.5976 - val_loss: 1.2005 - val_accuracy: 0.5015\n",
            "Epoch 46/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9329 - accuracy: 0.5875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 304ms/step - loss: 0.9329 - accuracy: 0.5875 - val_loss: 1.2331 - val_accuracy: 0.4275\n",
            "Epoch 47/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8988 - accuracy: 0.6219"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 19s 377ms/step - loss: 0.8988 - accuracy: 0.6219 - val_loss: 1.1148 - val_accuracy: 0.5170\n",
            "Epoch 48/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9593 - accuracy: 0.5810"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 311ms/step - loss: 0.9568 - accuracy: 0.5819 - val_loss: 1.1245 - val_accuracy: 0.4730\n",
            "Epoch 49/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9111 - accuracy: 0.6025"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 322ms/step - loss: 0.9111 - accuracy: 0.6025 - val_loss: 1.1923 - val_accuracy: 0.4360\n",
            "Epoch 50/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8986 - accuracy: 0.6052"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 310ms/step - loss: 0.9019 - accuracy: 0.6019 - val_loss: 1.1309 - val_accuracy: 0.4757\n",
            "Epoch 51/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9267 - accuracy: 0.6200"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 367ms/step - loss: 0.9267 - accuracy: 0.6200 - val_loss: 1.1495 - val_accuracy: 0.5123\n",
            "Epoch 52/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9070 - accuracy: 0.6231"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 310ms/step - loss: 0.9070 - accuracy: 0.6231 - val_loss: 1.4893 - val_accuracy: 0.4638\n",
            "Epoch 53/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9053 - accuracy: 0.6040"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 365ms/step - loss: 0.9067 - accuracy: 0.6044 - val_loss: 1.1133 - val_accuracy: 0.4835\n",
            "Epoch 54/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.9151 - accuracy: 0.6144"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 322ms/step - loss: 0.9151 - accuracy: 0.6144 - val_loss: 1.3152 - val_accuracy: 0.5362\n",
            "Epoch 55/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9066 - accuracy: 0.6218"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 349ms/step - loss: 0.9039 - accuracy: 0.6231 - val_loss: 1.7346 - val_accuracy: 0.3180\n",
            "Epoch 56/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.9205 - accuracy: 0.6173"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 310ms/step - loss: 0.9156 - accuracy: 0.6212 - val_loss: 1.0849 - val_accuracy: 0.5170\n",
            "Epoch 57/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8875 - accuracy: 0.6225"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 313ms/step - loss: 0.8875 - accuracy: 0.6225 - val_loss: 1.3882 - val_accuracy: 0.5100\n",
            "Epoch 58/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8608 - accuracy: 0.6263"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 314ms/step - loss: 0.8609 - accuracy: 0.6256 - val_loss: 1.2430 - val_accuracy: 0.4363\n",
            "Epoch 59/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8673 - accuracy: 0.6294"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 368ms/step - loss: 0.8673 - accuracy: 0.6294 - val_loss: 1.4697 - val_accuracy: 0.4445\n",
            "Epoch 60/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8848 - accuracy: 0.6231"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 356ms/step - loss: 0.8830 - accuracy: 0.6263 - val_loss: 1.3814 - val_accuracy: 0.4128\n",
            "Epoch 61/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8576 - accuracy: 0.6421"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 332ms/step - loss: 0.8576 - accuracy: 0.6421 - val_loss: 1.1694 - val_accuracy: 0.4565\n",
            "Epoch 62/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8563 - accuracy: 0.6575"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 367ms/step - loss: 0.8529 - accuracy: 0.6594 - val_loss: 1.2584 - val_accuracy: 0.4442\n",
            "Epoch 63/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8563 - accuracy: 0.6333"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 334ms/step - loss: 0.8548 - accuracy: 0.6350 - val_loss: 1.0741 - val_accuracy: 0.5088\n",
            "Epoch 64/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8295 - accuracy: 0.6531"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 325ms/step - loss: 0.8295 - accuracy: 0.6531 - val_loss: 1.6900 - val_accuracy: 0.3480\n",
            "Epoch 65/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8348 - accuracy: 0.6511"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 373ms/step - loss: 0.8331 - accuracy: 0.6506 - val_loss: 1.2464 - val_accuracy: 0.5217\n",
            "Epoch 66/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8478 - accuracy: 0.6344"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 369ms/step - loss: 0.8478 - accuracy: 0.6344 - val_loss: 1.2106 - val_accuracy: 0.4523\n",
            "Epoch 67/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8384 - accuracy: 0.6492"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 354ms/step - loss: 0.8445 - accuracy: 0.6444 - val_loss: 1.2081 - val_accuracy: 0.4770\n",
            "Epoch 68/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8234 - accuracy: 0.6448"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 345ms/step - loss: 0.8230 - accuracy: 0.6469 - val_loss: 1.1011 - val_accuracy: 0.5270\n",
            "Epoch 69/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8190 - accuracy: 0.6556"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 332ms/step - loss: 0.8161 - accuracy: 0.6569 - val_loss: 1.1116 - val_accuracy: 0.5523\n",
            "Epoch 70/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8337 - accuracy: 0.6575"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 351ms/step - loss: 0.8337 - accuracy: 0.6575 - val_loss: 1.1098 - val_accuracy: 0.5150\n",
            "Epoch 71/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8236 - accuracy: 0.6440"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 356ms/step - loss: 0.8236 - accuracy: 0.6440 - val_loss: 1.1089 - val_accuracy: 0.5195\n",
            "Epoch 72/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8775 - accuracy: 0.6244"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 360ms/step - loss: 0.8775 - accuracy: 0.6244 - val_loss: 1.3231 - val_accuracy: 0.5197\n",
            "Epoch 73/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8129 - accuracy: 0.6607"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 346ms/step - loss: 0.8106 - accuracy: 0.6625 - val_loss: 1.0771 - val_accuracy: 0.5225\n",
            "Epoch 74/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8019 - accuracy: 0.6800"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 332ms/step - loss: 0.8019 - accuracy: 0.6800 - val_loss: 1.1260 - val_accuracy: 0.5165\n",
            "Epoch 75/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8011 - accuracy: 0.6569"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 364ms/step - loss: 0.8011 - accuracy: 0.6569 - val_loss: 1.2680 - val_accuracy: 0.4333\n",
            "Epoch 76/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8094 - accuracy: 0.6505"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 311ms/step - loss: 0.8090 - accuracy: 0.6513 - val_loss: 1.5324 - val_accuracy: 0.3417\n",
            "Epoch 77/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8207 - accuracy: 0.6677"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 365ms/step - loss: 0.8228 - accuracy: 0.6687 - val_loss: 1.1450 - val_accuracy: 0.5092\n",
            "Epoch 78/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8013 - accuracy: 0.6587"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 363ms/step - loss: 0.8013 - accuracy: 0.6587 - val_loss: 1.2627 - val_accuracy: 0.5293\n",
            "Epoch 79/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8063 - accuracy: 0.6744"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 311ms/step - loss: 0.8063 - accuracy: 0.6744 - val_loss: 1.4201 - val_accuracy: 0.3663\n",
            "Epoch 80/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.8266 - accuracy: 0.6409"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 332ms/step - loss: 0.8249 - accuracy: 0.6413 - val_loss: 1.2080 - val_accuracy: 0.4720\n",
            "Epoch 81/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8078 - accuracy: 0.6675"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 345ms/step - loss: 0.8078 - accuracy: 0.6675 - val_loss: 1.1129 - val_accuracy: 0.4895\n",
            "Epoch 82/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.8038 - accuracy: 0.6700"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 364ms/step - loss: 0.8038 - accuracy: 0.6700 - val_loss: 1.1271 - val_accuracy: 0.4990\n",
            "Epoch 83/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7883 - accuracy: 0.6537"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 315ms/step - loss: 0.7807 - accuracy: 0.6581 - val_loss: 1.1051 - val_accuracy: 0.5165\n",
            "Epoch 84/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7404 - accuracy: 0.6938"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 374ms/step - loss: 0.7404 - accuracy: 0.6938 - val_loss: 1.2247 - val_accuracy: 0.4843\n",
            "Epoch 85/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7696 - accuracy: 0.6831"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 359ms/step - loss: 0.7696 - accuracy: 0.6831 - val_loss: 1.3672 - val_accuracy: 0.5475\n",
            "Epoch 86/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7827 - accuracy: 0.6643"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 320ms/step - loss: 0.7827 - accuracy: 0.6643 - val_loss: 1.1472 - val_accuracy: 0.5250\n",
            "Epoch 87/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7992 - accuracy: 0.6637"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 345ms/step - loss: 0.7992 - accuracy: 0.6637 - val_loss: 1.1065 - val_accuracy: 0.4703\n",
            "Epoch 88/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7687 - accuracy: 0.6837"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 319ms/step - loss: 0.7687 - accuracy: 0.6837 - val_loss: 1.5689 - val_accuracy: 0.4092\n",
            "Epoch 89/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7560 - accuracy: 0.6888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 344ms/step - loss: 0.7560 - accuracy: 0.6888 - val_loss: 1.2519 - val_accuracy: 0.4710\n",
            "Epoch 90/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7493 - accuracy: 0.6875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 308ms/step - loss: 0.7533 - accuracy: 0.6862 - val_loss: 1.4177 - val_accuracy: 0.4635\n",
            "Epoch 91/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7837 - accuracy: 0.6798"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 318ms/step - loss: 0.7838 - accuracy: 0.6806 - val_loss: 1.3110 - val_accuracy: 0.5107\n",
            "Epoch 92/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7302 - accuracy: 0.7069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 366ms/step - loss: 0.7302 - accuracy: 0.7069 - val_loss: 1.1059 - val_accuracy: 0.5055\n",
            "Epoch 93/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7450 - accuracy: 0.6901"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 353ms/step - loss: 0.7457 - accuracy: 0.6894 - val_loss: 1.2233 - val_accuracy: 0.5192\n",
            "Epoch 94/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7361 - accuracy: 0.6964"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 350ms/step - loss: 0.7338 - accuracy: 0.6969 - val_loss: 1.5384 - val_accuracy: 0.4575\n",
            "Epoch 95/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7689 - accuracy: 0.6849"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 311ms/step - loss: 0.7712 - accuracy: 0.6856 - val_loss: 1.2606 - val_accuracy: 0.4495\n",
            "Epoch 96/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7335 - accuracy: 0.6888"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 311ms/step - loss: 0.7371 - accuracy: 0.6894 - val_loss: 1.6726 - val_accuracy: 0.5310\n",
            "Epoch 97/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7500 - accuracy: 0.6869"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 23s 463ms/step - loss: 0.7500 - accuracy: 0.6869 - val_loss: 1.5792 - val_accuracy: 0.4520\n",
            "Epoch 98/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7443 - accuracy: 0.6944"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 348ms/step - loss: 0.7443 - accuracy: 0.6944 - val_loss: 1.5203 - val_accuracy: 0.4372\n",
            "Epoch 99/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7212 - accuracy: 0.6919"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 325ms/step - loss: 0.7212 - accuracy: 0.6919 - val_loss: 1.2292 - val_accuracy: 0.4717\n",
            "Epoch 100/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7358 - accuracy: 0.6831"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 358ms/step - loss: 0.7358 - accuracy: 0.6831 - val_loss: 1.2745 - val_accuracy: 0.5197\n",
            "Epoch 101/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7183 - accuracy: 0.7013"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 359ms/step - loss: 0.7183 - accuracy: 0.7013 - val_loss: 1.1145 - val_accuracy: 0.5527\n",
            "Epoch 102/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7221 - accuracy: 0.7069"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 339ms/step - loss: 0.7221 - accuracy: 0.7069 - val_loss: 1.3764 - val_accuracy: 0.4908\n",
            "Epoch 103/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7499 - accuracy: 0.6958"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 350ms/step - loss: 0.7520 - accuracy: 0.6938 - val_loss: 1.2377 - val_accuracy: 0.5263\n",
            "Epoch 104/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7530 - accuracy: 0.6945"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 354ms/step - loss: 0.7566 - accuracy: 0.6938 - val_loss: 1.4755 - val_accuracy: 0.5372\n",
            "Epoch 105/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7574 - accuracy: 0.6879"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 330ms/step - loss: 0.7534 - accuracy: 0.6904 - val_loss: 1.1849 - val_accuracy: 0.5075\n",
            "Epoch 106/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6764 - accuracy: 0.7245"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 312ms/step - loss: 0.6753 - accuracy: 0.7244 - val_loss: 1.2535 - val_accuracy: 0.5075\n",
            "Epoch 107/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6681 - accuracy: 0.7232"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 344ms/step - loss: 0.6698 - accuracy: 0.7219 - val_loss: 1.8726 - val_accuracy: 0.3438\n",
            "Epoch 108/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7197 - accuracy: 0.7047"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 325ms/step - loss: 0.7160 - accuracy: 0.7056 - val_loss: 1.5664 - val_accuracy: 0.4502\n",
            "Epoch 109/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7387 - accuracy: 0.6917"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 374ms/step - loss: 0.7387 - accuracy: 0.6917 - val_loss: 2.1210 - val_accuracy: 0.2615\n",
            "Epoch 110/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7400 - accuracy: 0.6920"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 313ms/step - loss: 0.7434 - accuracy: 0.6900 - val_loss: 1.3376 - val_accuracy: 0.5165\n",
            "Epoch 111/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6892 - accuracy: 0.7213"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 321ms/step - loss: 0.6874 - accuracy: 0.7219 - val_loss: 1.2972 - val_accuracy: 0.4995\n",
            "Epoch 112/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7436 - accuracy: 0.6869"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 326ms/step - loss: 0.7436 - accuracy: 0.6869 - val_loss: 1.4970 - val_accuracy: 0.4485\n",
            "Epoch 113/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7041 - accuracy: 0.7143"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 364ms/step - loss: 0.7040 - accuracy: 0.7144 - val_loss: 1.2898 - val_accuracy: 0.5205\n",
            "Epoch 114/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7224 - accuracy: 0.7113"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 364ms/step - loss: 0.7224 - accuracy: 0.7113 - val_loss: 1.4616 - val_accuracy: 0.5552\n",
            "Epoch 115/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.7206 - accuracy: 0.7073"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 353ms/step - loss: 0.7221 - accuracy: 0.7063 - val_loss: 2.2096 - val_accuracy: 0.4215\n",
            "Epoch 116/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6818 - accuracy: 0.7213"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 310ms/step - loss: 0.6789 - accuracy: 0.7225 - val_loss: 1.3838 - val_accuracy: 0.4947\n",
            "Epoch 117/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6821 - accuracy: 0.7207"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 315ms/step - loss: 0.6827 - accuracy: 0.7212 - val_loss: 1.3117 - val_accuracy: 0.4778\n",
            "Epoch 118/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6605 - accuracy: 0.7494"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 366ms/step - loss: 0.6605 - accuracy: 0.7494 - val_loss: 1.4777 - val_accuracy: 0.4378\n",
            "Epoch 119/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6819 - accuracy: 0.7287"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 318ms/step - loss: 0.6819 - accuracy: 0.7287 - val_loss: 1.5047 - val_accuracy: 0.4338\n",
            "Epoch 120/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6905 - accuracy: 0.7258"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 358ms/step - loss: 0.6869 - accuracy: 0.7275 - val_loss: 2.1093 - val_accuracy: 0.4685\n",
            "Epoch 121/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6650 - accuracy: 0.7294"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 334ms/step - loss: 0.6650 - accuracy: 0.7294 - val_loss: 1.9801 - val_accuracy: 0.3413\n",
            "Epoch 122/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6614 - accuracy: 0.7275"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 310ms/step - loss: 0.6614 - accuracy: 0.7275 - val_loss: 1.3542 - val_accuracy: 0.4908\n",
            "Epoch 123/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.7175"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 307ms/step - loss: 0.6699 - accuracy: 0.7181 - val_loss: 1.5779 - val_accuracy: 0.3855\n",
            "Epoch 124/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7082 - accuracy: 0.7063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 324ms/step - loss: 0.7082 - accuracy: 0.7063 - val_loss: 1.5266 - val_accuracy: 0.5240\n",
            "Epoch 125/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7015 - accuracy: 0.7006"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 350ms/step - loss: 0.7015 - accuracy: 0.7006 - val_loss: 1.4327 - val_accuracy: 0.4785\n",
            "Epoch 126/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6737 - accuracy: 0.7353"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 349ms/step - loss: 0.6722 - accuracy: 0.7369 - val_loss: 1.5936 - val_accuracy: 0.5063\n",
            "Epoch 127/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6506 - accuracy: 0.7270"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 318ms/step - loss: 0.6476 - accuracy: 0.7281 - val_loss: 1.3892 - val_accuracy: 0.4450\n",
            "Epoch 128/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6836 - accuracy: 0.7216"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 310ms/step - loss: 0.6836 - accuracy: 0.7216 - val_loss: 1.1859 - val_accuracy: 0.4920\n",
            "Epoch 129/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6437 - accuracy: 0.7294"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 310ms/step - loss: 0.6484 - accuracy: 0.7273 - val_loss: 1.1703 - val_accuracy: 0.5088\n",
            "Epoch 130/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6550 - accuracy: 0.7294"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 357ms/step - loss: 0.6550 - accuracy: 0.7294 - val_loss: 1.2350 - val_accuracy: 0.5030\n",
            "Epoch 131/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.7249"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 311ms/step - loss: 0.6710 - accuracy: 0.7254 - val_loss: 1.5806 - val_accuracy: 0.4720\n",
            "Epoch 132/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6743 - accuracy: 0.7283"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 343ms/step - loss: 0.6688 - accuracy: 0.7319 - val_loss: 1.2559 - val_accuracy: 0.4960\n",
            "Epoch 133/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6307 - accuracy: 0.7556"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 330ms/step - loss: 0.6307 - accuracy: 0.7556 - val_loss: 1.6090 - val_accuracy: 0.4290\n",
            "Epoch 134/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.7025 - accuracy: 0.7194"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 316ms/step - loss: 0.7025 - accuracy: 0.7194 - val_loss: 1.3553 - val_accuracy: 0.4575\n",
            "Epoch 135/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6684 - accuracy: 0.7302"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 313ms/step - loss: 0.6695 - accuracy: 0.7300 - val_loss: 1.9793 - val_accuracy: 0.3598\n",
            "Epoch 136/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6781 - accuracy: 0.7251"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 336ms/step - loss: 0.6739 - accuracy: 0.7269 - val_loss: 1.2275 - val_accuracy: 0.5197\n",
            "Epoch 137/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6758 - accuracy: 0.7194"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 373ms/step - loss: 0.6758 - accuracy: 0.7194 - val_loss: 1.5118 - val_accuracy: 0.4980\n",
            "Epoch 138/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6541 - accuracy: 0.7343"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 352ms/step - loss: 0.6541 - accuracy: 0.7343 - val_loss: 1.1814 - val_accuracy: 0.5310\n",
            "Epoch 139/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6408 - accuracy: 0.7564"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 333ms/step - loss: 0.6376 - accuracy: 0.7594 - val_loss: 1.1457 - val_accuracy: 0.5247\n",
            "Epoch 140/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6457 - accuracy: 0.7423"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 19s 378ms/step - loss: 0.6460 - accuracy: 0.7412 - val_loss: 1.6318 - val_accuracy: 0.5030\n",
            "Epoch 141/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6386 - accuracy: 0.7350"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 353ms/step - loss: 0.6386 - accuracy: 0.7350 - val_loss: 1.1877 - val_accuracy: 0.4983\n",
            "Epoch 142/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6243 - accuracy: 0.7474"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 308ms/step - loss: 0.6260 - accuracy: 0.7475 - val_loss: 2.1738 - val_accuracy: 0.4040\n",
            "Epoch 143/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5804 - accuracy: 0.7570"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 327ms/step - loss: 0.5834 - accuracy: 0.7550 - val_loss: 1.8044 - val_accuracy: 0.3613\n",
            "Epoch 144/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6402 - accuracy: 0.7430"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 359ms/step - loss: 0.6408 - accuracy: 0.7425 - val_loss: 1.7902 - val_accuracy: 0.3675\n",
            "Epoch 145/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6298 - accuracy: 0.7475"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 317ms/step - loss: 0.6298 - accuracy: 0.7475 - val_loss: 1.4513 - val_accuracy: 0.5265\n",
            "Epoch 146/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6427 - accuracy: 0.7290"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 331ms/step - loss: 0.6455 - accuracy: 0.7281 - val_loss: 1.1904 - val_accuracy: 0.4983\n",
            "Epoch 147/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6499 - accuracy: 0.7469"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 19s 385ms/step - loss: 0.6499 - accuracy: 0.7469 - val_loss: 1.3370 - val_accuracy: 0.5188\n",
            "Epoch 148/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6298 - accuracy: 0.7506"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 364ms/step - loss: 0.6298 - accuracy: 0.7506 - val_loss: 1.5309 - val_accuracy: 0.4530\n",
            "Epoch 149/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6497 - accuracy: 0.7341"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 337ms/step - loss: 0.6506 - accuracy: 0.7344 - val_loss: 1.1486 - val_accuracy: 0.5235\n",
            "Epoch 150/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6346 - accuracy: 0.7443"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 19s 379ms/step - loss: 0.6317 - accuracy: 0.7444 - val_loss: 2.1035 - val_accuracy: 0.3523\n",
            "Epoch 151/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6262 - accuracy: 0.7481"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 331ms/step - loss: 0.6262 - accuracy: 0.7481 - val_loss: 1.2960 - val_accuracy: 0.5178\n",
            "Epoch 152/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6108 - accuracy: 0.7557"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 335ms/step - loss: 0.6118 - accuracy: 0.7556 - val_loss: 1.2519 - val_accuracy: 0.5038\n",
            "Epoch 153/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6174 - accuracy: 0.7475"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 329ms/step - loss: 0.6174 - accuracy: 0.7475 - val_loss: 1.3441 - val_accuracy: 0.4795\n",
            "Epoch 154/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6018 - accuracy: 0.7631"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 333ms/step - loss: 0.6018 - accuracy: 0.7631 - val_loss: 1.3162 - val_accuracy: 0.5330\n",
            "Epoch 155/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6219 - accuracy: 0.7559"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 375ms/step - loss: 0.6219 - accuracy: 0.7559 - val_loss: 1.6960 - val_accuracy: 0.5415\n",
            "Epoch 156/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6277 - accuracy: 0.7596"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 325ms/step - loss: 0.6284 - accuracy: 0.7563 - val_loss: 1.9704 - val_accuracy: 0.4625\n",
            "Epoch 157/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6198 - accuracy: 0.7449"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 322ms/step - loss: 0.6159 - accuracy: 0.7462 - val_loss: 1.7558 - val_accuracy: 0.5375\n",
            "Epoch 158/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6392 - accuracy: 0.7372"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 325ms/step - loss: 0.6375 - accuracy: 0.7362 - val_loss: 1.3212 - val_accuracy: 0.4762\n",
            "Epoch 159/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6407 - accuracy: 0.7526"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 19s 381ms/step - loss: 0.6409 - accuracy: 0.7519 - val_loss: 1.2596 - val_accuracy: 0.4725\n",
            "Epoch 160/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6032 - accuracy: 0.7500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 316ms/step - loss: 0.6032 - accuracy: 0.7500 - val_loss: 1.6544 - val_accuracy: 0.3805\n",
            "Epoch 161/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5925 - accuracy: 0.7600"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 356ms/step - loss: 0.5925 - accuracy: 0.7600 - val_loss: 1.5438 - val_accuracy: 0.4392\n",
            "Epoch 162/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5634 - accuracy: 0.7650"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 355ms/step - loss: 0.5634 - accuracy: 0.7650 - val_loss: 1.6749 - val_accuracy: 0.5788\n",
            "Epoch 163/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5587 - accuracy: 0.7763"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 365ms/step - loss: 0.5587 - accuracy: 0.7763 - val_loss: 1.8872 - val_accuracy: 0.5203\n",
            "Epoch 164/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.6028 - accuracy: 0.7475"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 19s 380ms/step - loss: 0.6028 - accuracy: 0.7475 - val_loss: 1.8356 - val_accuracy: 0.4150\n",
            "Epoch 165/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6432 - accuracy: 0.7468"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 329ms/step - loss: 0.6373 - accuracy: 0.7506 - val_loss: 1.3960 - val_accuracy: 0.5155\n",
            "Epoch 166/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5939 - accuracy: 0.7619"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 356ms/step - loss: 0.5939 - accuracy: 0.7619 - val_loss: 1.6545 - val_accuracy: 0.5033\n",
            "Epoch 167/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.7725"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 358ms/step - loss: 0.5662 - accuracy: 0.7725 - val_loss: 1.6659 - val_accuracy: 0.4925\n",
            "Epoch 168/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5889 - accuracy: 0.7557"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 336ms/step - loss: 0.5892 - accuracy: 0.7550 - val_loss: 1.7384 - val_accuracy: 0.4992\n",
            "Epoch 169/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5820 - accuracy: 0.7612"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 350ms/step - loss: 0.5803 - accuracy: 0.7635 - val_loss: 2.0655 - val_accuracy: 0.4608\n",
            "Epoch 170/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5897 - accuracy: 0.7606"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 370ms/step - loss: 0.5897 - accuracy: 0.7606 - val_loss: 1.7618 - val_accuracy: 0.4520\n",
            "Epoch 171/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5789 - accuracy: 0.7666"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 356ms/step - loss: 0.5810 - accuracy: 0.7669 - val_loss: 1.2192 - val_accuracy: 0.5230\n",
            "Epoch 172/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5467 - accuracy: 0.7806"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 310ms/step - loss: 0.5479 - accuracy: 0.7800 - val_loss: 1.5690 - val_accuracy: 0.5255\n",
            "Epoch 173/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.7719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 337ms/step - loss: 0.5916 - accuracy: 0.7719 - val_loss: 1.8803 - val_accuracy: 0.3898\n",
            "Epoch 174/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5836 - accuracy: 0.7640"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 376ms/step - loss: 0.5905 - accuracy: 0.7625 - val_loss: 1.6154 - val_accuracy: 0.4602\n",
            "Epoch 175/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5841 - accuracy: 0.7657"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 309ms/step - loss: 0.5804 - accuracy: 0.7667 - val_loss: 1.5748 - val_accuracy: 0.5180\n",
            "Epoch 176/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5852 - accuracy: 0.7698"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 320ms/step - loss: 0.5873 - accuracy: 0.7688 - val_loss: 1.5535 - val_accuracy: 0.4767\n",
            "Epoch 177/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5751 - accuracy: 0.7663"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 19s 378ms/step - loss: 0.5751 - accuracy: 0.7663 - val_loss: 1.5465 - val_accuracy: 0.4757\n",
            "Epoch 178/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.6142 - accuracy: 0.7577"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 336ms/step - loss: 0.6116 - accuracy: 0.7594 - val_loss: 1.5712 - val_accuracy: 0.5088\n",
            "Epoch 179/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5524 - accuracy: 0.7800"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 342ms/step - loss: 0.5524 - accuracy: 0.7800 - val_loss: 1.4156 - val_accuracy: 0.5123\n",
            "Epoch 180/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5485 - accuracy: 0.7781"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 331ms/step - loss: 0.5485 - accuracy: 0.7781 - val_loss: 1.4703 - val_accuracy: 0.4827\n",
            "Epoch 181/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5417 - accuracy: 0.7900"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 364ms/step - loss: 0.5417 - accuracy: 0.7900 - val_loss: 1.6693 - val_accuracy: 0.5325\n",
            "Epoch 182/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5378 - accuracy: 0.7887"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 335ms/step - loss: 0.5378 - accuracy: 0.7887 - val_loss: 1.4504 - val_accuracy: 0.5215\n",
            "Epoch 183/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5577 - accuracy: 0.7788"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 324ms/step - loss: 0.5577 - accuracy: 0.7788 - val_loss: 1.5948 - val_accuracy: 0.4430\n",
            "Epoch 184/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5551 - accuracy: 0.7859"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 356ms/step - loss: 0.5543 - accuracy: 0.7858 - val_loss: 1.4966 - val_accuracy: 0.5415\n",
            "Epoch 185/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5866 - accuracy: 0.7638"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 355ms/step - loss: 0.5866 - accuracy: 0.7638 - val_loss: 1.4552 - val_accuracy: 0.5403\n",
            "Epoch 186/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5220 - accuracy: 0.7915"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 349ms/step - loss: 0.5206 - accuracy: 0.7912 - val_loss: 1.7164 - val_accuracy: 0.5468\n",
            "Epoch 187/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5491 - accuracy: 0.7869"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 343ms/step - loss: 0.5491 - accuracy: 0.7869 - val_loss: 1.9873 - val_accuracy: 0.5060\n",
            "Epoch 188/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5355 - accuracy: 0.7819"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 311ms/step - loss: 0.5356 - accuracy: 0.7819 - val_loss: 1.8024 - val_accuracy: 0.4728\n",
            "Epoch 189/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5239 - accuracy: 0.7981"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 354ms/step - loss: 0.5239 - accuracy: 0.7981 - val_loss: 1.4014 - val_accuracy: 0.5160\n",
            "Epoch 190/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5140 - accuracy: 0.7959"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 330ms/step - loss: 0.5110 - accuracy: 0.7981 - val_loss: 1.6804 - val_accuracy: 0.4877\n",
            "Epoch 191/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5781 - accuracy: 0.7669"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 370ms/step - loss: 0.5781 - accuracy: 0.7669 - val_loss: 2.0480 - val_accuracy: 0.3045\n",
            "Epoch 192/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5430 - accuracy: 0.7889"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 359ms/step - loss: 0.5468 - accuracy: 0.7856 - val_loss: 1.3215 - val_accuracy: 0.5452\n",
            "Epoch 193/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5689 - accuracy: 0.7725"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 366ms/step - loss: 0.5689 - accuracy: 0.7725 - val_loss: 1.3392 - val_accuracy: 0.5230\n",
            "Epoch 194/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5482 - accuracy: 0.7800"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 328ms/step - loss: 0.5482 - accuracy: 0.7800 - val_loss: 1.5923 - val_accuracy: 0.4453\n",
            "Epoch 195/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5355 - accuracy: 0.7825"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 364ms/step - loss: 0.5389 - accuracy: 0.7800 - val_loss: 1.6351 - val_accuracy: 0.4672\n",
            "Epoch 196/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5475 - accuracy: 0.7819"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 327ms/step - loss: 0.5475 - accuracy: 0.7819 - val_loss: 1.5981 - val_accuracy: 0.4683\n",
            "Epoch 197/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4988 - accuracy: 0.8029"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 360ms/step - loss: 0.5040 - accuracy: 0.8006 - val_loss: 1.3827 - val_accuracy: 0.4995\n",
            "Epoch 198/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5044 - accuracy: 0.7931"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 23s 463ms/step - loss: 0.5044 - accuracy: 0.7931 - val_loss: 1.1931 - val_accuracy: 0.5173\n",
            "Epoch 199/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5319 - accuracy: 0.7902"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 339ms/step - loss: 0.5329 - accuracy: 0.7887 - val_loss: 1.6388 - val_accuracy: 0.5167\n",
            "Epoch 200/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5044 - accuracy: 0.8004"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 327ms/step - loss: 0.5044 - accuracy: 0.8004 - val_loss: 2.3168 - val_accuracy: 0.4665\n",
            "Epoch 201/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5287 - accuracy: 0.8017"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 351ms/step - loss: 0.5280 - accuracy: 0.8012 - val_loss: 1.9850 - val_accuracy: 0.5495\n",
            "Epoch 202/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.7962"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 347ms/step - loss: 0.5202 - accuracy: 0.7962 - val_loss: 3.0626 - val_accuracy: 0.4322\n",
            "Epoch 203/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4961 - accuracy: 0.8048"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 359ms/step - loss: 0.4948 - accuracy: 0.8050 - val_loss: 1.3050 - val_accuracy: 0.5178\n",
            "Epoch 204/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4944 - accuracy: 0.8106"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 332ms/step - loss: 0.4944 - accuracy: 0.8106 - val_loss: 1.6744 - val_accuracy: 0.5397\n",
            "Epoch 205/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4960 - accuracy: 0.7925"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 368ms/step - loss: 0.4960 - accuracy: 0.7925 - val_loss: 1.9593 - val_accuracy: 0.4327\n",
            "Epoch 206/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5552 - accuracy: 0.7755"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 324ms/step - loss: 0.5555 - accuracy: 0.7756 - val_loss: 1.9586 - val_accuracy: 0.5255\n",
            "Epoch 207/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5312 - accuracy: 0.7975"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 364ms/step - loss: 0.5312 - accuracy: 0.7975 - val_loss: 1.8741 - val_accuracy: 0.4313\n",
            "Epoch 208/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5336 - accuracy: 0.7869"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 335ms/step - loss: 0.5336 - accuracy: 0.7869 - val_loss: 1.8479 - val_accuracy: 0.4605\n",
            "Epoch 209/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4988 - accuracy: 0.8031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 353ms/step - loss: 0.4988 - accuracy: 0.8031 - val_loss: 2.1363 - val_accuracy: 0.5132\n",
            "Epoch 210/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5359 - accuracy: 0.7755"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 340ms/step - loss: 0.5371 - accuracy: 0.7744 - val_loss: 2.4161 - val_accuracy: 0.5652\n",
            "Epoch 211/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5254 - accuracy: 0.7912"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 354ms/step - loss: 0.5254 - accuracy: 0.7912 - val_loss: 1.7188 - val_accuracy: 0.5315\n",
            "Epoch 212/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.8010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 333ms/step - loss: 0.4964 - accuracy: 0.8012 - val_loss: 1.6253 - val_accuracy: 0.4830\n",
            "Epoch 213/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5169 - accuracy: 0.8019"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 324ms/step - loss: 0.5169 - accuracy: 0.8019 - val_loss: 1.4927 - val_accuracy: 0.4985\n",
            "Epoch 214/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4754 - accuracy: 0.8031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 332ms/step - loss: 0.4754 - accuracy: 0.8031 - val_loss: 1.7535 - val_accuracy: 0.4378\n",
            "Epoch 215/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.8087"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 362ms/step - loss: 0.4904 - accuracy: 0.8087 - val_loss: 1.4240 - val_accuracy: 0.5008\n",
            "Epoch 216/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.8206"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 355ms/step - loss: 0.4604 - accuracy: 0.8206 - val_loss: 1.6027 - val_accuracy: 0.5715\n",
            "Epoch 217/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4923 - accuracy: 0.8087"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 337ms/step - loss: 0.4959 - accuracy: 0.8075 - val_loss: 1.5751 - val_accuracy: 0.5098\n",
            "Epoch 218/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4755 - accuracy: 0.8125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 358ms/step - loss: 0.4755 - accuracy: 0.8125 - val_loss: 1.5234 - val_accuracy: 0.4575\n",
            "Epoch 219/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4903 - accuracy: 0.8004"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 328ms/step - loss: 0.4894 - accuracy: 0.8006 - val_loss: 2.4402 - val_accuracy: 0.4100\n",
            "Epoch 220/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5184 - accuracy: 0.8087"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 354ms/step - loss: 0.5184 - accuracy: 0.8087 - val_loss: 1.7244 - val_accuracy: 0.4868\n",
            "Epoch 221/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4473 - accuracy: 0.8265"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 317ms/step - loss: 0.4444 - accuracy: 0.8275 - val_loss: 1.7763 - val_accuracy: 0.4283\n",
            "Epoch 222/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4903 - accuracy: 0.8074"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 344ms/step - loss: 0.4887 - accuracy: 0.8062 - val_loss: 1.4431 - val_accuracy: 0.5195\n",
            "Epoch 223/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4698 - accuracy: 0.8125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 307ms/step - loss: 0.4698 - accuracy: 0.8125 - val_loss: 2.5662 - val_accuracy: 0.3503\n",
            "Epoch 224/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4886 - accuracy: 0.7934"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 329ms/step - loss: 0.4899 - accuracy: 0.7931 - val_loss: 1.9522 - val_accuracy: 0.5123\n",
            "Epoch 225/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5246 - accuracy: 0.7900"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 334ms/step - loss: 0.5246 - accuracy: 0.7900 - val_loss: 2.5190 - val_accuracy: 0.3817\n",
            "Epoch 226/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.5014 - accuracy: 0.7959"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 365ms/step - loss: 0.4987 - accuracy: 0.7969 - val_loss: 1.2594 - val_accuracy: 0.5210\n",
            "Epoch 227/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4622 - accuracy: 0.8240"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 309ms/step - loss: 0.4590 - accuracy: 0.8244 - val_loss: 1.5695 - val_accuracy: 0.4428\n",
            "Epoch 228/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4397 - accuracy: 0.8263"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 333ms/step - loss: 0.4397 - accuracy: 0.8263 - val_loss: 1.8008 - val_accuracy: 0.4420\n",
            "Epoch 229/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.5010 - accuracy: 0.8062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 15s 310ms/step - loss: 0.5010 - accuracy: 0.8062 - val_loss: 1.8307 - val_accuracy: 0.5100\n",
            "Epoch 230/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4818 - accuracy: 0.8163"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 318ms/step - loss: 0.4818 - accuracy: 0.8163 - val_loss: 1.4502 - val_accuracy: 0.5082\n",
            "Epoch 231/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4539 - accuracy: 0.8272"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 339ms/step - loss: 0.4505 - accuracy: 0.8281 - val_loss: 1.3984 - val_accuracy: 0.4640\n",
            "Epoch 232/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.8206"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 19s 378ms/step - loss: 0.4562 - accuracy: 0.8206 - val_loss: 1.5671 - val_accuracy: 0.5098\n",
            "Epoch 233/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4804 - accuracy: 0.8044"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 353ms/step - loss: 0.4804 - accuracy: 0.8044 - val_loss: 2.5438 - val_accuracy: 0.5702\n",
            "Epoch 234/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4773 - accuracy: 0.8010"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 330ms/step - loss: 0.4773 - accuracy: 0.8010 - val_loss: 1.5040 - val_accuracy: 0.5525\n",
            "Epoch 235/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4694 - accuracy: 0.8125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 339ms/step - loss: 0.4712 - accuracy: 0.8112 - val_loss: 2.5267 - val_accuracy: 0.4205\n",
            "Epoch 236/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4438 - accuracy: 0.8306"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 374ms/step - loss: 0.4438 - accuracy: 0.8306 - val_loss: 1.7313 - val_accuracy: 0.4975\n",
            "Epoch 237/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4576 - accuracy: 0.8256"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 365ms/step - loss: 0.4576 - accuracy: 0.8256 - val_loss: 2.8959 - val_accuracy: 0.4030\n",
            "Epoch 238/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4965 - accuracy: 0.7994"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 344ms/step - loss: 0.4965 - accuracy: 0.7994 - val_loss: 1.6156 - val_accuracy: 0.5000\n",
            "Epoch 239/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4418 - accuracy: 0.8244"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 357ms/step - loss: 0.4418 - accuracy: 0.8244 - val_loss: 1.5389 - val_accuracy: 0.5335\n",
            "Epoch 240/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4802 - accuracy: 0.8157"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 326ms/step - loss: 0.4771 - accuracy: 0.8175 - val_loss: 1.4693 - val_accuracy: 0.5390\n",
            "Epoch 241/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4385 - accuracy: 0.8244"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 350ms/step - loss: 0.4385 - accuracy: 0.8244 - val_loss: 2.0056 - val_accuracy: 0.4243\n",
            "Epoch 242/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4361 - accuracy: 0.8344"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 357ms/step - loss: 0.4361 - accuracy: 0.8344 - val_loss: 2.0250 - val_accuracy: 0.5188\n",
            "Epoch 243/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4616 - accuracy: 0.8233"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 333ms/step - loss: 0.4580 - accuracy: 0.8244 - val_loss: 2.2109 - val_accuracy: 0.4180\n",
            "Epoch 244/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4420 - accuracy: 0.8406"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 332ms/step - loss: 0.4420 - accuracy: 0.8406 - val_loss: 1.6497 - val_accuracy: 0.4665\n",
            "Epoch 245/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4553 - accuracy: 0.8265"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 19s 382ms/step - loss: 0.4598 - accuracy: 0.8238 - val_loss: 1.6678 - val_accuracy: 0.5560\n",
            "Epoch 246/250\n",
            "49/50 [============================>.] - ETA: 0s - loss: 0.4593 - accuracy: 0.8208"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 18s 369ms/step - loss: 0.4632 - accuracy: 0.8200 - val_loss: 1.4850 - val_accuracy: 0.5010\n",
            "Epoch 247/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4462 - accuracy: 0.8263"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 344ms/step - loss: 0.4462 - accuracy: 0.8263 - val_loss: 1.6588 - val_accuracy: 0.4815\n",
            "Epoch 248/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.8375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 19s 391ms/step - loss: 0.4057 - accuracy: 0.8375 - val_loss: 1.9694 - val_accuracy: 0.5490\n",
            "Epoch 249/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4521 - accuracy: 0.8252"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 16s 330ms/step - loss: 0.4521 - accuracy: 0.8252 - val_loss: 2.6141 - val_accuracy: 0.4938\n",
            "Epoch 250/250\n",
            "50/50 [==============================] - ETA: 0s - loss: 0.4412 - accuracy: 0.8288"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r50/50 [==============================] - 17s 345ms/step - loss: 0.4412 - accuracy: 0.8288 - val_loss: 2.2132 - val_accuracy: 0.4940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\tevaluate_model(trained_resnet, test_batches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWdpfDxmMm5p",
        "outputId": "c1577b8d-9cce-4837-e940-59b19b16197c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 1.9727603197097778 / Test accuracy: 0.4921875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "**Finally the resnet model could converge but in both datasets of rgb and grayscale the maximum accuracy obtained was this last one of 0.49, maybe the quantity of images are too small and the quality of them is not so high too, so resnet is not selected for the final model for the solution**"
      ],
      "metadata": {
        "id": "B3vhlLLWgi5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_model_resnet = trained_resnet.predict(test_set)\n",
        "test_pred_model_resnet_classes = np.argmax(test_pred_model_resnet, axis=1)"
      ],
      "metadata": {
        "id": "qKbK2JERPurc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d6c27c-ca33-4acd-fa45-eb91757da375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 23ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "true_classes_model_resnet = test_set.classes\n",
        "class_labels_model_resnet = list(test_set.class_indices.keys())\n",
        "\n",
        "# Printing the classification report\n",
        "\n",
        "print(classification_report(true_classes_model_resnet, test_pred_model_resnet_classes))\n",
        "\n",
        "# Plotting the heatmap using confusion matrix\n",
        "\n",
        "cm = confusion_matrix(true_classes_model_resnet, test_pred_model_resnet_classes)\n",
        "\n",
        "plt.figure(figsize = (8, 5))\n",
        "\n",
        "sns.heatmap(cm, annot = True,  fmt = '.0f')\n",
        "\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "plt.xlabel('Predicted')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8LdOfRqNX4CH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "outputId": "fc1f8a92-220f-48c3-e829-bfe67dd987e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      0.22      0.18        32\n",
            "           1       0.26      0.22      0.24        32\n",
            "           2       0.26      0.31      0.28        32\n",
            "           3       0.28      0.16      0.20        32\n",
            "\n",
            "    accuracy                           0.23       128\n",
            "   macro avg       0.24      0.23      0.23       128\n",
            "weighted avg       0.24      0.23      0.23       128\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_resnet.save('/content/drive/MyDrive/Models')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAd9VgEXNN_6",
        "outputId": "aed8fa6f-1251-4148-e0ad-29c05ad5ab78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 19). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81uYGSmHwxfD"
      },
      "source": [
        "**Observations and Insights:**\n",
        "**For the task we will implement a model and use Bayessian Optimization to find the best learning rate. As with transfer learning models as VGG and the implementation of resnet that obtain accurracies of 0.50 and 0.49 respectivily. Many factors can be a reason for this as the small dataset, the not so good quality of the images, the images that should not correspond to a class and other ones that make the more complex models to not perform so good as the simpler model model3. So for this dataset, for the solution it will be chosen the model3 which we implement and test in the next lines.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.save('/content/drive/MyDrive/Models')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rng6YO8nY_fb",
        "outputId": "24807d07-e903-4b11-f2d6-6e201db9fcb6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 12). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjKlBaZDpWoV"
      },
      "source": [
        "## **Building a Complex Neural Network Architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bMFUj3Fpe75"
      },
      "source": [
        "So we choose to use a new model, the Model3 that we will implment and improve its performance, to reduce the complexity we keep using the one channel input and we reduce some layers in the model In this section, we will build a more complex Convolutional Neural Network Model that has close to as many parameters as we had in our Transfer Learning Models. However, we will have only 1 input channel for our input images for hardware purposes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejGfyYSbtx-F"
      },
      "source": [
        "## **Creating our Data Loaders**\n",
        "\n",
        "In this section, we are creating data loaders which we will use as inputs to the more Complicated Convolutional Neural Network. We will go ahead with color_mode = 'grayscale'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft5U6f1Wie2R"
      },
      "source": [
        "### **Model Building**\n",
        "\n",
        "* In this network, we plan to reduce some 7 Convolutional Blocks and 2 full  connected layers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "37f9194d"
      },
      "outputs": [],
      "source": [
        "######################################################\n",
        "\n",
        "\n",
        "\n",
        "# Clearing backend\n",
        "\n",
        "from tensorflow.keras import backend\n",
        "\n",
        "backend.clear_session()\n",
        "# Fixing the seed for random number generators\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "import random\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "#######################################################\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "l1_l2_reg = regularizers.L1L2(l1=0.05, l2=0.025)\n",
        "\n",
        "#######################################################\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "no_of_classes = 4\n",
        "\n",
        "def create_model(params):\n",
        "  model3 = Sequential()\n",
        "\n",
        "  # Add 1st CNN Block\n",
        "  #____________\n",
        "  model3.add(Conv2D(filters = 64, kernel_size = (2, 2), activation = 'relu', padding = 'same', input_shape = (48, 48, 1)))\n",
        "  model3.add(BatchNormalization())\n",
        "  model3.add(LeakyReLU(alpha=0.1))\n",
        "  model3.add(MaxPooling2D((2, 2), padding = 'same'))\n",
        "  model3.add(Dropout(0.2))\n",
        "\n",
        "  # Add 2nd CNN Block\n",
        "  #____________\n",
        "  model3.add(Conv2D(filters = 128, kernel_size = (2, 2), activation = 'relu', padding = 'same'))\n",
        "  model3.add(BatchNormalization())\n",
        "  model3.add(LeakyReLU(alpha=0.1))\n",
        "  model3.add(MaxPooling2D((2, 2), padding = 'same'))\n",
        "  model3.add(Dropout(0.2))\n",
        "\n",
        "  # Add 3rd CNN Block\n",
        "  #____________\n",
        "  model3.add(Conv2D(filters = 512, kernel_size = (2, 2), activation = 'relu', padding = 'same'))\n",
        "  model3.add(BatchNormalization())\n",
        "  model3.add(LeakyReLU(alpha=0.1))\n",
        "  model3.add(MaxPooling2D((2, 2), padding = 'same'))\n",
        "  model3.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "  # Add 4th CNN Block\n",
        "  #____________\n",
        "  model3.add(Conv2D(filters = 512, kernel_size = (2, 2), activation = 'relu', padding = 'same'))\n",
        "  model3.add(Conv2D(filters = 512, kernel_size = (2, 2), activation = 'relu', padding = 'same'))\n",
        "  model3.add(Conv2D(filters = 512, kernel_size = (2, 2), activation = 'relu', padding = 'same'))\n",
        "  model3.add(Activation(\"relu\"))\n",
        "\n",
        "\n",
        "\n",
        "  #Add 5th CNN Block\n",
        "\n",
        "  model3.add(Conv2D(filters = 256, kernel_size = (2, 2), activation = 'relu', padding = 'same'))\n",
        "  model3.add(Conv2D(filters = 256, kernel_size = (2, 2), activation = 'relu', padding = 'same'))\n",
        "  model3.add(Activation(\"relu\"))\n",
        "\n",
        "\n",
        "  #Add 6th CNN Block\n",
        "\n",
        "  model3.add(Conv2D(filters = 256, kernel_size = (2, 2), activation = 'relu', padding = 'same'))\n",
        "  model3.add(Conv2D(filters = 256, kernel_size = (2, 2), activation = 'relu', padding = 'same'))\n",
        "  model3.add(Activation(\"relu\"))\n",
        "\n",
        "  # Add 7th CNN Block\n",
        "\n",
        "  model3.add(Conv2D(filters = 256, kernel_size = (2, 2), activation = 'relu', padding = 'same'))\n",
        "  model3.add(Conv2D(filters = 256, kernel_size = (2, 2), activation = 'relu', padding = 'same'))\n",
        "\n",
        "  model3.add(Flatten())\n",
        "\n",
        "  # First fully connected layer\n",
        "  #____________\n",
        "\n",
        "  model3.add(Dense(256, activation='relu'))\n",
        "  model3.add(BatchNormalization())\n",
        "  model3.add(Dense(256, activation='relu'))\n",
        "  model3.add(Dropout(0.2))\n",
        "\n",
        "  # Second fully connected layer\n",
        "  #____________\n",
        "  model3.add(Dense(256, activation='relu'))\n",
        "  model3.add(BatchNormalization())\n",
        "  model3.add(Dense(256, activation='relu'))\n",
        "  model3.add(Dropout(0.2))\n",
        "\n",
        "  model3.add(Dense(no_of_classes, activation = 'softmax'))\n",
        "\n",
        "  model3.summary()\n",
        "\n",
        "  opt = tf.keras.optimizers.Adam(learning_rate=0.000110599529645911)#0.0018876351674999116)#0.00002) #0.0000725) (learning rates obtained with Bayessian optimization and searchng in some ranges)\n",
        "  model3.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  return model3\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = create_model('params')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFIz15K7gRoA",
        "outputId": "3eaabc13-0292-4fea-dd75-0fbef92f83ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 48, 48, 64)        320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 48, 48, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 128)       32896     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 512)       262656    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 12, 12, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 12, 12, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 6, 6, 512)         1049088   \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 6, 6, 512)         1049088   \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 6, 6, 512)         1049088   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 6, 6, 256)         524544    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 6, 6, 256)         262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 6, 6, 256)         262400    \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 6, 6, 256)         262400    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 6, 6, 256)         262400    \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 6, 6, 256)         262400    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,842,500\n",
            "Trainable params: 7,840,068\n",
            "Non-trainable params: 2,432\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyc0B--hwTHS"
      },
      "source": [
        "### **Compiling and Training the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0edabf52"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "\n",
        "epochs = 15\n",
        "\n",
        "steps_per_epoch = train_set.n//train_set.batch_size\n",
        "validation_steps = validation_set.n//validation_set.batch_size\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"model3.h5\", monitor = 'val_accuracy',\n",
        "                            save_weights_only = True, model = 'max', verbose = 1)\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, min_lr = 0.0000001 , model = 'auto')\n",
        "\n",
        "callbacks = [checkpoint, reduce_lr]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from hyperopt import fmin, tpe, hp\n",
        "\n",
        "space = {\n",
        " #   'units': hp.choice('units', [64, 128, 256]),  # Can customize the choices\n",
        "    'learning_rate': hp.loguniform('learning_rate', -10, -5)  # Adjust the range as needed. Here the ranges were changed as looking for better spaces\n",
        "}\n",
        "\n",
        "def objective(params):\n",
        "  model3 = create_model(params)\n",
        "  history_model3 = model3.fit(train_set,\n",
        "        steps_per_epoch=100,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_set,\n",
        "        validation_steps=20\n",
        "        )# Writing the code to fit the model. Use train_set as the training data and validation_set as the validation data. Train the model for 100 epochs.\n",
        "  #Evaluate the model\n",
        "  val_loss = history_model3.history['val_loss'][-1]\n",
        "  return -val_loss\n"
      ],
      "metadata": {
        "id": "2kso8OsFhNhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BAYESSIAN OPTIMIZATION USING HYPEROPT FOR THE LEARNING RATE HYPERPARAMETER FOR MODEL 3**"
      ],
      "metadata": {
        "id": "HjdYp_u9t7tg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Bayesian Optimization to find the best hyperparameters\n",
        "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10)  # Adjust max_evals as needed\n",
        "print(\"Best hyperparameters:\")\n",
        "print(best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7HGZ6EBi7mu",
        "outputId": "dfe46eec-da1a-41bd-dc36-e4e1636514dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Epoch 4/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 19s - loss: 1.4692 - accuracy: 0.2292\n",
            "  2/100 [..............................] - ETA: 10s - loss: 1.4787 - accuracy: 0.2083\n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.4571 - accuracy: 0.2153 \n",
            "  4/100 [>.............................] - ETA: 10s - loss: 1.4496 - accuracy: 0.2135\n",
            "  5/100 [>.............................] - ETA: 10s - loss: 1.4419 - accuracy: 0.2208\n",
            "  6/100 [>.............................] - ETA: 10s - loss: 1.4548 - accuracy: 0.2222\n",
            "  7/100 [=>............................] - ETA: 10s - loss: 1.4502 - accuracy: 0.2173\n",
            "  8/100 [=>............................] - ETA: 10s - loss: 1.4561 - accuracy: 0.2266\n",
            "  9/100 [=>............................] - ETA: 10s - loss: 1.4659 - accuracy: 0.2130\n",
            " 10/100 [==>...........................] - ETA: 10s - loss: 1.4565 - accuracy: 0.2167\n",
            " 11/100 [==>...........................] - ETA: 9s - loss: 1.4559 - accuracy: 0.2254 \n",
            " 12/100 [==>...........................] - ETA: 9s - loss: 1.4487 - accuracy: 0.2344\n",
            " 13/100 [==>...........................] - ETA: 9s - loss: 1.4453 - accuracy: 0.2404\n",
            " 14/100 [===>..........................] - ETA: 9s - loss: 1.4410 - accuracy: 0.2455\n",
            " 15/100 [===>..........................] - ETA: 9s - loss: 1.4369 - accuracy: 0.2472\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.4363 - accuracy: 0.2513\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.4376 - accuracy: 0.2463\n",
            " 18/100 [====>.........................] - ETA: 8s - loss: 1.4369 - accuracy: 0.2488\n",
            " 19/100 [====>.........................] - ETA: 8s - loss: 1.4349 - accuracy: 0.2500\n",
            " 20/100 [=====>........................] - ETA: 8s - loss: 1.4321 - accuracy: 0.2521\n",
            " 21/100 [=====>........................] - ETA: 8s - loss: 1.4337 - accuracy: 0.2520\n",
            " 22/100 [=====>........................] - ETA: 8s - loss: 1.4359 - accuracy: 0.2509\n",
            " 23/100 [=====>........................] - ETA: 8s - loss: 1.4344 - accuracy: 0.2527\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.4321 - accuracy: 0.2561\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.4330 - accuracy: 0.2542\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.4314 - accuracy: 0.2564\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.4309 - accuracy: 0.2569\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.4315 - accuracy: 0.2560\n",
            " 29/100 [=======>......................] - ETA: 7s - loss: 1.4320 - accuracy: 0.2586\n",
            " 30/100 [========>.....................] - ETA: 7s - loss: 1.4320 - accuracy: 0.2604\n",
            " 31/100 [========>.....................] - ETA: 7s - loss: 1.4312 - accuracy: 0.2621\n",
            " 32/100 [========>.....................] - ETA: 7s - loss: 1.4318 - accuracy: 0.2643\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.4314 - accuracy: 0.2645\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.4322 - accuracy: 0.2635\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.4330 - accuracy: 0.2631\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.4343 - accuracy: 0.2598\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.4333 - accuracy: 0.2596\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.4338 - accuracy: 0.2593\n",
            " 39/100 [==========>...................] - ETA: 6s - loss: 1.4325 - accuracy: 0.2591\n",
            " 40/100 [===========>..................] - ETA: 6s - loss: 1.4316 - accuracy: 0.2573\n",
            " 41/100 [===========>..................] - ETA: 6s - loss: 1.4298 - accuracy: 0.2602\n",
            " 42/100 [===========>..................] - ETA: 6s - loss: 1.4297 - accuracy: 0.2599\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.4314 - accuracy: 0.2582\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.4327 - accuracy: 0.2571\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.4328 - accuracy: 0.2556\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.4307 - accuracy: 0.2572\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.4304 - accuracy: 0.2584\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.4291 - accuracy: 0.2582\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.4298 - accuracy: 0.2611\n",
            " 50/100 [==============>...............] - ETA: 5s - loss: 1.4307 - accuracy: 0.2621\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.4326 - accuracy: 0.2610\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.4330 - accuracy: 0.2604\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.4329 - accuracy: 0.2586\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.4315 - accuracy: 0.2608\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.4307 - accuracy: 0.2606\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.4299 - accuracy: 0.2604\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.4294 - accuracy: 0.2610\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.4295 - accuracy: 0.2604\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.4292 - accuracy: 0.2599\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.4285 - accuracy: 0.2604\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.4277 - accuracy: 0.2613\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.4272 - accuracy: 0.2611\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.4270 - accuracy: 0.2609\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.4258 - accuracy: 0.2614\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.4254 - accuracy: 0.2609\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.4258 - accuracy: 0.2607\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.4255 - accuracy: 0.2593\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.4255 - accuracy: 0.2577\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.4257 - accuracy: 0.2566\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.4261 - accuracy: 0.2562\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.4258 - accuracy: 0.2562\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.4253 - accuracy: 0.2564\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.4250 - accuracy: 0.2571\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.4248 - accuracy: 0.2576\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.4253 - accuracy: 0.2572\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.4253 - accuracy: 0.2563\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.4254 - accuracy: 0.2568\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.4255 - accuracy: 0.2580\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.4249 - accuracy: 0.2595\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.4242 - accuracy: 0.2604\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.4239 - accuracy: 0.2608\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.4235 - accuracy: 0.2612\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.4231 - accuracy: 0.2615\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.4234 - accuracy: 0.2604\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.4241 - accuracy: 0.2591\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.4241 - accuracy: 0.2582\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.4235 - accuracy: 0.2593\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.4235 - accuracy: 0.2597\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.4233 - accuracy: 0.2594\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.4226 - accuracy: 0.2595\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.4226 - accuracy: 0.2598\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.4222 - accuracy: 0.2593\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.4220 - accuracy: 0.2590\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.4220 - accuracy: 0.2584\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.4219 - accuracy: 0.2581\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.4225 - accuracy: 0.2574\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.4224 - accuracy: 0.2569\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.4219 - accuracy: 0.2574\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.4211 - accuracy: 0.2586\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.4210 - accuracy: 0.2579\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 1.4210 - accuracy: 0.2579 - val_loss: 1.3600 - val_accuracy: 0.3281\n",
            "\n",
            "Epoch 5/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 14s - loss: 1.3605 - accuracy: 0.3542\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.3983 - accuracy: 0.2500 \n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.3994 - accuracy: 0.2639\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.4208 - accuracy: 0.2500\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.4203 - accuracy: 0.2583\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.4214 - accuracy: 0.2604\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.4204 - accuracy: 0.2679\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.4132 - accuracy: 0.2734\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.4166 - accuracy: 0.2639\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.4186 - accuracy: 0.2542\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.4148 - accuracy: 0.2557\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.4168 - accuracy: 0.2587\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.4108 - accuracy: 0.2644\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.4097 - accuracy: 0.2634\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.4062 - accuracy: 0.2681\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.4031 - accuracy: 0.2734\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.4010 - accuracy: 0.2745\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3989 - accuracy: 0.2755\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.4001 - accuracy: 0.2763\n",
            " 20/100 [=====>........................] - ETA: 6s - loss: 1.3988 - accuracy: 0.2781\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.4029 - accuracy: 0.2758\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.4014 - accuracy: 0.2775\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.4028 - accuracy: 0.2772\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.4022 - accuracy: 0.2795\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.4026 - accuracy: 0.2817\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.4040 - accuracy: 0.2748\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.4034 - accuracy: 0.2755\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.4047 - accuracy: 0.2723\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.4065 - accuracy: 0.2708\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.4071 - accuracy: 0.2694\n",
            " 31/100 [========>.....................] - ETA: 5s - loss: 1.4072 - accuracy: 0.2715\n",
            " 32/100 [========>.....................] - ETA: 5s - loss: 1.4065 - accuracy: 0.2715\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.4073 - accuracy: 0.2683\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.4070 - accuracy: 0.2678\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.4073 - accuracy: 0.2679\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.4064 - accuracy: 0.2674\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.4052 - accuracy: 0.2686\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.4056 - accuracy: 0.2670\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.4051 - accuracy: 0.2666\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.4038 - accuracy: 0.2693\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.4034 - accuracy: 0.2698\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.4039 - accuracy: 0.2674\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.4013 - accuracy: 0.2718\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.4025 - accuracy: 0.2694\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.4029 - accuracy: 0.2676\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.4011 - accuracy: 0.2690\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.4007 - accuracy: 0.2686\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.4010 - accuracy: 0.2682\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3988 - accuracy: 0.2721\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3993 - accuracy: 0.2704\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3991 - accuracy: 0.2717\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3990 - accuracy: 0.2708\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3995 - accuracy: 0.2700\n",
            " 54/100 [===============>..............] - ETA: 3s - loss: 1.3990 - accuracy: 0.2708\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3994 - accuracy: 0.2689\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3991 - accuracy: 0.2686\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3997 - accuracy: 0.2668\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3994 - accuracy: 0.2662\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3985 - accuracy: 0.2677\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3986 - accuracy: 0.2660\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3984 - accuracy: 0.2643\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3992 - accuracy: 0.2634\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3994 - accuracy: 0.2629\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3999 - accuracy: 0.2637\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3990 - accuracy: 0.2660\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.3987 - accuracy: 0.2661\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3981 - accuracy: 0.2668\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3983 - accuracy: 0.2669\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3976 - accuracy: 0.2666\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3974 - accuracy: 0.2667\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3967 - accuracy: 0.2664\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3974 - accuracy: 0.2662\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3974 - accuracy: 0.2657\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3961 - accuracy: 0.2675\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3968 - accuracy: 0.2669\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3964 - accuracy: 0.2678\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3963 - accuracy: 0.2676\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3963 - accuracy: 0.2668\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3972 - accuracy: 0.2666\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3960 - accuracy: 0.2677\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3959 - accuracy: 0.2685\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3967 - accuracy: 0.2688\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3967 - accuracy: 0.2686\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3966 - accuracy: 0.2698\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3970 - accuracy: 0.2699\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3970 - accuracy: 0.2682\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3965 - accuracy: 0.2692\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3966 - accuracy: 0.2685\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3964 - accuracy: 0.2694\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3967 - accuracy: 0.2692\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3966 - accuracy: 0.2695\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3966 - accuracy: 0.2699\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3963 - accuracy: 0.2699\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3963 - accuracy: 0.2702\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3962 - accuracy: 0.2704\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3960 - accuracy: 0.2704\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3963 - accuracy: 0.2691\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3965 - accuracy: 0.2696\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3964 - accuracy: 0.2706\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3964 - accuracy: 0.2700\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 1.3964 - accuracy: 0.2700 - val_loss: 1.4621 - val_accuracy: 0.1833\n",
            "\n",
            "Epoch 6/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 15s - loss: 1.4302 - accuracy: 0.1875\n",
            "  2/100 [..............................] - ETA: 7s - loss: 1.3996 - accuracy: 0.2500 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.4096 - accuracy: 0.2431\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.4101 - accuracy: 0.2344\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.4002 - accuracy: 0.2750\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.4004 - accuracy: 0.2674\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3985 - accuracy: 0.2827\n",
            "  8/100 [=>............................] - ETA: 7s - loss: 1.3991 - accuracy: 0.2734\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.3938 - accuracy: 0.2847\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.3943 - accuracy: 0.2833\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3939 - accuracy: 0.2841\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3881 - accuracy: 0.2847\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3907 - accuracy: 0.2772\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3905 - accuracy: 0.2738\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3913 - accuracy: 0.2694\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3941 - accuracy: 0.2695\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3937 - accuracy: 0.2733\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3935 - accuracy: 0.2708\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3927 - accuracy: 0.2686\n",
            " 20/100 [=====>........................] - ETA: 6s - loss: 1.3962 - accuracy: 0.2698\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.3948 - accuracy: 0.2718\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3952 - accuracy: 0.2746\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3951 - accuracy: 0.2708\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3928 - accuracy: 0.2752\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3917 - accuracy: 0.2758\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3899 - accuracy: 0.2804\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3882 - accuracy: 0.2832\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3880 - accuracy: 0.2835\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3893 - accuracy: 0.2838\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3903 - accuracy: 0.2819\n",
            " 31/100 [========>.....................] - ETA: 5s - loss: 1.3902 - accuracy: 0.2829\n",
            " 32/100 [========>.....................] - ETA: 5s - loss: 1.3910 - accuracy: 0.2799\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3920 - accuracy: 0.2790\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3929 - accuracy: 0.2788\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3908 - accuracy: 0.2804\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3894 - accuracy: 0.2818\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3874 - accuracy: 0.2838\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3851 - accuracy: 0.2851\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3849 - accuracy: 0.2863\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3850 - accuracy: 0.2849\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3855 - accuracy: 0.2871\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3864 - accuracy: 0.2877\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3897 - accuracy: 0.2863\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3903 - accuracy: 0.2869\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3904 - accuracy: 0.2884\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3894 - accuracy: 0.2903\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3893 - accuracy: 0.2890\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3886 - accuracy: 0.2895\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3877 - accuracy: 0.2908\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3877 - accuracy: 0.2883\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3876 - accuracy: 0.2884\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3886 - accuracy: 0.2873\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3893 - accuracy: 0.2858\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3897 - accuracy: 0.2847\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3910 - accuracy: 0.2837\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3907 - accuracy: 0.2824\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3918 - accuracy: 0.2822\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3929 - accuracy: 0.2816\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3933 - accuracy: 0.2800\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3936 - accuracy: 0.2799\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3942 - accuracy: 0.2801\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3945 - accuracy: 0.2799\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3947 - accuracy: 0.2801\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3949 - accuracy: 0.2796\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3952 - accuracy: 0.2788\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3952 - accuracy: 0.2790\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3954 - accuracy: 0.2789\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3957 - accuracy: 0.2776\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3953 - accuracy: 0.2778\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3950 - accuracy: 0.2780\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3954 - accuracy: 0.2779\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3956 - accuracy: 0.2772\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3967 - accuracy: 0.2757\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3975 - accuracy: 0.2748\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3975 - accuracy: 0.2747\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3978 - accuracy: 0.2744\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3972 - accuracy: 0.2749\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3973 - accuracy: 0.2735\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3969 - accuracy: 0.2745\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3966 - accuracy: 0.2758\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3966 - accuracy: 0.2760\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3966 - accuracy: 0.2744\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3959 - accuracy: 0.2759\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3957 - accuracy: 0.2755\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3955 - accuracy: 0.2752\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3952 - accuracy: 0.2759\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3945 - accuracy: 0.2766\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3948 - accuracy: 0.2758\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3944 - accuracy: 0.2774\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3950 - accuracy: 0.2778\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3951 - accuracy: 0.2770\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3956 - accuracy: 0.2760\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3956 - accuracy: 0.2760\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3949 - accuracy: 0.2762\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3951 - accuracy: 0.2763\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3954 - accuracy: 0.2769\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3948 - accuracy: 0.2779\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3944 - accuracy: 0.2778\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3943 - accuracy: 0.2780\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3947 - accuracy: 0.2769\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 1.3947 - accuracy: 0.2769 - val_loss: 1.4104 - val_accuracy: 0.2323\n",
            "\n",
            "Epoch 7/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 13s - loss: 1.3677 - accuracy: 0.3333\n",
            "  2/100 [..............................] - ETA: 8s - loss: 1.3536 - accuracy: 0.3229 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.3567 - accuracy: 0.2917\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.3723 - accuracy: 0.2760\n",
            "  5/100 [>.............................] - ETA: 7s - loss: 1.3738 - accuracy: 0.2792\n",
            "  6/100 [>.............................] - ETA: 7s - loss: 1.3812 - accuracy: 0.2778\n",
            "  7/100 [=>............................] - ETA: 7s - loss: 1.3910 - accuracy: 0.2679\n",
            "  8/100 [=>............................] - ETA: 7s - loss: 1.3940 - accuracy: 0.2656\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.3983 - accuracy: 0.2662\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.3968 - accuracy: 0.2646\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3944 - accuracy: 0.2670\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3939 - accuracy: 0.2708\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3913 - accuracy: 0.2708\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3925 - accuracy: 0.2664\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3918 - accuracy: 0.2681\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3922 - accuracy: 0.2656\n",
            " 17/100 [====>.........................] - ETA: 6s - loss: 1.3928 - accuracy: 0.2623\n",
            " 18/100 [====>.........................] - ETA: 6s - loss: 1.3921 - accuracy: 0.2662\n",
            " 19/100 [====>.........................] - ETA: 6s - loss: 1.3922 - accuracy: 0.2643\n",
            " 20/100 [=====>........................] - ETA: 6s - loss: 1.3905 - accuracy: 0.2708\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.3907 - accuracy: 0.2738\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3915 - accuracy: 0.2708\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3932 - accuracy: 0.2736\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3923 - accuracy: 0.2734\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3934 - accuracy: 0.2733\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3924 - accuracy: 0.2756\n",
            " 27/100 [=======>......................] - ETA: 5s - loss: 1.3922 - accuracy: 0.2762\n",
            " 28/100 [=======>......................] - ETA: 5s - loss: 1.3934 - accuracy: 0.2738\n",
            " 29/100 [=======>......................] - ETA: 5s - loss: 1.3941 - accuracy: 0.2744\n",
            " 30/100 [========>.....................] - ETA: 5s - loss: 1.3953 - accuracy: 0.2722\n",
            " 31/100 [========>.....................] - ETA: 5s - loss: 1.3943 - accuracy: 0.2728\n",
            " 32/100 [========>.....................] - ETA: 5s - loss: 1.3948 - accuracy: 0.2708\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3949 - accuracy: 0.2702\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3938 - accuracy: 0.2708\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3939 - accuracy: 0.2696\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3931 - accuracy: 0.2703\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3914 - accuracy: 0.2731\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3916 - accuracy: 0.2730\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3910 - accuracy: 0.2740\n",
            " 40/100 [===========>..................] - ETA: 4s - loss: 1.3901 - accuracy: 0.2734\n",
            " 41/100 [===========>..................] - ETA: 4s - loss: 1.3903 - accuracy: 0.2724\n",
            " 42/100 [===========>..................] - ETA: 4s - loss: 1.3895 - accuracy: 0.2738\n",
            " 43/100 [===========>..................] - ETA: 4s - loss: 1.3901 - accuracy: 0.2747\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3889 - accuracy: 0.2770\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3890 - accuracy: 0.2764\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3884 - accuracy: 0.2758\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3878 - accuracy: 0.2779\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3878 - accuracy: 0.2756\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3877 - accuracy: 0.2755\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3879 - accuracy: 0.2746\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3888 - accuracy: 0.2741\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3892 - accuracy: 0.2728\n",
            " 53/100 [==============>...............] - ETA: 3s - loss: 1.3891 - accuracy: 0.2724\n",
            " 54/100 [===============>..............] - ETA: 3s - loss: 1.3895 - accuracy: 0.2708\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3889 - accuracy: 0.2723\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3886 - accuracy: 0.2719\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3887 - accuracy: 0.2701\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3893 - accuracy: 0.2698\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3884 - accuracy: 0.2712\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3884 - accuracy: 0.2715\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3892 - accuracy: 0.2698\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3902 - accuracy: 0.2681\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3898 - accuracy: 0.2695\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3893 - accuracy: 0.2692\n",
            " 65/100 [==================>...........] - ETA: 2s - loss: 1.3895 - accuracy: 0.2699\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.3896 - accuracy: 0.2705\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3896 - accuracy: 0.2708\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3896 - accuracy: 0.2708\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3895 - accuracy: 0.2699\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3897 - accuracy: 0.2693\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3898 - accuracy: 0.2688\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3901 - accuracy: 0.2679\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3901 - accuracy: 0.2671\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3901 - accuracy: 0.2672\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3898 - accuracy: 0.2672\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3897 - accuracy: 0.2664\n",
            " 77/100 [======================>.......] - ETA: 1s - loss: 1.3894 - accuracy: 0.2662\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3891 - accuracy: 0.2655\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3890 - accuracy: 0.2658\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3890 - accuracy: 0.2659\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3893 - accuracy: 0.2652\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3899 - accuracy: 0.2658\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3900 - accuracy: 0.2658\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3894 - accuracy: 0.2664\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3892 - accuracy: 0.2662\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3889 - accuracy: 0.2672\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3884 - accuracy: 0.2680\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3879 - accuracy: 0.2680\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3878 - accuracy: 0.2673\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3881 - accuracy: 0.2671\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3888 - accuracy: 0.2669\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3888 - accuracy: 0.2674\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3889 - accuracy: 0.2672\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3893 - accuracy: 0.2673\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3893 - accuracy: 0.2678\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3897 - accuracy: 0.2678\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3908 - accuracy: 0.2680\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3907 - accuracy: 0.2687\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3906 - accuracy: 0.2683\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3906 - accuracy: 0.2669\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.3906 - accuracy: 0.2669 - val_loss: 1.3854 - val_accuracy: 0.2448\n",
            "\n",
            "Epoch 8/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 17s - loss: 1.3285 - accuracy: 0.4167\n",
            "  2/100 [..............................] - ETA: 11s - loss: 1.3548 - accuracy: 0.3229\n",
            "  3/100 [..............................] - ETA: 10s - loss: 1.3570 - accuracy: 0.3403\n",
            "  4/100 [>.............................] - ETA: 10s - loss: 1.3621 - accuracy: 0.3281\n",
            "  5/100 [>.............................] - ETA: 10s - loss: 1.3640 - accuracy: 0.3292\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.3663 - accuracy: 0.3229 \n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.3713 - accuracy: 0.3244\n",
            "  8/100 [=>............................] - ETA: 9s - loss: 1.3707 - accuracy: 0.3229\n",
            "  9/100 [=>............................] - ETA: 9s - loss: 1.3678 - accuracy: 0.3264\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3705 - accuracy: 0.3167\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3720 - accuracy: 0.3182\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.3743 - accuracy: 0.3150\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.3755 - accuracy: 0.3100\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.3776 - accuracy: 0.3026\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.3805 - accuracy: 0.3004\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.3802 - accuracy: 0.2946\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.3823 - accuracy: 0.2882\n",
            " 18/100 [====>.........................] - ETA: 8s - loss: 1.3813 - accuracy: 0.2884\n",
            " 19/100 [====>.........................] - ETA: 8s - loss: 1.3834 - accuracy: 0.2863\n",
            " 20/100 [=====>........................] - ETA: 8s - loss: 1.3821 - accuracy: 0.2898\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3812 - accuracy: 0.2919\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3824 - accuracy: 0.2880\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3836 - accuracy: 0.2855\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3850 - accuracy: 0.2831\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3836 - accuracy: 0.2885\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.3862 - accuracy: 0.2829\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.3864 - accuracy: 0.2817\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.3865 - accuracy: 0.2798\n",
            " 29/100 [=======>......................] - ETA: 7s - loss: 1.3858 - accuracy: 0.2795\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3837 - accuracy: 0.2834\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3836 - accuracy: 0.2837\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3837 - accuracy: 0.2879\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3834 - accuracy: 0.2861\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3832 - accuracy: 0.2844\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3841 - accuracy: 0.2804\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3857 - accuracy: 0.2784\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.3847 - accuracy: 0.2805\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.3832 - accuracy: 0.2852\n",
            " 39/100 [==========>...................] - ETA: 6s - loss: 1.3843 - accuracy: 0.2837\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3845 - accuracy: 0.2823\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3851 - accuracy: 0.2780\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3848 - accuracy: 0.2773\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3842 - accuracy: 0.2781\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3843 - accuracy: 0.2770\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3848 - accuracy: 0.2769\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3841 - accuracy: 0.2772\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3840 - accuracy: 0.2784\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.3837 - accuracy: 0.2782\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.3848 - accuracy: 0.2751\n",
            " 50/100 [==============>...............] - ETA: 5s - loss: 1.3852 - accuracy: 0.2742\n",
            " 51/100 [==============>...............] - ETA: 5s - loss: 1.3853 - accuracy: 0.2749\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3850 - accuracy: 0.2757\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3849 - accuracy: 0.2767\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3847 - accuracy: 0.2786\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3842 - accuracy: 0.2788\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3844 - accuracy: 0.2764\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3843 - accuracy: 0.2771\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.3846 - accuracy: 0.2770\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.3845 - accuracy: 0.2783\n",
            " 60/100 [=================>............] - ETA: 4s - loss: 1.3845 - accuracy: 0.2771\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3845 - accuracy: 0.2770\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3842 - accuracy: 0.2769\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3846 - accuracy: 0.2751\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3843 - accuracy: 0.2747\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3842 - accuracy: 0.2747\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3839 - accuracy: 0.2753\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3835 - accuracy: 0.2752\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3839 - accuracy: 0.2745\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.3839 - accuracy: 0.2742\n",
            " 70/100 [====================>.........] - ETA: 3s - loss: 1.3841 - accuracy: 0.2738\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3841 - accuracy: 0.2738\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3836 - accuracy: 0.2743\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3836 - accuracy: 0.2740\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3839 - accuracy: 0.2745\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3836 - accuracy: 0.2736\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3830 - accuracy: 0.2766\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3825 - accuracy: 0.2768\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3826 - accuracy: 0.2770\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3829 - accuracy: 0.2780\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3830 - accuracy: 0.2784\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3823 - accuracy: 0.2796\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3825 - accuracy: 0.2787\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3819 - accuracy: 0.2794\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3813 - accuracy: 0.2803\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3817 - accuracy: 0.2794\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3826 - accuracy: 0.2786\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3825 - accuracy: 0.2780\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3830 - accuracy: 0.2772\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3829 - accuracy: 0.2776\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3835 - accuracy: 0.2762\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3839 - accuracy: 0.2761\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3836 - accuracy: 0.2772\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3839 - accuracy: 0.2762\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3840 - accuracy: 0.2753\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3839 - accuracy: 0.2757\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3840 - accuracy: 0.2752\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3843 - accuracy: 0.2745\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3844 - accuracy: 0.2738\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3841 - accuracy: 0.2744\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3845 - accuracy: 0.2740\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 1.3845 - accuracy: 0.2740 - val_loss: 1.3872 - val_accuracy: 0.2698\n",
            "\n",
            "Epoch 9/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 14s - loss: 1.3835 - accuracy: 0.2917\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.3905 - accuracy: 0.2917 \n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.3784 - accuracy: 0.2778\n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.3797 - accuracy: 0.2656\n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.3815 - accuracy: 0.2917\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3842 - accuracy: 0.2917\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3821 - accuracy: 0.2917\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3851 - accuracy: 0.2760\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3816 - accuracy: 0.2824\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3807 - accuracy: 0.2812\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3810 - accuracy: 0.2784\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3814 - accuracy: 0.2795\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3803 - accuracy: 0.2804\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3811 - accuracy: 0.2783\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3844 - accuracy: 0.2736\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3870 - accuracy: 0.2643\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3874 - accuracy: 0.2659\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3876 - accuracy: 0.2662\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3858 - accuracy: 0.2774\n",
            " 20/100 [=====>........................] - ETA: 6s - loss: 1.3885 - accuracy: 0.2750\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.3876 - accuracy: 0.2728\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3863 - accuracy: 0.2718\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3874 - accuracy: 0.2717\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3881 - accuracy: 0.2717\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3872 - accuracy: 0.2742\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3881 - accuracy: 0.2700\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3873 - accuracy: 0.2662\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3860 - accuracy: 0.2738\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3866 - accuracy: 0.2730\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3872 - accuracy: 0.2708\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3865 - accuracy: 0.2742\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3865 - accuracy: 0.2773\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3862 - accuracy: 0.2778\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3865 - accuracy: 0.2770\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3865 - accuracy: 0.2750\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3864 - accuracy: 0.2760\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3865 - accuracy: 0.2765\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3866 - accuracy: 0.2752\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3875 - accuracy: 0.2740\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3879 - accuracy: 0.2719\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3881 - accuracy: 0.2708\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3870 - accuracy: 0.2713\n",
            " 43/100 [===========>..................] - ETA: 4s - loss: 1.3871 - accuracy: 0.2733\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3877 - accuracy: 0.2727\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3875 - accuracy: 0.2713\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3875 - accuracy: 0.2704\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3883 - accuracy: 0.2691\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3883 - accuracy: 0.2687\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3876 - accuracy: 0.2708\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3876 - accuracy: 0.2704\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3874 - accuracy: 0.2692\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3869 - accuracy: 0.2704\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3865 - accuracy: 0.2708\n",
            " 54/100 [===============>..............] - ETA: 3s - loss: 1.3863 - accuracy: 0.2716\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3862 - accuracy: 0.2701\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3856 - accuracy: 0.2708\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3857 - accuracy: 0.2697\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3856 - accuracy: 0.2694\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3852 - accuracy: 0.2698\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3845 - accuracy: 0.2701\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3845 - accuracy: 0.2708\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3842 - accuracy: 0.2702\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3842 - accuracy: 0.2692\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3838 - accuracy: 0.2705\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3835 - accuracy: 0.2702\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.3838 - accuracy: 0.2696\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3833 - accuracy: 0.2680\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3832 - accuracy: 0.2675\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3828 - accuracy: 0.2681\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3835 - accuracy: 0.2688\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3832 - accuracy: 0.2702\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3833 - accuracy: 0.2703\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3833 - accuracy: 0.2708\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3829 - accuracy: 0.2708\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3830 - accuracy: 0.2697\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3832 - accuracy: 0.2689\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3831 - accuracy: 0.2689\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3834 - accuracy: 0.2692\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3833 - accuracy: 0.2693\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3825 - accuracy: 0.2703\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3822 - accuracy: 0.2721\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3824 - accuracy: 0.2724\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3825 - accuracy: 0.2726\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3822 - accuracy: 0.2733\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3825 - accuracy: 0.2740\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3826 - accuracy: 0.2735\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3829 - accuracy: 0.2732\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3831 - accuracy: 0.2732\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3833 - accuracy: 0.2722\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3831 - accuracy: 0.2725\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3830 - accuracy: 0.2717\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3834 - accuracy: 0.2702\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3837 - accuracy: 0.2697\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3837 - accuracy: 0.2706\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3836 - accuracy: 0.2704\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3835 - accuracy: 0.2708\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3834 - accuracy: 0.2723\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3834 - accuracy: 0.2717\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3834 - accuracy: 0.2715\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3837 - accuracy: 0.2710\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.3837 - accuracy: 0.2710 - val_loss: 1.3621 - val_accuracy: 0.2896\n",
            "\n",
            "Epoch 10/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 15s - loss: 1.3458 - accuracy: 0.3333\n",
            "  2/100 [..............................] - ETA: 11s - loss: 1.3660 - accuracy: 0.3125\n",
            "  3/100 [..............................] - ETA: 10s - loss: 1.3676 - accuracy: 0.3125\n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.3699 - accuracy: 0.3177 \n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.3697 - accuracy: 0.3125\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.3776 - accuracy: 0.3090\n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.3766 - accuracy: 0.3095\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3774 - accuracy: 0.3047\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3793 - accuracy: 0.3079\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3801 - accuracy: 0.3021\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3793 - accuracy: 0.2955\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.3811 - accuracy: 0.2899\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.3801 - accuracy: 0.2853\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.3802 - accuracy: 0.2917\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.3806 - accuracy: 0.2931\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.3806 - accuracy: 0.2891\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.3818 - accuracy: 0.2892\n",
            " 18/100 [====>.........................] - ETA: 8s - loss: 1.3819 - accuracy: 0.2894\n",
            " 19/100 [====>.........................] - ETA: 8s - loss: 1.3833 - accuracy: 0.2917\n",
            " 20/100 [=====>........................] - ETA: 8s - loss: 1.3813 - accuracy: 0.2958\n",
            " 21/100 [=====>........................] - ETA: 8s - loss: 1.3799 - accuracy: 0.2986\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3804 - accuracy: 0.2973\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3805 - accuracy: 0.2953\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3809 - accuracy: 0.2925\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3802 - accuracy: 0.2950\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.3797 - accuracy: 0.2973\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.3788 - accuracy: 0.3017\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.3763 - accuracy: 0.3073\n",
            " 29/100 [=======>......................] - ETA: 7s - loss: 1.3768 - accuracy: 0.3068\n",
            " 30/100 [========>.....................] - ETA: 7s - loss: 1.3755 - accuracy: 0.3090\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3755 - accuracy: 0.3038\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3763 - accuracy: 0.3014\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3780 - accuracy: 0.2986\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3782 - accuracy: 0.2996\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3778 - accuracy: 0.2964\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3801 - accuracy: 0.2946\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.3812 - accuracy: 0.2911\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.3822 - accuracy: 0.2895\n",
            " 39/100 [==========>...................] - ETA: 6s - loss: 1.3819 - accuracy: 0.2895\n",
            " 40/100 [===========>..................] - ETA: 6s - loss: 1.3808 - accuracy: 0.2917\n",
            " 41/100 [===========>..................] - ETA: 6s - loss: 1.3804 - accuracy: 0.2912\n",
            " 42/100 [===========>..................] - ETA: 6s - loss: 1.3796 - accuracy: 0.2907\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3804 - accuracy: 0.2892\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3794 - accuracy: 0.2912\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3787 - accuracy: 0.2921\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3783 - accuracy: 0.2939\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3789 - accuracy: 0.2926\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.3799 - accuracy: 0.2912\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.3807 - accuracy: 0.2883\n",
            " 50/100 [==============>...............] - ETA: 5s - loss: 1.3808 - accuracy: 0.2887\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3810 - accuracy: 0.2892\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3805 - accuracy: 0.2917\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3804 - accuracy: 0.2901\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3809 - accuracy: 0.2874\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3812 - accuracy: 0.2856\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3815 - accuracy: 0.2846\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3812 - accuracy: 0.2840\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.3809 - accuracy: 0.2834\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.3814 - accuracy: 0.2843\n",
            " 60/100 [=================>............] - ETA: 4s - loss: 1.3810 - accuracy: 0.2854\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3812 - accuracy: 0.2838\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3818 - accuracy: 0.2833\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3816 - accuracy: 0.2827\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3814 - accuracy: 0.2829\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3815 - accuracy: 0.2837\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3815 - accuracy: 0.2825\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3813 - accuracy: 0.2826\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3816 - accuracy: 0.2816\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.3812 - accuracy: 0.2817\n",
            " 70/100 [====================>.........] - ETA: 3s - loss: 1.3811 - accuracy: 0.2815\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3812 - accuracy: 0.2826\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3811 - accuracy: 0.2830\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3809 - accuracy: 0.2820\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3808 - accuracy: 0.2812\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3808 - accuracy: 0.2808\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3807 - accuracy: 0.2818\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3810 - accuracy: 0.2817\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3809 - accuracy: 0.2815\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3810 - accuracy: 0.2801\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3805 - accuracy: 0.2812\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3808 - accuracy: 0.2811\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3809 - accuracy: 0.2797\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3808 - accuracy: 0.2801\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3812 - accuracy: 0.2793\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3815 - accuracy: 0.2782\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3813 - accuracy: 0.2793\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3813 - accuracy: 0.2787\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3812 - accuracy: 0.2791\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3807 - accuracy: 0.2797\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3812 - accuracy: 0.2794\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3806 - accuracy: 0.2802\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3806 - accuracy: 0.2801\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3803 - accuracy: 0.2807\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3802 - accuracy: 0.2810\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3802 - accuracy: 0.2811\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3806 - accuracy: 0.2804\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3804 - accuracy: 0.2814\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3803 - accuracy: 0.2810\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3803 - accuracy: 0.2814\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3800 - accuracy: 0.2810\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 1.3800 - accuracy: 0.2810 - val_loss: 1.3913 - val_accuracy: 0.2396\n",
            "\n",
            "Epoch 11/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 19s - loss: 1.3753 - accuracy: 0.2917\n",
            "  2/100 [..............................] - ETA: 10s - loss: 1.4023 - accuracy: 0.2500\n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.4040 - accuracy: 0.2639 \n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.3976 - accuracy: 0.2656\n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.3989 - accuracy: 0.2500\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.3947 - accuracy: 0.2674\n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.3905 - accuracy: 0.2798\n",
            "  8/100 [=>............................] - ETA: 9s - loss: 1.3891 - accuracy: 0.2865\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3886 - accuracy: 0.2755\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3886 - accuracy: 0.2750\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3862 - accuracy: 0.2784\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.3873 - accuracy: 0.2760\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.3880 - accuracy: 0.2708\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.3890 - accuracy: 0.2664\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.3888 - accuracy: 0.2625\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.3884 - accuracy: 0.2630\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.3893 - accuracy: 0.2561\n",
            " 18/100 [====>.........................] - ETA: 8s - loss: 1.3892 - accuracy: 0.2593\n",
            " 19/100 [====>.........................] - ETA: 8s - loss: 1.3882 - accuracy: 0.2621\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3887 - accuracy: 0.2656\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3886 - accuracy: 0.2639\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3889 - accuracy: 0.2595\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3890 - accuracy: 0.2600\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3891 - accuracy: 0.2622\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3897 - accuracy: 0.2600\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.3894 - accuracy: 0.2580\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3888 - accuracy: 0.2562\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3888 - accuracy: 0.2537\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3888 - accuracy: 0.2557\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3890 - accuracy: 0.2528\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3882 - accuracy: 0.2560\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3874 - accuracy: 0.2591\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3867 - accuracy: 0.2595\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3864 - accuracy: 0.2592\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3853 - accuracy: 0.2631\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3858 - accuracy: 0.2622\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3858 - accuracy: 0.2630\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3855 - accuracy: 0.2610\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3857 - accuracy: 0.2607\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3850 - accuracy: 0.2594\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3840 - accuracy: 0.2612\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3837 - accuracy: 0.2619\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3837 - accuracy: 0.2611\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3828 - accuracy: 0.2623\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3845 - accuracy: 0.2616\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3843 - accuracy: 0.2627\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3844 - accuracy: 0.2606\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3839 - accuracy: 0.2595\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3842 - accuracy: 0.2594\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3841 - accuracy: 0.2579\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3831 - accuracy: 0.2569\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3828 - accuracy: 0.2572\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3826 - accuracy: 0.2586\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3822 - accuracy: 0.2600\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3813 - accuracy: 0.2598\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3807 - accuracy: 0.2604\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3808 - accuracy: 0.2606\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3820 - accuracy: 0.2608\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3813 - accuracy: 0.2620\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3810 - accuracy: 0.2611\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3816 - accuracy: 0.2609\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3817 - accuracy: 0.2611\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3815 - accuracy: 0.2606\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3823 - accuracy: 0.2604\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3823 - accuracy: 0.2603\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3823 - accuracy: 0.2607\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3825 - accuracy: 0.2603\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3828 - accuracy: 0.2601\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3824 - accuracy: 0.2594\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3821 - accuracy: 0.2610\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3824 - accuracy: 0.2594\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3825 - accuracy: 0.2590\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3827 - accuracy: 0.2588\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3825 - accuracy: 0.2587\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3826 - accuracy: 0.2575\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3827 - accuracy: 0.2571\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3829 - accuracy: 0.2568\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3827 - accuracy: 0.2583\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3824 - accuracy: 0.2603\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3823 - accuracy: 0.2604\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3819 - accuracy: 0.2613\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3820 - accuracy: 0.2604\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3820 - accuracy: 0.2603\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3819 - accuracy: 0.2604\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3821 - accuracy: 0.2600\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3820 - accuracy: 0.2604\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3816 - accuracy: 0.2605\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3817 - accuracy: 0.2611\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3827 - accuracy: 0.2605\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3827 - accuracy: 0.2609\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3829 - accuracy: 0.2608\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3826 - accuracy: 0.2615\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3824 - accuracy: 0.2605\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3822 - accuracy: 0.2613\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3826 - accuracy: 0.2614\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3824 - accuracy: 0.2619\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3823 - accuracy: 0.2627\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3824 - accuracy: 0.2634\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3823 - accuracy: 0.2630\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3824 - accuracy: 0.2635\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 1.3824 - accuracy: 0.2635 - val_loss: 1.3662 - val_accuracy: 0.2896\n",
            "\n",
            "Epoch 12/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 18s - loss: 1.3898 - accuracy: 0.1875\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.3851 - accuracy: 0.2083 \n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.3858 - accuracy: 0.2500\n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.3883 - accuracy: 0.2240\n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.3850 - accuracy: 0.2292\n",
            "  6/100 [>.............................] - ETA: 10s - loss: 1.3825 - accuracy: 0.2465\n",
            "  7/100 [=>............................] - ETA: 10s - loss: 1.3811 - accuracy: 0.2589\n",
            "  8/100 [=>............................] - ETA: 9s - loss: 1.3843 - accuracy: 0.2526 \n",
            "  9/100 [=>............................] - ETA: 9s - loss: 1.3829 - accuracy: 0.2616\n",
            " 10/100 [==>...........................] - ETA: 9s - loss: 1.3830 - accuracy: 0.2604\n",
            " 11/100 [==>...........................] - ETA: 9s - loss: 1.3827 - accuracy: 0.2595\n",
            " 12/100 [==>...........................] - ETA: 9s - loss: 1.3843 - accuracy: 0.2500\n",
            " 13/100 [==>...........................] - ETA: 9s - loss: 1.3856 - accuracy: 0.2516\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.3864 - accuracy: 0.2455\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.3878 - accuracy: 0.2347\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.3879 - accuracy: 0.2370\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.3873 - accuracy: 0.2390\n",
            " 18/100 [====>.........................] - ETA: 8s - loss: 1.3868 - accuracy: 0.2384\n",
            " 19/100 [====>.........................] - ETA: 8s - loss: 1.3864 - accuracy: 0.2357\n",
            " 20/100 [=====>........................] - ETA: 8s - loss: 1.3874 - accuracy: 0.2354\n",
            " 21/100 [=====>........................] - ETA: 8s - loss: 1.3877 - accuracy: 0.2331\n",
            " 22/100 [=====>........................] - ETA: 8s - loss: 1.3872 - accuracy: 0.2348\n",
            " 23/100 [=====>........................] - ETA: 8s - loss: 1.3869 - accuracy: 0.2346\n",
            " 24/100 [======>.......................] - ETA: 8s - loss: 1.3868 - accuracy: 0.2335\n",
            " 25/100 [======>.......................] - ETA: 8s - loss: 1.3867 - accuracy: 0.2342\n",
            " 26/100 [======>.......................] - ETA: 8s - loss: 1.3855 - accuracy: 0.2372\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.3853 - accuracy: 0.2415\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.3845 - accuracy: 0.2426\n",
            " 29/100 [=======>......................] - ETA: 7s - loss: 1.3842 - accuracy: 0.2471\n",
            " 30/100 [========>.....................] - ETA: 7s - loss: 1.3829 - accuracy: 0.2514\n",
            " 31/100 [========>.....................] - ETA: 7s - loss: 1.3827 - accuracy: 0.2500\n",
            " 32/100 [========>.....................] - ETA: 7s - loss: 1.3828 - accuracy: 0.2526\n",
            " 33/100 [========>.....................] - ETA: 7s - loss: 1.3838 - accuracy: 0.2532\n",
            " 34/100 [=========>....................] - ETA: 7s - loss: 1.3825 - accuracy: 0.2586\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3825 - accuracy: 0.2583\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3825 - accuracy: 0.2575\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.3827 - accuracy: 0.2568\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.3825 - accuracy: 0.2621\n",
            " 39/100 [==========>...................] - ETA: 6s - loss: 1.3815 - accuracy: 0.2644\n",
            " 40/100 [===========>..................] - ETA: 6s - loss: 1.3803 - accuracy: 0.2667\n",
            " 41/100 [===========>..................] - ETA: 6s - loss: 1.3805 - accuracy: 0.2652\n",
            " 42/100 [===========>..................] - ETA: 6s - loss: 1.3804 - accuracy: 0.2649\n",
            " 43/100 [===========>..................] - ETA: 6s - loss: 1.3811 - accuracy: 0.2645\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3806 - accuracy: 0.2642\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3808 - accuracy: 0.2634\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3802 - accuracy: 0.2659\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3789 - accuracy: 0.2673\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.3790 - accuracy: 0.2691\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.3780 - accuracy: 0.2687\n",
            " 50/100 [==============>...............] - ETA: 5s - loss: 1.3775 - accuracy: 0.2696\n",
            " 51/100 [==============>...............] - ETA: 5s - loss: 1.3783 - accuracy: 0.2692\n",
            " 52/100 [==============>...............] - ETA: 5s - loss: 1.3783 - accuracy: 0.2692\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3785 - accuracy: 0.2689\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3786 - accuracy: 0.2689\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3785 - accuracy: 0.2712\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3791 - accuracy: 0.2701\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3791 - accuracy: 0.2712\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.3793 - accuracy: 0.2712\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.3793 - accuracy: 0.2712\n",
            " 60/100 [=================>............] - ETA: 4s - loss: 1.3792 - accuracy: 0.2722\n",
            " 61/100 [=================>............] - ETA: 4s - loss: 1.3787 - accuracy: 0.2732\n",
            " 62/100 [=================>............] - ETA: 4s - loss: 1.3789 - accuracy: 0.2718\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3787 - accuracy: 0.2728\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3786 - accuracy: 0.2734\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3784 - accuracy: 0.2737\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3781 - accuracy: 0.2749\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3780 - accuracy: 0.2746\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3779 - accuracy: 0.2745\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.3781 - accuracy: 0.2732\n",
            " 70/100 [====================>.........] - ETA: 3s - loss: 1.3778 - accuracy: 0.2747\n",
            " 71/100 [====================>.........] - ETA: 3s - loss: 1.3775 - accuracy: 0.2767\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3771 - accuracy: 0.2760\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3770 - accuracy: 0.2763\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3781 - accuracy: 0.2748\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3781 - accuracy: 0.2744\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3780 - accuracy: 0.2741\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3783 - accuracy: 0.2752\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3780 - accuracy: 0.2762\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3780 - accuracy: 0.2764\n",
            " 80/100 [=======================>......] - ETA: 2s - loss: 1.3777 - accuracy: 0.2758\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3782 - accuracy: 0.2760\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3783 - accuracy: 0.2759\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3787 - accuracy: 0.2751\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3785 - accuracy: 0.2760\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3790 - accuracy: 0.2760\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3790 - accuracy: 0.2762\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3791 - accuracy: 0.2761\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3791 - accuracy: 0.2763\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3789 - accuracy: 0.2765\n",
            " 90/100 [==========================>...] - ETA: 1s - loss: 1.3790 - accuracy: 0.2769\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3793 - accuracy: 0.2756\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3798 - accuracy: 0.2742\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3795 - accuracy: 0.2749\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3793 - accuracy: 0.2744\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3791 - accuracy: 0.2746\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3789 - accuracy: 0.2756\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3788 - accuracy: 0.2758\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3792 - accuracy: 0.2747\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3795 - accuracy: 0.2740\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3795 - accuracy: 0.2742\n",
            "100/100 [==============================] - 12s 115ms/step - loss: 1.3795 - accuracy: 0.2742 - val_loss: 1.3537 - val_accuracy: 0.3719\n",
            "\n",
            "Epoch 13/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 17s - loss: 1.3915 - accuracy: 0.3125\n",
            "  2/100 [..............................] - ETA: 10s - loss: 1.3936 - accuracy: 0.2917\n",
            "  3/100 [..............................] - ETA: 10s - loss: 1.3965 - accuracy: 0.2708\n",
            "  4/100 [>.............................] - ETA: 10s - loss: 1.3914 - accuracy: 0.2812\n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.3869 - accuracy: 0.2875 \n",
            "  6/100 [>.............................] - ETA: 10s - loss: 1.3817 - accuracy: 0.2917\n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.3785 - accuracy: 0.2946 \n",
            "  8/100 [=>............................] - ETA: 9s - loss: 1.3753 - accuracy: 0.2943\n",
            "  9/100 [=>............................] - ETA: 9s - loss: 1.3766 - accuracy: 0.2917\n",
            " 10/100 [==>...........................] - ETA: 9s - loss: 1.3825 - accuracy: 0.2896\n",
            " 11/100 [==>...........................] - ETA: 9s - loss: 1.3835 - accuracy: 0.2879\n",
            " 12/100 [==>...........................] - ETA: 9s - loss: 1.3825 - accuracy: 0.2899\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.3828 - accuracy: 0.2869\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.3873 - accuracy: 0.2827\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.3860 - accuracy: 0.2833\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.3870 - accuracy: 0.2839\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.3872 - accuracy: 0.2806\n",
            " 18/100 [====>.........................] - ETA: 8s - loss: 1.3868 - accuracy: 0.2755\n",
            " 19/100 [====>.........................] - ETA: 8s - loss: 1.3857 - accuracy: 0.2752\n",
            " 20/100 [=====>........................] - ETA: 8s - loss: 1.3850 - accuracy: 0.2760\n",
            " 21/100 [=====>........................] - ETA: 8s - loss: 1.3832 - accuracy: 0.2798\n",
            " 22/100 [=====>........................] - ETA: 8s - loss: 1.3821 - accuracy: 0.2794\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3828 - accuracy: 0.2763\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3813 - accuracy: 0.2805\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3798 - accuracy: 0.2801\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.3803 - accuracy: 0.2813\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.3789 - accuracy: 0.2825\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.3788 - accuracy: 0.2866\n",
            " 29/100 [=======>......................] - ETA: 7s - loss: 1.3798 - accuracy: 0.2846\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3810 - accuracy: 0.2827\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3797 - accuracy: 0.2857\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3800 - accuracy: 0.2846\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3786 - accuracy: 0.2867\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3780 - accuracy: 0.2862\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3783 - accuracy: 0.2864\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3773 - accuracy: 0.2860\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.3802 - accuracy: 0.2816\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.3809 - accuracy: 0.2824\n",
            " 39/100 [==========>...................] - ETA: 6s - loss: 1.3819 - accuracy: 0.2810\n",
            " 40/100 [===========>..................] - ETA: 6s - loss: 1.3826 - accuracy: 0.2803\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3821 - accuracy: 0.2805\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3820 - accuracy: 0.2798\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3829 - accuracy: 0.2781\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3832 - accuracy: 0.2761\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3832 - accuracy: 0.2764\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3831 - accuracy: 0.2749\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3824 - accuracy: 0.2753\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.3821 - accuracy: 0.2769\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.3813 - accuracy: 0.2781\n",
            " 50/100 [==============>...............] - ETA: 5s - loss: 1.3819 - accuracy: 0.2775\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3822 - accuracy: 0.2766\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3812 - accuracy: 0.2793\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3805 - accuracy: 0.2787\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3802 - accuracy: 0.2809\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3804 - accuracy: 0.2815\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3796 - accuracy: 0.2832\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3793 - accuracy: 0.2833\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.3795 - accuracy: 0.2816\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.3793 - accuracy: 0.2818\n",
            " 60/100 [=================>............] - ETA: 4s - loss: 1.3796 - accuracy: 0.2806\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3794 - accuracy: 0.2804\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3801 - accuracy: 0.2806\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3802 - accuracy: 0.2801\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3811 - accuracy: 0.2790\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3811 - accuracy: 0.2795\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3817 - accuracy: 0.2794\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3815 - accuracy: 0.2786\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3818 - accuracy: 0.2788\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.3819 - accuracy: 0.2790\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3824 - accuracy: 0.2786\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3819 - accuracy: 0.2794\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3814 - accuracy: 0.2798\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3811 - accuracy: 0.2803\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3812 - accuracy: 0.2787\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3813 - accuracy: 0.2784\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3811 - accuracy: 0.2785\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3810 - accuracy: 0.2795\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3807 - accuracy: 0.2810\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3806 - accuracy: 0.2814\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3804 - accuracy: 0.2818\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3800 - accuracy: 0.2817\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3797 - accuracy: 0.2815\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3798 - accuracy: 0.2817\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3796 - accuracy: 0.2815\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3799 - accuracy: 0.2816\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3802 - accuracy: 0.2822\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3809 - accuracy: 0.2819\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3810 - accuracy: 0.2808\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3809 - accuracy: 0.2802\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3815 - accuracy: 0.2794\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3815 - accuracy: 0.2786\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3818 - accuracy: 0.2776\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3814 - accuracy: 0.2769\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3815 - accuracy: 0.2768\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3812 - accuracy: 0.2779\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3813 - accuracy: 0.2776\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3814 - accuracy: 0.2773\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3814 - accuracy: 0.2770\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3810 - accuracy: 0.2769\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3806 - accuracy: 0.2777\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 1.3806 - accuracy: 0.2777 - val_loss: 1.3578 - val_accuracy: 0.3354\n",
            "\n",
            "Epoch 14/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 16s - loss: 1.3645 - accuracy: 0.2083\n",
            "  2/100 [..............................] - ETA: 8s - loss: 1.3636 - accuracy: 0.2188 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.3666 - accuracy: 0.2500\n",
            "  4/100 [>.............................] - ETA: 7s - loss: 1.3699 - accuracy: 0.2552\n",
            "  5/100 [>.............................] - ETA: 7s - loss: 1.3736 - accuracy: 0.2667\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3719 - accuracy: 0.2847\n",
            "  7/100 [=>............................] - ETA: 7s - loss: 1.3808 - accuracy: 0.2768\n",
            "  8/100 [=>............................] - ETA: 7s - loss: 1.3859 - accuracy: 0.2604\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.3818 - accuracy: 0.2616\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.3777 - accuracy: 0.2792\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3750 - accuracy: 0.2784\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3783 - accuracy: 0.2778\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3805 - accuracy: 0.2708\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3768 - accuracy: 0.2812\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3795 - accuracy: 0.2792\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3783 - accuracy: 0.2812\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3761 - accuracy: 0.2831\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3754 - accuracy: 0.2836\n",
            " 19/100 [====>.........................] - ETA: 6s - loss: 1.3758 - accuracy: 0.2763\n",
            " 20/100 [=====>........................] - ETA: 6s - loss: 1.3764 - accuracy: 0.2740\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.3756 - accuracy: 0.2698\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3781 - accuracy: 0.2689\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3778 - accuracy: 0.2736\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3758 - accuracy: 0.2769\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3766 - accuracy: 0.2750\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3744 - accuracy: 0.2780\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3738 - accuracy: 0.2801\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3732 - accuracy: 0.2820\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3733 - accuracy: 0.2823\n",
            " 30/100 [========>.....................] - ETA: 5s - loss: 1.3736 - accuracy: 0.2806\n",
            " 31/100 [========>.....................] - ETA: 5s - loss: 1.3731 - accuracy: 0.2849\n",
            " 32/100 [========>.....................] - ETA: 5s - loss: 1.3736 - accuracy: 0.2858\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3740 - accuracy: 0.2854\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3747 - accuracy: 0.2843\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3741 - accuracy: 0.2804\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3740 - accuracy: 0.2812\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3764 - accuracy: 0.2810\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3757 - accuracy: 0.2802\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3767 - accuracy: 0.2794\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3771 - accuracy: 0.2792\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3766 - accuracy: 0.2790\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3774 - accuracy: 0.2763\n",
            " 43/100 [===========>..................] - ETA: 4s - loss: 1.3772 - accuracy: 0.2771\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3781 - accuracy: 0.2751\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3785 - accuracy: 0.2745\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3786 - accuracy: 0.2731\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3789 - accuracy: 0.2730\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3787 - accuracy: 0.2747\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3786 - accuracy: 0.2751\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3787 - accuracy: 0.2742\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3791 - accuracy: 0.2721\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3789 - accuracy: 0.2732\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3789 - accuracy: 0.2728\n",
            " 54/100 [===============>..............] - ETA: 3s - loss: 1.3792 - accuracy: 0.2716\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3797 - accuracy: 0.2693\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3805 - accuracy: 0.2693\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3803 - accuracy: 0.2690\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3800 - accuracy: 0.2698\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3798 - accuracy: 0.2694\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3803 - accuracy: 0.2698\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3803 - accuracy: 0.2708\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3799 - accuracy: 0.2712\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3800 - accuracy: 0.2705\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3799 - accuracy: 0.2715\n",
            " 65/100 [==================>...........] - ETA: 2s - loss: 1.3800 - accuracy: 0.2718\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.3793 - accuracy: 0.2727\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3791 - accuracy: 0.2727\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3789 - accuracy: 0.2708\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3786 - accuracy: 0.2717\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3789 - accuracy: 0.2714\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3793 - accuracy: 0.2720\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3800 - accuracy: 0.2714\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3794 - accuracy: 0.2731\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3783 - accuracy: 0.2745\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3794 - accuracy: 0.2736\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3791 - accuracy: 0.2749\n",
            " 77/100 [======================>.......] - ETA: 1s - loss: 1.3794 - accuracy: 0.2744\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3790 - accuracy: 0.2738\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3793 - accuracy: 0.2735\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3792 - accuracy: 0.2734\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3791 - accuracy: 0.2739\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3790 - accuracy: 0.2736\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3790 - accuracy: 0.2738\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3795 - accuracy: 0.2728\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3795 - accuracy: 0.2728\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3792 - accuracy: 0.2728\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3793 - accuracy: 0.2727\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3791 - accuracy: 0.2732\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3789 - accuracy: 0.2736\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3789 - accuracy: 0.2734\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3793 - accuracy: 0.2727\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3791 - accuracy: 0.2729\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3792 - accuracy: 0.2728\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3789 - accuracy: 0.2730\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3788 - accuracy: 0.2728\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3786 - accuracy: 0.2739\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3786 - accuracy: 0.2741\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3786 - accuracy: 0.2738\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3782 - accuracy: 0.2755\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3780 - accuracy: 0.2752\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 1.3780 - accuracy: 0.2752 - val_loss: 1.3802 - val_accuracy: 0.2219\n",
            "\n",
            "Epoch 15/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 13s - loss: 1.3535 - accuracy: 0.3333\n",
            "  2/100 [..............................] - ETA: 11s - loss: 1.3647 - accuracy: 0.2812\n",
            "  3/100 [..............................] - ETA: 10s - loss: 1.3638 - accuracy: 0.2569\n",
            "  4/100 [>.............................] - ETA: 10s - loss: 1.3727 - accuracy: 0.2552\n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.3780 - accuracy: 0.2667 \n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.3716 - accuracy: 0.2847\n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.3702 - accuracy: 0.2917\n",
            "  8/100 [=>............................] - ETA: 9s - loss: 1.3676 - accuracy: 0.2969\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3684 - accuracy: 0.2917\n",
            " 10/100 [==>...........................] - ETA: 9s - loss: 1.3682 - accuracy: 0.2875\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3682 - accuracy: 0.2860\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.3680 - accuracy: 0.2934\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.3690 - accuracy: 0.2917\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.3705 - accuracy: 0.2902\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.3698 - accuracy: 0.2875\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.3690 - accuracy: 0.2878\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.3699 - accuracy: 0.2868\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3688 - accuracy: 0.2917\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3698 - accuracy: 0.2906\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3718 - accuracy: 0.2896\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3728 - accuracy: 0.2867\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3747 - accuracy: 0.2831\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3735 - accuracy: 0.2835\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3729 - accuracy: 0.2821\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3728 - accuracy: 0.2833\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.3728 - accuracy: 0.2837\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.3731 - accuracy: 0.2863\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.3721 - accuracy: 0.2902\n",
            " 29/100 [=======>......................] - ETA: 7s - loss: 1.3726 - accuracy: 0.2881\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3734 - accuracy: 0.2875\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3740 - accuracy: 0.2876\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3749 - accuracy: 0.2858\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3746 - accuracy: 0.2828\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3752 - accuracy: 0.2788\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3753 - accuracy: 0.2810\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3747 - accuracy: 0.2807\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.3739 - accuracy: 0.2821\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.3738 - accuracy: 0.2840\n",
            " 39/100 [==========>...................] - ETA: 6s - loss: 1.3744 - accuracy: 0.2815\n",
            " 40/100 [===========>..................] - ETA: 6s - loss: 1.3755 - accuracy: 0.2807\n",
            " 41/100 [===========>..................] - ETA: 6s - loss: 1.3762 - accuracy: 0.2795\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3769 - accuracy: 0.2768\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3777 - accuracy: 0.2757\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3771 - accuracy: 0.2789\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3771 - accuracy: 0.2782\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3779 - accuracy: 0.2781\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3778 - accuracy: 0.2770\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.3779 - accuracy: 0.2782\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.3779 - accuracy: 0.2755\n",
            " 50/100 [==============>...............] - ETA: 5s - loss: 1.3784 - accuracy: 0.2750\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3790 - accuracy: 0.2778\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3777 - accuracy: 0.2780\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3773 - accuracy: 0.2783\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3779 - accuracy: 0.2774\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3780 - accuracy: 0.2773\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3779 - accuracy: 0.2764\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3773 - accuracy: 0.2763\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.3773 - accuracy: 0.2769\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.3771 - accuracy: 0.2744\n",
            " 60/100 [=================>............] - ETA: 4s - loss: 1.3773 - accuracy: 0.2747\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3766 - accuracy: 0.2763\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3767 - accuracy: 0.2772\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3765 - accuracy: 0.2781\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3771 - accuracy: 0.2764\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3767 - accuracy: 0.2744\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3761 - accuracy: 0.2756\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3763 - accuracy: 0.2746\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3761 - accuracy: 0.2754\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.3760 - accuracy: 0.2766\n",
            " 70/100 [====================>.........] - ETA: 3s - loss: 1.3764 - accuracy: 0.2762\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3756 - accuracy: 0.2779\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3755 - accuracy: 0.2781\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3756 - accuracy: 0.2791\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3759 - accuracy: 0.2790\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3762 - accuracy: 0.2792\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3753 - accuracy: 0.2807\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3750 - accuracy: 0.2806\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3745 - accuracy: 0.2818\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3752 - accuracy: 0.2814\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3757 - accuracy: 0.2815\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3760 - accuracy: 0.2816\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3768 - accuracy: 0.2818\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3771 - accuracy: 0.2814\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3770 - accuracy: 0.2820\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3770 - accuracy: 0.2824\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3770 - accuracy: 0.2825\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3771 - accuracy: 0.2821\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3773 - accuracy: 0.2820\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3770 - accuracy: 0.2830\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3770 - accuracy: 0.2838\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3769 - accuracy: 0.2848\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3772 - accuracy: 0.2844\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3771 - accuracy: 0.2847\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3772 - accuracy: 0.2855\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3772 - accuracy: 0.2855\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3771 - accuracy: 0.2860\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3771 - accuracy: 0.2863\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3775 - accuracy: 0.2851\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3774 - accuracy: 0.2845\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3770 - accuracy: 0.2850\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 1.3770 - accuracy: 0.2850 - val_loss: 1.3769 - val_accuracy: 0.2781\n",
            "\n",
            "Epoch 16/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 13s - loss: 1.3398 - accuracy: 0.3333\n",
            "  2/100 [..............................] - ETA: 10s - loss: 1.3521 - accuracy: 0.2917\n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.3467 - accuracy: 0.2986 \n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.3631 - accuracy: 0.2865\n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.3643 - accuracy: 0.2875\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.3587 - accuracy: 0.2917\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3612 - accuracy: 0.2887\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3756 - accuracy: 0.2708\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3719 - accuracy: 0.2755\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3670 - accuracy: 0.2875\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3633 - accuracy: 0.2992\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3626 - accuracy: 0.3038\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3688 - accuracy: 0.2885\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3688 - accuracy: 0.2917\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3656 - accuracy: 0.2889\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3658 - accuracy: 0.2904\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3695 - accuracy: 0.2868\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3716 - accuracy: 0.2882\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3717 - accuracy: 0.2862\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3731 - accuracy: 0.2854\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3722 - accuracy: 0.2857\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3721 - accuracy: 0.2869\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3727 - accuracy: 0.2853\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3758 - accuracy: 0.2830\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3777 - accuracy: 0.2783\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3778 - accuracy: 0.2780\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3783 - accuracy: 0.2778\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3781 - accuracy: 0.2775\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3783 - accuracy: 0.2766\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3776 - accuracy: 0.2792\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3766 - accuracy: 0.2809\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3760 - accuracy: 0.2812\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3765 - accuracy: 0.2835\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3763 - accuracy: 0.2825\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3758 - accuracy: 0.2827\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3761 - accuracy: 0.2812\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3768 - accuracy: 0.2804\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3765 - accuracy: 0.2812\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3762 - accuracy: 0.2831\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3773 - accuracy: 0.2812\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3764 - accuracy: 0.2830\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3768 - accuracy: 0.2808\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3767 - accuracy: 0.2800\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3761 - accuracy: 0.2789\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3763 - accuracy: 0.2796\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3759 - accuracy: 0.2799\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3757 - accuracy: 0.2815\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3757 - accuracy: 0.2839\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3761 - accuracy: 0.2819\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3759 - accuracy: 0.2817\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3754 - accuracy: 0.2815\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3760 - accuracy: 0.2817\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3766 - accuracy: 0.2818\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3764 - accuracy: 0.2820\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3776 - accuracy: 0.2803\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3770 - accuracy: 0.2805\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3770 - accuracy: 0.2800\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3778 - accuracy: 0.2795\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3775 - accuracy: 0.2807\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3783 - accuracy: 0.2806\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3782 - accuracy: 0.2811\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3782 - accuracy: 0.2799\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3781 - accuracy: 0.2808\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3778 - accuracy: 0.2806\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3782 - accuracy: 0.2801\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.3786 - accuracy: 0.2794\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3790 - accuracy: 0.2795\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3790 - accuracy: 0.2785\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3788 - accuracy: 0.2802\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3789 - accuracy: 0.2801\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3796 - accuracy: 0.2796\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3800 - accuracy: 0.2784\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3801 - accuracy: 0.2788\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3805 - accuracy: 0.2787\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3805 - accuracy: 0.2797\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3805 - accuracy: 0.2785\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3806 - accuracy: 0.2781\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3807 - accuracy: 0.2783\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3808 - accuracy: 0.2774\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3806 - accuracy: 0.2786\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3809 - accuracy: 0.2775\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3808 - accuracy: 0.2772\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3809 - accuracy: 0.2781\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3809 - accuracy: 0.2780\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3802 - accuracy: 0.2801\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3801 - accuracy: 0.2800\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3804 - accuracy: 0.2797\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3802 - accuracy: 0.2786\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3804 - accuracy: 0.2781\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3799 - accuracy: 0.2785\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3801 - accuracy: 0.2775\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3801 - accuracy: 0.2774\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3806 - accuracy: 0.2776\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3807 - accuracy: 0.2768\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3806 - accuracy: 0.2779\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3804 - accuracy: 0.2784\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3802 - accuracy: 0.2786\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3798 - accuracy: 0.2791\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3802 - accuracy: 0.2799\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3805 - accuracy: 0.2800\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.3805 - accuracy: 0.2800 - val_loss: 1.3829 - val_accuracy: 0.2708\n",
            "\n",
            "Epoch 17/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 16s - loss: 1.3952 - accuracy: 0.2708\n",
            "  2/100 [..............................] - ETA: 11s - loss: 1.3870 - accuracy: 0.2917\n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.3923 - accuracy: 0.2500 \n",
            "  4/100 [>.............................] - ETA: 10s - loss: 1.3845 - accuracy: 0.2865\n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.3855 - accuracy: 0.2833 \n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3846 - accuracy: 0.2812\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3852 - accuracy: 0.2917\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3846 - accuracy: 0.2891\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3828 - accuracy: 0.2917\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3789 - accuracy: 0.3021\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3799 - accuracy: 0.3011\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.3753 - accuracy: 0.3056\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.3732 - accuracy: 0.3141\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.3736 - accuracy: 0.3110\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.3735 - accuracy: 0.3125\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3725 - accuracy: 0.3177\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3736 - accuracy: 0.3113\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3755 - accuracy: 0.3032\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3759 - accuracy: 0.3048\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3761 - accuracy: 0.3021\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3759 - accuracy: 0.3046\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3739 - accuracy: 0.3040\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3749 - accuracy: 0.3025\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3760 - accuracy: 0.3003\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3763 - accuracy: 0.3017\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.3756 - accuracy: 0.3005\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.3767 - accuracy: 0.2971\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3783 - accuracy: 0.2924\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3776 - accuracy: 0.2924\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3781 - accuracy: 0.2944\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3773 - accuracy: 0.2950\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3784 - accuracy: 0.2949\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3791 - accuracy: 0.2942\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3797 - accuracy: 0.2898\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3804 - accuracy: 0.2899\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3797 - accuracy: 0.2917\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3794 - accuracy: 0.2917\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3797 - accuracy: 0.2928\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3796 - accuracy: 0.2917\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3797 - accuracy: 0.2901\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3797 - accuracy: 0.2881\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3793 - accuracy: 0.2877\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3792 - accuracy: 0.2873\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3791 - accuracy: 0.2888\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3789 - accuracy: 0.2880\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3788 - accuracy: 0.2880\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3779 - accuracy: 0.2903\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3777 - accuracy: 0.2895\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3778 - accuracy: 0.2883\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3781 - accuracy: 0.2887\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3778 - accuracy: 0.2892\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3773 - accuracy: 0.2893\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3777 - accuracy: 0.2889\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3778 - accuracy: 0.2878\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3779 - accuracy: 0.2864\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3776 - accuracy: 0.2861\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3776 - accuracy: 0.2865\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3775 - accuracy: 0.2859\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3775 - accuracy: 0.2846\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3771 - accuracy: 0.2844\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3773 - accuracy: 0.2848\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3775 - accuracy: 0.2833\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3767 - accuracy: 0.2847\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3764 - accuracy: 0.2861\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3768 - accuracy: 0.2856\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3761 - accuracy: 0.2872\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3770 - accuracy: 0.2873\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3763 - accuracy: 0.2874\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3769 - accuracy: 0.2865\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3772 - accuracy: 0.2857\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3774 - accuracy: 0.2864\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3776 - accuracy: 0.2859\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3774 - accuracy: 0.2860\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3778 - accuracy: 0.2858\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3779 - accuracy: 0.2861\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3784 - accuracy: 0.2845\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3780 - accuracy: 0.2849\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3783 - accuracy: 0.2839\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3781 - accuracy: 0.2840\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3780 - accuracy: 0.2844\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3777 - accuracy: 0.2845\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3777 - accuracy: 0.2846\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3780 - accuracy: 0.2834\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3780 - accuracy: 0.2830\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3778 - accuracy: 0.2833\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3779 - accuracy: 0.2846\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3779 - accuracy: 0.2845\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3775 - accuracy: 0.2853\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3776 - accuracy: 0.2856\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3776 - accuracy: 0.2856\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3779 - accuracy: 0.2853\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3780 - accuracy: 0.2849\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3780 - accuracy: 0.2849\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3781 - accuracy: 0.2855\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3778 - accuracy: 0.2862\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3778 - accuracy: 0.2862\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3775 - accuracy: 0.2872\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3772 - accuracy: 0.2876\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3776 - accuracy: 0.2875\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3775 - accuracy: 0.2877\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.3775 - accuracy: 0.2877 - val_loss: 1.4526 - val_accuracy: 0.2375\n",
            "\n",
            "Epoch 18/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 13s - loss: 1.3567 - accuracy: 0.3542\n",
            "  2/100 [..............................] - ETA: 8s - loss: 1.3700 - accuracy: 0.3021 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.3595 - accuracy: 0.3264\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.3618 - accuracy: 0.3229\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3665 - accuracy: 0.3083\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3698 - accuracy: 0.2951\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3729 - accuracy: 0.2857\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3750 - accuracy: 0.2812\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3783 - accuracy: 0.2685\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3750 - accuracy: 0.2771\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3753 - accuracy: 0.2708\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3780 - accuracy: 0.2743\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3763 - accuracy: 0.2740\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3743 - accuracy: 0.2812\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3742 - accuracy: 0.2861\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3737 - accuracy: 0.2867\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3788 - accuracy: 0.2783\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3809 - accuracy: 0.2755\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3815 - accuracy: 0.2719\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3805 - accuracy: 0.2719\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3811 - accuracy: 0.2698\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3823 - accuracy: 0.2670\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3820 - accuracy: 0.2635\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3831 - accuracy: 0.2594\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3818 - accuracy: 0.2632\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3818 - accuracy: 0.2603\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3828 - accuracy: 0.2607\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3817 - accuracy: 0.2633\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3822 - accuracy: 0.2621\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3818 - accuracy: 0.2638\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3815 - accuracy: 0.2674\n",
            " 32/100 [========>.....................] - ETA: 5s - loss: 1.3827 - accuracy: 0.2669\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3832 - accuracy: 0.2676\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3830 - accuracy: 0.2696\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3833 - accuracy: 0.2702\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3827 - accuracy: 0.2726\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3820 - accuracy: 0.2754\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3816 - accuracy: 0.2763\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3820 - accuracy: 0.2746\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3822 - accuracy: 0.2750\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3813 - accuracy: 0.2775\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3815 - accuracy: 0.2773\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3815 - accuracy: 0.2757\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3829 - accuracy: 0.2746\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3827 - accuracy: 0.2741\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3831 - accuracy: 0.2749\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3826 - accuracy: 0.2757\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3832 - accuracy: 0.2752\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3827 - accuracy: 0.2755\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3817 - accuracy: 0.2779\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3819 - accuracy: 0.2778\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3820 - accuracy: 0.2769\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3815 - accuracy: 0.2767\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3814 - accuracy: 0.2766\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3812 - accuracy: 0.2784\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3814 - accuracy: 0.2794\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3809 - accuracy: 0.2804\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3808 - accuracy: 0.2806\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3803 - accuracy: 0.2800\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3811 - accuracy: 0.2788\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3808 - accuracy: 0.2780\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3802 - accuracy: 0.2782\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3799 - accuracy: 0.2798\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3794 - accuracy: 0.2803\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3794 - accuracy: 0.2808\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.3787 - accuracy: 0.2813\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3783 - accuracy: 0.2811\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3772 - accuracy: 0.2816\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3768 - accuracy: 0.2836\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3776 - accuracy: 0.2828\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3777 - accuracy: 0.2829\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3773 - accuracy: 0.2824\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3772 - accuracy: 0.2834\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3764 - accuracy: 0.2844\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3758 - accuracy: 0.2842\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3755 - accuracy: 0.2849\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3761 - accuracy: 0.2839\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3762 - accuracy: 0.2834\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3760 - accuracy: 0.2841\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3764 - accuracy: 0.2831\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3763 - accuracy: 0.2835\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3771 - accuracy: 0.2831\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3773 - accuracy: 0.2824\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3770 - accuracy: 0.2820\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3768 - accuracy: 0.2812\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3771 - accuracy: 0.2805\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3771 - accuracy: 0.2809\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3768 - accuracy: 0.2810\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3765 - accuracy: 0.2821\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3761 - accuracy: 0.2841\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3762 - accuracy: 0.2844\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3765 - accuracy: 0.2849\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3764 - accuracy: 0.2852\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3760 - accuracy: 0.2866\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3767 - accuracy: 0.2856\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3773 - accuracy: 0.2841\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3772 - accuracy: 0.2837\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3775 - accuracy: 0.2825\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3772 - accuracy: 0.2826\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3770 - accuracy: 0.2829\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 1.3770 - accuracy: 0.2829 - val_loss: 1.3922 - val_accuracy: 0.2542\n",
            "\n",
            "Epoch 19/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 19s - loss: 1.3445 - accuracy: 0.3542\n",
            "  2/100 [..............................] - ETA: 10s - loss: 1.3421 - accuracy: 0.3333\n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.3460 - accuracy: 0.3125 \n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.3510 - accuracy: 0.3229\n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.3519 - accuracy: 0.3125\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.3538 - accuracy: 0.3160\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3546 - accuracy: 0.3214\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3569 - accuracy: 0.3177\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3575 - accuracy: 0.3194\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3621 - accuracy: 0.3187\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3663 - accuracy: 0.3106\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.3673 - accuracy: 0.3108\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3670 - accuracy: 0.3045\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3664 - accuracy: 0.3021\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3638 - accuracy: 0.2972\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3620 - accuracy: 0.3021\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3653 - accuracy: 0.2953\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3647 - accuracy: 0.2986\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3682 - accuracy: 0.3004\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3693 - accuracy: 0.2990\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3689 - accuracy: 0.3006\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3703 - accuracy: 0.2992\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3701 - accuracy: 0.3025\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3704 - accuracy: 0.2995\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3685 - accuracy: 0.3017\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3711 - accuracy: 0.2957\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3720 - accuracy: 0.2955\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3727 - accuracy: 0.2969\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3715 - accuracy: 0.2967\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3732 - accuracy: 0.2931\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3739 - accuracy: 0.2930\n",
            " 32/100 [========>.....................] - ETA: 5s - loss: 1.3756 - accuracy: 0.2923\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3767 - accuracy: 0.2891\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3762 - accuracy: 0.2892\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3770 - accuracy: 0.2881\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3771 - accuracy: 0.2865\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3770 - accuracy: 0.2866\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3766 - accuracy: 0.2867\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3775 - accuracy: 0.2863\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3786 - accuracy: 0.2859\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3785 - accuracy: 0.2856\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3781 - accuracy: 0.2872\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3776 - accuracy: 0.2907\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3776 - accuracy: 0.2926\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3777 - accuracy: 0.2931\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3778 - accuracy: 0.2921\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3777 - accuracy: 0.2930\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3777 - accuracy: 0.2938\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3773 - accuracy: 0.2938\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3771 - accuracy: 0.2937\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3765 - accuracy: 0.2937\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3759 - accuracy: 0.2949\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3763 - accuracy: 0.2936\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3766 - accuracy: 0.2932\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3763 - accuracy: 0.2917\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3766 - accuracy: 0.2913\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3771 - accuracy: 0.2902\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3769 - accuracy: 0.2909\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3772 - accuracy: 0.2913\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3789 - accuracy: 0.2885\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3789 - accuracy: 0.2886\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3794 - accuracy: 0.2876\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3796 - accuracy: 0.2860\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3796 - accuracy: 0.2858\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3795 - accuracy: 0.2856\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.3789 - accuracy: 0.2860\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3792 - accuracy: 0.2845\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3796 - accuracy: 0.2843\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3801 - accuracy: 0.2823\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3799 - accuracy: 0.2833\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3802 - accuracy: 0.2820\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3801 - accuracy: 0.2821\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3795 - accuracy: 0.2825\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3796 - accuracy: 0.2815\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3795 - accuracy: 0.2811\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3795 - accuracy: 0.2802\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3801 - accuracy: 0.2792\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3802 - accuracy: 0.2780\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3803 - accuracy: 0.2785\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3799 - accuracy: 0.2802\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3800 - accuracy: 0.2793\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3800 - accuracy: 0.2787\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3800 - accuracy: 0.2786\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3801 - accuracy: 0.2778\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3798 - accuracy: 0.2775\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3793 - accuracy: 0.2781\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3793 - accuracy: 0.2792\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3795 - accuracy: 0.2777\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3794 - accuracy: 0.2783\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3792 - accuracy: 0.2775\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3789 - accuracy: 0.2775\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3788 - accuracy: 0.2788\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3790 - accuracy: 0.2782\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3793 - accuracy: 0.2770\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3791 - accuracy: 0.2783\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3793 - accuracy: 0.2782\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3792 - accuracy: 0.2781\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3789 - accuracy: 0.2785\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3791 - accuracy: 0.2780\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3792 - accuracy: 0.2779\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.3792 - accuracy: 0.2779 - val_loss: 2.0449 - val_accuracy: 0.2812\n",
            "\n",
            "Epoch 20/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 10s - loss: 1.3195 - accuracy: 0.2708\n",
            "  2/100 [..............................] - ETA: 8s - loss: 1.3564 - accuracy: 0.2812 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.3623 - accuracy: 0.2986\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.3573 - accuracy: 0.3125\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3727 - accuracy: 0.2833\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3703 - accuracy: 0.2778\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3732 - accuracy: 0.2887\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3721 - accuracy: 0.2917\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3688 - accuracy: 0.3009\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3667 - accuracy: 0.2917\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3643 - accuracy: 0.2955\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3674 - accuracy: 0.2899\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.3693 - accuracy: 0.2804\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.3699 - accuracy: 0.2798\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.3710 - accuracy: 0.2750\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.3721 - accuracy: 0.2682\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.3707 - accuracy: 0.2733\n",
            " 18/100 [====>.........................] - ETA: 8s - loss: 1.3694 - accuracy: 0.2685\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3679 - accuracy: 0.2708\n",
            " 20/100 [=====>........................] - ETA: 8s - loss: 1.3693 - accuracy: 0.2646\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3695 - accuracy: 0.2629\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3702 - accuracy: 0.2623\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3705 - accuracy: 0.2636\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3697 - accuracy: 0.2613\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3689 - accuracy: 0.2583\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.3676 - accuracy: 0.2628\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.3722 - accuracy: 0.2608\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.3724 - accuracy: 0.2612\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3715 - accuracy: 0.2644\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3724 - accuracy: 0.2646\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3714 - accuracy: 0.2634\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3721 - accuracy: 0.2656\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3729 - accuracy: 0.2639\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3739 - accuracy: 0.2672\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3748 - accuracy: 0.2667\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3751 - accuracy: 0.2691\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.3748 - accuracy: 0.2703\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.3740 - accuracy: 0.2725\n",
            " 39/100 [==========>...................] - ETA: 6s - loss: 1.3743 - accuracy: 0.2740\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3744 - accuracy: 0.2724\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3746 - accuracy: 0.2724\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3746 - accuracy: 0.2738\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3755 - accuracy: 0.2718\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3756 - accuracy: 0.2704\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3758 - accuracy: 0.2699\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3758 - accuracy: 0.2708\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3761 - accuracy: 0.2713\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.3768 - accuracy: 0.2704\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.3768 - accuracy: 0.2704\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3771 - accuracy: 0.2683\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3770 - accuracy: 0.2692\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3775 - accuracy: 0.2680\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3780 - accuracy: 0.2665\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3780 - accuracy: 0.2662\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3778 - accuracy: 0.2667\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3774 - accuracy: 0.2701\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3773 - accuracy: 0.2712\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.3774 - accuracy: 0.2723\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.3769 - accuracy: 0.2754\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3770 - accuracy: 0.2733\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3772 - accuracy: 0.2712\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3772 - accuracy: 0.2705\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3771 - accuracy: 0.2708\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3771 - accuracy: 0.2708\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3772 - accuracy: 0.2718\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3772 - accuracy: 0.2718\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3768 - accuracy: 0.2743\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3769 - accuracy: 0.2745\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.3764 - accuracy: 0.2751\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3765 - accuracy: 0.2762\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3767 - accuracy: 0.2767\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3769 - accuracy: 0.2760\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3771 - accuracy: 0.2760\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3767 - accuracy: 0.2770\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3767 - accuracy: 0.2772\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3769 - accuracy: 0.2763\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3763 - accuracy: 0.2781\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3768 - accuracy: 0.2767\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3764 - accuracy: 0.2780\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3764 - accuracy: 0.2794\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3758 - accuracy: 0.2803\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3758 - accuracy: 0.2800\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3755 - accuracy: 0.2814\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3753 - accuracy: 0.2820\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3756 - accuracy: 0.2811\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3755 - accuracy: 0.2820\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3761 - accuracy: 0.2814\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3761 - accuracy: 0.2812\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3762 - accuracy: 0.2811\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3765 - accuracy: 0.2810\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3765 - accuracy: 0.2814\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3766 - accuracy: 0.2812\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3760 - accuracy: 0.2823\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3758 - accuracy: 0.2815\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3756 - accuracy: 0.2820\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3755 - accuracy: 0.2817\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3752 - accuracy: 0.2818\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3751 - accuracy: 0.2819\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3750 - accuracy: 0.2814\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3759 - accuracy: 0.2802\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 1.3759 - accuracy: 0.2802 - val_loss: 1.3395 - val_accuracy: 0.3594\n",
            "\n",
            "Epoch 21/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 10s - loss: 1.3606 - accuracy: 0.3333\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.3471 - accuracy: 0.3646 \n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.3405 - accuracy: 0.3125\n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.3501 - accuracy: 0.3021\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3596 - accuracy: 0.2917\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3648 - accuracy: 0.2847\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3702 - accuracy: 0.2798\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3672 - accuracy: 0.2865\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3678 - accuracy: 0.2824\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.3744 - accuracy: 0.2729\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3790 - accuracy: 0.2727\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3772 - accuracy: 0.2760\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3733 - accuracy: 0.2804\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3722 - accuracy: 0.2783\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3731 - accuracy: 0.2847\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3755 - accuracy: 0.2839\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3745 - accuracy: 0.2831\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3757 - accuracy: 0.2778\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3754 - accuracy: 0.2840\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3732 - accuracy: 0.2906\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.3722 - accuracy: 0.2917\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3739 - accuracy: 0.2907\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3724 - accuracy: 0.2953\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3719 - accuracy: 0.2951\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3724 - accuracy: 0.2983\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3729 - accuracy: 0.2989\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3739 - accuracy: 0.2971\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3732 - accuracy: 0.3006\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3738 - accuracy: 0.2981\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3725 - accuracy: 0.2993\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3732 - accuracy: 0.2970\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3728 - accuracy: 0.2995\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3725 - accuracy: 0.3030\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3711 - accuracy: 0.3064\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3707 - accuracy: 0.3083\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3704 - accuracy: 0.3079\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3705 - accuracy: 0.3069\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3684 - accuracy: 0.3087\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3678 - accuracy: 0.3088\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3685 - accuracy: 0.3068\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3690 - accuracy: 0.3074\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3688 - accuracy: 0.3075\n",
            " 43/100 [===========>..................] - ETA: 4s - loss: 1.3685 - accuracy: 0.3081\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3685 - accuracy: 0.3092\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3680 - accuracy: 0.3093\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3686 - accuracy: 0.3089\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3695 - accuracy: 0.3081\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3699 - accuracy: 0.3069\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3701 - accuracy: 0.3091\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3693 - accuracy: 0.3104\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3691 - accuracy: 0.3121\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3699 - accuracy: 0.3125\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3693 - accuracy: 0.3121\n",
            " 54/100 [===============>..............] - ETA: 3s - loss: 1.3691 - accuracy: 0.3121\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3688 - accuracy: 0.3125\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3682 - accuracy: 0.3125\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3683 - accuracy: 0.3129\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3684 - accuracy: 0.3118\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3693 - accuracy: 0.3093\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3693 - accuracy: 0.3090\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3694 - accuracy: 0.3067\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3693 - accuracy: 0.3071\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3688 - accuracy: 0.3062\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3687 - accuracy: 0.3047\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3676 - accuracy: 0.3058\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.3675 - accuracy: 0.3068\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3682 - accuracy: 0.3047\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3686 - accuracy: 0.3036\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3683 - accuracy: 0.3050\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3685 - accuracy: 0.3045\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3678 - accuracy: 0.3049\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3676 - accuracy: 0.3050\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3676 - accuracy: 0.3048\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3673 - accuracy: 0.3055\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3680 - accuracy: 0.3042\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3677 - accuracy: 0.3043\n",
            " 77/100 [======================>.......] - ETA: 1s - loss: 1.3678 - accuracy: 0.3052\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3687 - accuracy: 0.3040\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3695 - accuracy: 0.3025\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3696 - accuracy: 0.3036\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3693 - accuracy: 0.3050\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3693 - accuracy: 0.3056\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3691 - accuracy: 0.3060\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3690 - accuracy: 0.3053\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3691 - accuracy: 0.3051\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3691 - accuracy: 0.3055\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3692 - accuracy: 0.3048\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3693 - accuracy: 0.3049\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3692 - accuracy: 0.3045\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3684 - accuracy: 0.3056\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3684 - accuracy: 0.3049\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3687 - accuracy: 0.3050\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3687 - accuracy: 0.3044\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3688 - accuracy: 0.3043\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3689 - accuracy: 0.3033\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3690 - accuracy: 0.3014\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3689 - accuracy: 0.3011\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3689 - accuracy: 0.3019\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3688 - accuracy: 0.3022\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3690 - accuracy: 0.3008\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.3690 - accuracy: 0.3008 - val_loss: 1.3697 - val_accuracy: 0.2781\n",
            "\n",
            "Epoch 22/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 20s - loss: 1.3858 - accuracy: 0.2708\n",
            "  2/100 [..............................] - ETA: 12s - loss: 1.3745 - accuracy: 0.2604\n",
            "  3/100 [..............................] - ETA: 10s - loss: 1.3627 - accuracy: 0.3056\n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.3465 - accuracy: 0.3125 \n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.3530 - accuracy: 0.3167\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.3613 - accuracy: 0.3194\n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.3641 - accuracy: 0.3065\n",
            "  8/100 [=>............................] - ETA: 9s - loss: 1.3593 - accuracy: 0.3125\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3590 - accuracy: 0.3056\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3553 - accuracy: 0.3167\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3553 - accuracy: 0.3125\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.3561 - accuracy: 0.3160\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.3542 - accuracy: 0.3109\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.3586 - accuracy: 0.3155\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.3611 - accuracy: 0.3069\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3669 - accuracy: 0.3047\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3658 - accuracy: 0.3051\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3685 - accuracy: 0.3044\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3658 - accuracy: 0.3081\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3674 - accuracy: 0.3063\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3656 - accuracy: 0.3056\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3673 - accuracy: 0.3040\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3694 - accuracy: 0.3016\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3683 - accuracy: 0.3021\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3689 - accuracy: 0.3025\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3687 - accuracy: 0.3045\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3674 - accuracy: 0.3063\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3678 - accuracy: 0.3028\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3686 - accuracy: 0.3017\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3686 - accuracy: 0.3021\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3680 - accuracy: 0.3004\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3675 - accuracy: 0.3001\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3671 - accuracy: 0.3011\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3675 - accuracy: 0.2990\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3684 - accuracy: 0.2952\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3681 - accuracy: 0.2963\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3684 - accuracy: 0.2934\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3680 - accuracy: 0.2950\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3688 - accuracy: 0.2922\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3694 - accuracy: 0.2896\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3693 - accuracy: 0.2882\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3697 - accuracy: 0.2868\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3697 - accuracy: 0.2874\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3707 - accuracy: 0.2856\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3709 - accuracy: 0.2839\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3704 - accuracy: 0.2849\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3711 - accuracy: 0.2829\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3714 - accuracy: 0.2822\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3714 - accuracy: 0.2824\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3713 - accuracy: 0.2834\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3712 - accuracy: 0.2819\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3718 - accuracy: 0.2821\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3714 - accuracy: 0.2823\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3706 - accuracy: 0.2840\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3708 - accuracy: 0.2834\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3705 - accuracy: 0.2832\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3703 - accuracy: 0.2848\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3693 - accuracy: 0.2838\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3695 - accuracy: 0.2825\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3699 - accuracy: 0.2827\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3696 - accuracy: 0.2832\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3712 - accuracy: 0.2816\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3717 - accuracy: 0.2824\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3732 - accuracy: 0.2813\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3734 - accuracy: 0.2818\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3741 - accuracy: 0.2803\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3744 - accuracy: 0.2793\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3740 - accuracy: 0.2800\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3742 - accuracy: 0.2781\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3741 - accuracy: 0.2789\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3741 - accuracy: 0.2788\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3739 - accuracy: 0.2784\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3736 - accuracy: 0.2780\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3738 - accuracy: 0.2782\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3733 - accuracy: 0.2797\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3732 - accuracy: 0.2791\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3729 - accuracy: 0.2806\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3730 - accuracy: 0.2799\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3730 - accuracy: 0.2806\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3730 - accuracy: 0.2818\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3729 - accuracy: 0.2814\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3727 - accuracy: 0.2823\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3726 - accuracy: 0.2824\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3728 - accuracy: 0.2825\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3728 - accuracy: 0.2839\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3720 - accuracy: 0.2856\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3722 - accuracy: 0.2855\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3720 - accuracy: 0.2853\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3712 - accuracy: 0.2861\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3712 - accuracy: 0.2866\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3715 - accuracy: 0.2869\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3714 - accuracy: 0.2876\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3710 - accuracy: 0.2877\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3708 - accuracy: 0.2877\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3701 - accuracy: 0.2886\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3703 - accuracy: 0.2891\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3704 - accuracy: 0.2891\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3705 - accuracy: 0.2892\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3705 - accuracy: 0.2885\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3705 - accuracy: 0.2884\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.3705 - accuracy: 0.2884 - val_loss: 1.3724 - val_accuracy: 0.2792\n",
            "\n",
            "Epoch 23/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 13s - loss: 1.3965 - accuracy: 0.3542\n",
            "  2/100 [..............................] - ETA: 8s - loss: 1.3581 - accuracy: 0.3854 \n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.3477 - accuracy: 0.4097\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.3548 - accuracy: 0.3646\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3559 - accuracy: 0.3542\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3478 - accuracy: 0.3576\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3526 - accuracy: 0.3393\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3591 - accuracy: 0.3359\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.3579 - accuracy: 0.3403\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.3570 - accuracy: 0.3396\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3519 - accuracy: 0.3409\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3518 - accuracy: 0.3351\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3534 - accuracy: 0.3301\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3559 - accuracy: 0.3229\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3594 - accuracy: 0.3125\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3604 - accuracy: 0.3086\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3571 - accuracy: 0.3150\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3577 - accuracy: 0.3171\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3581 - accuracy: 0.3147\n",
            " 20/100 [=====>........................] - ETA: 6s - loss: 1.3586 - accuracy: 0.3177\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.3603 - accuracy: 0.3125\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3598 - accuracy: 0.3153\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3590 - accuracy: 0.3216\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3593 - accuracy: 0.3160\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3588 - accuracy: 0.3117\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3600 - accuracy: 0.3117\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3593 - accuracy: 0.3140\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3606 - accuracy: 0.3132\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3600 - accuracy: 0.3168\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3601 - accuracy: 0.3167\n",
            " 31/100 [========>.....................] - ETA: 5s - loss: 1.3599 - accuracy: 0.3165\n",
            " 32/100 [========>.....................] - ETA: 5s - loss: 1.3604 - accuracy: 0.3158\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3594 - accuracy: 0.3176\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3581 - accuracy: 0.3180\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3582 - accuracy: 0.3196\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3600 - accuracy: 0.3166\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3612 - accuracy: 0.3159\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3609 - accuracy: 0.3169\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3615 - accuracy: 0.3162\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3621 - accuracy: 0.3161\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3622 - accuracy: 0.3166\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3618 - accuracy: 0.3175\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3611 - accuracy: 0.3183\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3616 - accuracy: 0.3172\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3599 - accuracy: 0.3194\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3597 - accuracy: 0.3175\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3601 - accuracy: 0.3152\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3604 - accuracy: 0.3125\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3611 - accuracy: 0.3099\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3623 - accuracy: 0.3108\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3634 - accuracy: 0.3088\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3643 - accuracy: 0.3077\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3652 - accuracy: 0.3070\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3641 - accuracy: 0.3075\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3646 - accuracy: 0.3068\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3647 - accuracy: 0.3058\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3646 - accuracy: 0.3074\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3643 - accuracy: 0.3096\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3641 - accuracy: 0.3111\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3646 - accuracy: 0.3094\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3647 - accuracy: 0.3091\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3646 - accuracy: 0.3095\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3654 - accuracy: 0.3075\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3663 - accuracy: 0.3070\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3666 - accuracy: 0.3071\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3668 - accuracy: 0.3068\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3676 - accuracy: 0.3050\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3684 - accuracy: 0.3039\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3686 - accuracy: 0.3034\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3687 - accuracy: 0.3033\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3687 - accuracy: 0.3040\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3684 - accuracy: 0.3038\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3687 - accuracy: 0.3034\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3691 - accuracy: 0.3021\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3691 - accuracy: 0.3028\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3691 - accuracy: 0.3026\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3691 - accuracy: 0.3030\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3690 - accuracy: 0.3045\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3690 - accuracy: 0.3041\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3687 - accuracy: 0.3049\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3689 - accuracy: 0.3050\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3691 - accuracy: 0.3041\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3687 - accuracy: 0.3040\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3692 - accuracy: 0.3041\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3695 - accuracy: 0.3027\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3695 - accuracy: 0.3018\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3691 - accuracy: 0.3015\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3690 - accuracy: 0.3018\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3692 - accuracy: 0.3006\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3696 - accuracy: 0.2995\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3695 - accuracy: 0.2992\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3693 - accuracy: 0.2987\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3694 - accuracy: 0.2988\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3691 - accuracy: 0.2983\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3695 - accuracy: 0.2971\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3699 - accuracy: 0.2971\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3694 - accuracy: 0.2988\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3687 - accuracy: 0.2993\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3682 - accuracy: 0.3001\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3678 - accuracy: 0.3006\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 1.3678 - accuracy: 0.3006 - val_loss: 1.4163 - val_accuracy: 0.2646\n",
            "\n",
            "Epoch 24/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 16s - loss: 1.3504 - accuracy: 0.3333\n",
            "  2/100 [..............................] - ETA: 10s - loss: 1.3300 - accuracy: 0.3542\n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.3757 - accuracy: 0.2917 \n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.3720 - accuracy: 0.3125\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3593 - accuracy: 0.3333\n",
            "  6/100 [>.............................] - ETA: 7s - loss: 1.3556 - accuracy: 0.3333\n",
            "  7/100 [=>............................] - ETA: 7s - loss: 1.3663 - accuracy: 0.3155\n",
            "  8/100 [=>............................] - ETA: 7s - loss: 1.3748 - accuracy: 0.3177\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.3708 - accuracy: 0.3218\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.3678 - accuracy: 0.3167\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3687 - accuracy: 0.3068\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3675 - accuracy: 0.3108\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3655 - accuracy: 0.3109\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3685 - accuracy: 0.3095\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3669 - accuracy: 0.3139\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3674 - accuracy: 0.3138\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3630 - accuracy: 0.3199\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3643 - accuracy: 0.3183\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3640 - accuracy: 0.3191\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3648 - accuracy: 0.3198\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3629 - accuracy: 0.3185\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3651 - accuracy: 0.3172\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3654 - accuracy: 0.3125\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3650 - accuracy: 0.3073\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3655 - accuracy: 0.3083\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3658 - accuracy: 0.3085\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3654 - accuracy: 0.3110\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3655 - accuracy: 0.3118\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3649 - accuracy: 0.3125\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3637 - accuracy: 0.3132\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3627 - accuracy: 0.3172\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3628 - accuracy: 0.3151\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3625 - accuracy: 0.3144\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3636 - accuracy: 0.3113\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3633 - accuracy: 0.3119\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3643 - accuracy: 0.3096\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3644 - accuracy: 0.3091\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3642 - accuracy: 0.3109\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3661 - accuracy: 0.3104\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3655 - accuracy: 0.3089\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3666 - accuracy: 0.3115\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3658 - accuracy: 0.3125\n",
            " 43/100 [===========>..................] - ETA: 4s - loss: 1.3657 - accuracy: 0.3120\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3655 - accuracy: 0.3120\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3649 - accuracy: 0.3125\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3647 - accuracy: 0.3120\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3648 - accuracy: 0.3121\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3644 - accuracy: 0.3121\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3632 - accuracy: 0.3125\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3643 - accuracy: 0.3104\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3629 - accuracy: 0.3129\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3633 - accuracy: 0.3121\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3632 - accuracy: 0.3129\n",
            " 54/100 [===============>..............] - ETA: 3s - loss: 1.3641 - accuracy: 0.3133\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3652 - accuracy: 0.3117\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3659 - accuracy: 0.3125\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3663 - accuracy: 0.3114\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3664 - accuracy: 0.3111\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3663 - accuracy: 0.3093\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3664 - accuracy: 0.3076\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3655 - accuracy: 0.3091\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3653 - accuracy: 0.3095\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3653 - accuracy: 0.3105\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3653 - accuracy: 0.3105\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3653 - accuracy: 0.3109\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.3648 - accuracy: 0.3119\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3645 - accuracy: 0.3106\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3643 - accuracy: 0.3116\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3639 - accuracy: 0.3131\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3639 - accuracy: 0.3134\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3642 - accuracy: 0.3128\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3640 - accuracy: 0.3134\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3636 - accuracy: 0.3136\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3630 - accuracy: 0.3148\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3628 - accuracy: 0.3150\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3616 - accuracy: 0.3169\n",
            " 77/100 [======================>.......] - ETA: 1s - loss: 1.3618 - accuracy: 0.3166\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3616 - accuracy: 0.3162\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3615 - accuracy: 0.3172\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3607 - accuracy: 0.3180\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3594 - accuracy: 0.3189\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3605 - accuracy: 0.3181\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3600 - accuracy: 0.3180\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3582 - accuracy: 0.3197\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3577 - accuracy: 0.3189\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3574 - accuracy: 0.3190\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3574 - accuracy: 0.3185\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3576 - accuracy: 0.3191\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3567 - accuracy: 0.3193\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3575 - accuracy: 0.3204\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3587 - accuracy: 0.3207\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3569 - accuracy: 0.3225\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3571 - accuracy: 0.3219\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3572 - accuracy: 0.3227\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3567 - accuracy: 0.3224\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3556 - accuracy: 0.3244\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3552 - accuracy: 0.3250\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3546 - accuracy: 0.3259\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3539 - accuracy: 0.3258\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3543 - accuracy: 0.3250\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 1.3543 - accuracy: 0.3250 - val_loss: 1.3944 - val_accuracy: 0.4000\n",
            "\n",
            "Epoch 25/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 14s - loss: 1.2953 - accuracy: 0.3125\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.3118 - accuracy: 0.3229 \n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.2999 - accuracy: 0.3472\n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.3002 - accuracy: 0.3490\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3221 - accuracy: 0.3292\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3257 - accuracy: 0.3299\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3386 - accuracy: 0.3244\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3392 - accuracy: 0.3177\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.3396 - accuracy: 0.3207\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.3408 - accuracy: 0.3220\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3513 - accuracy: 0.3133\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3473 - accuracy: 0.3150\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3442 - accuracy: 0.3197\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3371 - accuracy: 0.3298\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3351 - accuracy: 0.3300\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3358 - accuracy: 0.3289\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3372 - accuracy: 0.3242\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3339 - accuracy: 0.3283\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3350 - accuracy: 0.3307\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3367 - accuracy: 0.3309\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3336 - accuracy: 0.3300\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3380 - accuracy: 0.3321\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3398 - accuracy: 0.3330\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3387 - accuracy: 0.3348\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3399 - accuracy: 0.3356\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3381 - accuracy: 0.3387\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3392 - accuracy: 0.3401\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3390 - accuracy: 0.3413\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3383 - accuracy: 0.3425\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3399 - accuracy: 0.3415\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3417 - accuracy: 0.3406\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3421 - accuracy: 0.3384\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3414 - accuracy: 0.3382\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3405 - accuracy: 0.3356\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3429 - accuracy: 0.3331\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3420 - accuracy: 0.3337\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3417 - accuracy: 0.3343\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3404 - accuracy: 0.3354\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3393 - accuracy: 0.3358\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3387 - accuracy: 0.3379\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3376 - accuracy: 0.3388\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3381 - accuracy: 0.3377\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3393 - accuracy: 0.3366\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3394 - accuracy: 0.3370\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3394 - accuracy: 0.3383\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3396 - accuracy: 0.3414\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3374 - accuracy: 0.3434\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3357 - accuracy: 0.3445\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3345 - accuracy: 0.3460\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3334 - accuracy: 0.3470\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3315 - accuracy: 0.3484\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3321 - accuracy: 0.3489\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3302 - accuracy: 0.3494\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3310 - accuracy: 0.3495\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3295 - accuracy: 0.3518\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3276 - accuracy: 0.3538\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3291 - accuracy: 0.3530\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3286 - accuracy: 0.3534\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3276 - accuracy: 0.3534\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3283 - accuracy: 0.3534\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3265 - accuracy: 0.3541\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3274 - accuracy: 0.3538\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3261 - accuracy: 0.3551\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3265 - accuracy: 0.3571\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3250 - accuracy: 0.3586\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3274 - accuracy: 0.3583\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3262 - accuracy: 0.3594\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3259 - accuracy: 0.3584\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3262 - accuracy: 0.3572\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3257 - accuracy: 0.3562\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3243 - accuracy: 0.3562\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3252 - accuracy: 0.3562\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3254 - accuracy: 0.3570\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3248 - accuracy: 0.3584\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3254 - accuracy: 0.3572\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3242 - accuracy: 0.3569\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3244 - accuracy: 0.3563\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3236 - accuracy: 0.3563\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3230 - accuracy: 0.3560\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3222 - accuracy: 0.3557\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3221 - accuracy: 0.3549\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3208 - accuracy: 0.3554\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3195 - accuracy: 0.3562\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3184 - accuracy: 0.3574\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3186 - accuracy: 0.3576\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3176 - accuracy: 0.3575\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3173 - accuracy: 0.3568\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3172 - accuracy: 0.3558\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3166 - accuracy: 0.3567\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3155 - accuracy: 0.3581\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3166 - accuracy: 0.3578\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3164 - accuracy: 0.3585\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3156 - accuracy: 0.3589\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3140 - accuracy: 0.3595\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3133 - accuracy: 0.3590\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3127 - accuracy: 0.3583\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3118 - accuracy: 0.3580\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3116 - accuracy: 0.3580\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3110 - accuracy: 0.3590\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3101 - accuracy: 0.3594\n",
            "100/100 [==============================] - 12s 124ms/step - loss: 1.3101 - accuracy: 0.3594 - val_loss: 121.7013 - val_accuracy: 0.1531\n",
            "\n",
            "Model: \"sequential_17\"\n",
            "\n",
            "_________________________________________________________________\n",
            "\n",
            " Layer (type)                Output Shape              Param #   \n",
            "\n",
            "=================================================================\n",
            "\n",
            " conv2d_204 (Conv2D)         (None, 48, 48, 64)        320       \n",
            "\n",
            " batch_normalization_85 (Bat  (None, 48, 48, 64)       256       \n",
            "\n",
            " chNormalization)                                                \n",
            "\n",
            " leaky_re_lu_51 (LeakyReLU)  (None, 48, 48, 64)        0         \n",
            "\n",
            " max_pooling2d_51 (MaxPoolin  (None, 24, 24, 64)       0         \n",
            "\n",
            " g2D)                                                            \n",
            "\n",
            " dropout_85 (Dropout)        (None, 24, 24, 64)        0         \n",
            "\n",
            " conv2d_205 (Conv2D)         (None, 24, 24, 128)       32896     \n",
            "\n",
            " batch_normalization_86 (Bat  (None, 24, 24, 128)      512       \n",
            "\n",
            " chNormalization)                                                \n",
            "\n",
            " leaky_re_lu_52 (LeakyReLU)  (None, 24, 24, 128)       0         \n",
            "\n",
            " max_pooling2d_52 (MaxPoolin  (None, 12, 12, 128)      0         \n",
            "\n",
            " g2D)                                                            \n",
            "\n",
            " dropout_86 (Dropout)        (None, 12, 12, 128)       0         \n",
            "\n",
            " conv2d_206 (Conv2D)         (None, 12, 12, 512)       262656    \n",
            "\n",
            " batch_normalization_87 (Bat  (None, 12, 12, 512)      2048      \n",
            "\n",
            " chNormalization)                                                \n",
            "\n",
            " leaky_re_lu_53 (LeakyReLU)  (None, 12, 12, 512)       0         \n",
            "\n",
            " max_pooling2d_53 (MaxPoolin  (None, 6, 6, 512)        0         \n",
            "\n",
            " g2D)                                                            \n",
            "\n",
            " dropout_87 (Dropout)        (None, 6, 6, 512)         0         \n",
            "\n",
            " conv2d_207 (Conv2D)         (None, 6, 6, 512)         1049088   \n",
            "\n",
            " conv2d_208 (Conv2D)         (None, 6, 6, 512)         1049088   \n",
            "\n",
            " conv2d_209 (Conv2D)         (None, 6, 6, 512)         1049088   \n",
            "\n",
            " activation_51 (Activation)  (None, 6, 6, 512)         0         \n",
            "\n",
            " conv2d_210 (Conv2D)         (None, 6, 6, 256)         524544    \n",
            "\n",
            " conv2d_211 (Conv2D)         (None, 6, 6, 256)         262400    \n",
            "\n",
            " activation_52 (Activation)  (None, 6, 6, 256)         0         \n",
            "\n",
            " conv2d_212 (Conv2D)         (None, 6, 6, 256)         262400    \n",
            "\n",
            " conv2d_213 (Conv2D)         (None, 6, 6, 256)         262400    \n",
            "\n",
            " activation_53 (Activation)  (None, 6, 6, 256)         0         \n",
            "\n",
            " conv2d_214 (Conv2D)         (None, 6, 6, 256)         262400    \n",
            "\n",
            " conv2d_215 (Conv2D)         (None, 6, 6, 256)         262400    \n",
            "\n",
            " flatten_17 (Flatten)        (None, 9216)              0         \n",
            "\n",
            " dense_85 (Dense)            (None, 256)               2359552   \n",
            "\n",
            " batch_normalization_88 (Bat  (None, 256)              1024      \n",
            "\n",
            " chNormalization)                                                \n",
            "\n",
            " dense_86 (Dense)            (None, 256)               65792     \n",
            "\n",
            " dropout_88 (Dropout)        (None, 256)               0         \n",
            "\n",
            " dense_87 (Dense)            (None, 256)               65792     \n",
            "\n",
            " batch_normalization_89 (Bat  (None, 256)              1024      \n",
            "\n",
            " chNormalization)                                                \n",
            "\n",
            " dense_88 (Dense)            (None, 256)               65792     \n",
            "\n",
            " dropout_89 (Dropout)        (None, 256)               0         \n",
            "\n",
            " dense_89 (Dense)            (None, 4)                 1028      \n",
            "\n",
            "=================================================================\n",
            "\n",
            "Total params: 7,842,500\n",
            "\n",
            "Trainable params: 7,840,068\n",
            "\n",
            "Non-trainable params: 2,432\n",
            "\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 20:02 - loss: 1.6979 - accuracy: 0.3333\n",
            "  2/100 [..............................] - ETA: 7s - loss: 1.7022 - accuracy: 0.3333   \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.7061 - accuracy: 0.3125\n",
            "  4/100 [>.............................] - ETA: 7s - loss: 1.7355 - accuracy: 0.3073\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.7356 - accuracy: 0.2917\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.7283 - accuracy: 0.2812\n",
            "  7/100 [=>............................] - ETA: 7s - loss: 1.6824 - accuracy: 0.2976\n",
            "  8/100 [=>............................] - ETA: 7s - loss: 1.6926 - accuracy: 0.2943\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.7056 - accuracy: 0.2940\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.7106 - accuracy: 0.2917\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.6947 - accuracy: 0.3049\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.6933 - accuracy: 0.3003\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.6924 - accuracy: 0.3029\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.6790 - accuracy: 0.3021\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.6632 - accuracy: 0.3042\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.6588 - accuracy: 0.3034\n",
            " 17/100 [====>.........................] - ETA: 6s - loss: 1.6613 - accuracy: 0.3039\n",
            " 18/100 [====>.........................] - ETA: 6s - loss: 1.6681 - accuracy: 0.3009\n",
            " 19/100 [====>.........................] - ETA: 6s - loss: 1.6733 - accuracy: 0.2950\n",
            " 20/100 [=====>........................] - ETA: 6s - loss: 1.6803 - accuracy: 0.2937\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.6801 - accuracy: 0.2946\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.6814 - accuracy: 0.2955\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.6875 - accuracy: 0.2889\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.6879 - accuracy: 0.2865\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.6780 - accuracy: 0.2867\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.6843 - accuracy: 0.2788\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.6800 - accuracy: 0.2778\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.6818 - accuracy: 0.2760\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.6743 - accuracy: 0.2766\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.6657 - accuracy: 0.2771\n",
            " 31/100 [========>.....................] - ETA: 5s - loss: 1.6650 - accuracy: 0.2728\n",
            " 32/100 [========>.....................] - ETA: 5s - loss: 1.6646 - accuracy: 0.2702\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.6629 - accuracy: 0.2689\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.6590 - accuracy: 0.2696\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.6555 - accuracy: 0.2685\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.6535 - accuracy: 0.2679\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.6476 - accuracy: 0.2691\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.6433 - accuracy: 0.2670\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.6448 - accuracy: 0.2671\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.6437 - accuracy: 0.2661\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.6407 - accuracy: 0.2668\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.6412 - accuracy: 0.2639\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.6366 - accuracy: 0.2650\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.6330 - accuracy: 0.2647\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.6307 - accuracy: 0.2630\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.6305 - accuracy: 0.2609\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.6302 - accuracy: 0.2589\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.6286 - accuracy: 0.2582\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.6264 - accuracy: 0.2594\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.6245 - accuracy: 0.2579\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.6219 - accuracy: 0.2561\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.6186 - accuracy: 0.2552\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.6212 - accuracy: 0.2531\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.6181 - accuracy: 0.2523\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.6145 - accuracy: 0.2523\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.6156 - accuracy: 0.2511\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.6142 - accuracy: 0.2507\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.6128 - accuracy: 0.2514\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.6117 - accuracy: 0.2521\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.6128 - accuracy: 0.2514\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.6102 - accuracy: 0.2514\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.6092 - accuracy: 0.2513\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.6078 - accuracy: 0.2507\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.6085 - accuracy: 0.2507\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.6056 - accuracy: 0.2519\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.6031 - accuracy: 0.2525\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.6002 - accuracy: 0.2544\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.6012 - accuracy: 0.2540\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.6006 - accuracy: 0.2539\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.6023 - accuracy: 0.2536\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.6015 - accuracy: 0.2535\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.5997 - accuracy: 0.2529\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.5995 - accuracy: 0.2523\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.5973 - accuracy: 0.2525\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.5990 - accuracy: 0.2506\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.5982 - accuracy: 0.2497\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.5972 - accuracy: 0.2503\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.5950 - accuracy: 0.2513\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.5928 - accuracy: 0.2513\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.5923 - accuracy: 0.2521\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.5918 - accuracy: 0.2513\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.5892 - accuracy: 0.2523\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.5871 - accuracy: 0.2518\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.5863 - accuracy: 0.2517\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.5862 - accuracy: 0.2517\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.5863 - accuracy: 0.2517\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.5849 - accuracy: 0.2534\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.5851 - accuracy: 0.2528\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.5845 - accuracy: 0.2523\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.5835 - accuracy: 0.2528\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.5813 - accuracy: 0.2537\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.5818 - accuracy: 0.2532\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.5819 - accuracy: 0.2529\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.5824 - accuracy: 0.2529\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.5817 - accuracy: 0.2526\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.5797 - accuracy: 0.2522\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.5788 - accuracy: 0.2519\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.5773 - accuracy: 0.2519\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.5757 - accuracy: 0.2527\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.5763 - accuracy: 0.2523\n",
            "100/100 [==============================] - 24s 120ms/step - loss: 1.5763 - accuracy: 0.2523 - val_loss: 1.8617 - val_accuracy: 0.2031\n",
            "\n",
            "Epoch 2/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 17s - loss: 1.4536 - accuracy: 0.2917\n",
            "  2/100 [..............................] - ETA: 10s - loss: 1.6075 - accuracy: 0.2500\n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.5785 - accuracy: 0.2292 \n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.5756 - accuracy: 0.2396\n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.5612 - accuracy: 0.2500\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.5693 - accuracy: 0.2535\n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.5571 - accuracy: 0.2679\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.5597 - accuracy: 0.2578\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.5437 - accuracy: 0.2569\n",
            " 10/100 [==>...........................] - ETA: 9s - loss: 1.5430 - accuracy: 0.2562\n",
            " 11/100 [==>...........................] - ETA: 9s - loss: 1.5516 - accuracy: 0.2595\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.5367 - accuracy: 0.2622\n",
            " 13/100 [==>...........................] - ETA: 9s - loss: 1.5341 - accuracy: 0.2628\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.5236 - accuracy: 0.2693\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.5133 - accuracy: 0.2681\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.5098 - accuracy: 0.2643\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.5098 - accuracy: 0.2610\n",
            " 18/100 [====>.........................] - ETA: 8s - loss: 1.5075 - accuracy: 0.2616\n",
            " 19/100 [====>.........................] - ETA: 8s - loss: 1.5085 - accuracy: 0.2610\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.5079 - accuracy: 0.2594\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.5065 - accuracy: 0.2550\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.5037 - accuracy: 0.2585\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.5001 - accuracy: 0.2600\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.5077 - accuracy: 0.2569\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.5041 - accuracy: 0.2600\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.5044 - accuracy: 0.2604\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.5073 - accuracy: 0.2577\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.5078 - accuracy: 0.2574\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.5065 - accuracy: 0.2608\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.5039 - accuracy: 0.2611\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.4999 - accuracy: 0.2641\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.4937 - accuracy: 0.2689\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.4918 - accuracy: 0.2677\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.4918 - accuracy: 0.2665\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.4909 - accuracy: 0.2655\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.4860 - accuracy: 0.2674\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.4879 - accuracy: 0.2675\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.4864 - accuracy: 0.2681\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.4898 - accuracy: 0.2698\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.4933 - accuracy: 0.2703\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.4962 - accuracy: 0.2698\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.4941 - accuracy: 0.2713\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.4921 - accuracy: 0.2713\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.4900 - accuracy: 0.2718\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.4918 - accuracy: 0.2708\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.4935 - accuracy: 0.2681\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.4939 - accuracy: 0.2682\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.4945 - accuracy: 0.2665\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.4915 - accuracy: 0.2696\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.4922 - accuracy: 0.2683\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.4907 - accuracy: 0.2667\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.4896 - accuracy: 0.2676\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.4882 - accuracy: 0.2681\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.4873 - accuracy: 0.2670\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.4859 - accuracy: 0.2670\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.4852 - accuracy: 0.2693\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.4876 - accuracy: 0.2679\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.4850 - accuracy: 0.2694\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.4834 - accuracy: 0.2701\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.4814 - accuracy: 0.2701\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.4814 - accuracy: 0.2708\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.4804 - accuracy: 0.2728\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.4797 - accuracy: 0.2731\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.4794 - accuracy: 0.2731\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.4789 - accuracy: 0.2724\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.4790 - accuracy: 0.2724\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.4793 - accuracy: 0.2702\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.4802 - accuracy: 0.2693\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.4785 - accuracy: 0.2699\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.4789 - accuracy: 0.2690\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.4785 - accuracy: 0.2688\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.4785 - accuracy: 0.2691\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.4789 - accuracy: 0.2680\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.4793 - accuracy: 0.2672\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.4800 - accuracy: 0.2669\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.4793 - accuracy: 0.2673\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.4798 - accuracy: 0.2670\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.4784 - accuracy: 0.2674\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.4767 - accuracy: 0.2685\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.4778 - accuracy: 0.2688\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.4783 - accuracy: 0.2675\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.4786 - accuracy: 0.2670\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.4781 - accuracy: 0.2673\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.4781 - accuracy: 0.2666\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.4786 - accuracy: 0.2662\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.4771 - accuracy: 0.2670\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.4770 - accuracy: 0.2665\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.4763 - accuracy: 0.2666\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.4757 - accuracy: 0.2662\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.4749 - accuracy: 0.2662\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.4744 - accuracy: 0.2653\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.4740 - accuracy: 0.2647\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.4740 - accuracy: 0.2646\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.4740 - accuracy: 0.2640\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.4751 - accuracy: 0.2629\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.4762 - accuracy: 0.2613\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.4759 - accuracy: 0.2607\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.4766 - accuracy: 0.2600\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.4764 - accuracy: 0.2595\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.4770 - accuracy: 0.2590\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 1.4770 - accuracy: 0.2590 - val_loss: 1.8244 - val_accuracy: 0.1500\n",
            "\n",
            "Epoch 3/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 18s - loss: 1.4809 - accuracy: 0.2083\n",
            "  2/100 [..............................] - ETA: 10s - loss: 1.4603 - accuracy: 0.2396\n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.4446 - accuracy: 0.2431 \n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.4247 - accuracy: 0.2604\n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.4207 - accuracy: 0.2708\n",
            "  6/100 [>.............................] - ETA: 10s - loss: 1.4333 - accuracy: 0.2674\n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.4597 - accuracy: 0.2560 \n",
            "  8/100 [=>............................] - ETA: 9s - loss: 1.4638 - accuracy: 0.2552\n",
            "  9/100 [=>............................] - ETA: 9s - loss: 1.4525 - accuracy: 0.2616\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.4553 - accuracy: 0.2521\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.4569 - accuracy: 0.2500\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.4515 - accuracy: 0.2622\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.4540 - accuracy: 0.2644\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.4569 - accuracy: 0.2649\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.4494 - accuracy: 0.2750\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.4457 - accuracy: 0.2760\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.4498 - accuracy: 0.2721\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.4515 - accuracy: 0.2731\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.4532 - accuracy: 0.2730\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.4542 - accuracy: 0.2719\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.4543 - accuracy: 0.2708\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.4490 - accuracy: 0.2737\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.4477 - accuracy: 0.2754\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.4459 - accuracy: 0.2734\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.4460 - accuracy: 0.2758\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.4445 - accuracy: 0.2764\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.4456 - accuracy: 0.2755\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.4457 - accuracy: 0.2775\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.4438 - accuracy: 0.2759\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.4424 - accuracy: 0.2785\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.4412 - accuracy: 0.2755\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.4421 - accuracy: 0.2728\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.4414 - accuracy: 0.2708\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.4434 - accuracy: 0.2702\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.4478 - accuracy: 0.2685\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.4465 - accuracy: 0.2697\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.4485 - accuracy: 0.2669\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.4462 - accuracy: 0.2670\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.4464 - accuracy: 0.2655\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.4439 - accuracy: 0.2682\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.4444 - accuracy: 0.2668\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.4430 - accuracy: 0.2669\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.4430 - accuracy: 0.2684\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.4426 - accuracy: 0.2689\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.4406 - accuracy: 0.2699\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.4401 - accuracy: 0.2708\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.4410 - accuracy: 0.2682\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.4408 - accuracy: 0.2687\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.4389 - accuracy: 0.2696\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.4358 - accuracy: 0.2721\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.4362 - accuracy: 0.2708\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.4362 - accuracy: 0.2732\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.4355 - accuracy: 0.2736\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.4342 - accuracy: 0.2743\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.4352 - accuracy: 0.2723\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.4357 - accuracy: 0.2727\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.4357 - accuracy: 0.2723\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.4341 - accuracy: 0.2723\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.4331 - accuracy: 0.2744\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.4333 - accuracy: 0.2740\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.4345 - accuracy: 0.2715\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.4336 - accuracy: 0.2718\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.4344 - accuracy: 0.2708\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.4344 - accuracy: 0.2705\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.4324 - accuracy: 0.2724\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.4325 - accuracy: 0.2715\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.4318 - accuracy: 0.2724\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.4319 - accuracy: 0.2714\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.4322 - accuracy: 0.2708\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.4317 - accuracy: 0.2717\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.4312 - accuracy: 0.2708\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.4310 - accuracy: 0.2714\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.4299 - accuracy: 0.2714\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.4299 - accuracy: 0.2720\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.4300 - accuracy: 0.2711\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.4299 - accuracy: 0.2719\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.4293 - accuracy: 0.2727\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.4294 - accuracy: 0.2719\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.4301 - accuracy: 0.2711\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.4301 - accuracy: 0.2708\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.4293 - accuracy: 0.2711\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.4284 - accuracy: 0.2726\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.4293 - accuracy: 0.2718\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.4291 - accuracy: 0.2721\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.4295 - accuracy: 0.2718\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.4282 - accuracy: 0.2728\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.4285 - accuracy: 0.2723\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.4280 - accuracy: 0.2734\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.4274 - accuracy: 0.2732\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.4267 - accuracy: 0.2748\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.4273 - accuracy: 0.2743\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.4277 - accuracy: 0.2742\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.4272 - accuracy: 0.2746\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.4274 - accuracy: 0.2735\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.4277 - accuracy: 0.2735\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.4279 - accuracy: 0.2739\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.4278 - accuracy: 0.2743\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.4274 - accuracy: 0.2738\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.4266 - accuracy: 0.2740\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.4261 - accuracy: 0.2750\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.4261 - accuracy: 0.2750 - val_loss: 1.4632 - val_accuracy: 0.2323\n",
            "\n",
            "Epoch 4/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 13s - loss: 1.5861 - accuracy: 0.1042\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.5085 - accuracy: 0.1562 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.4695 - accuracy: 0.1806\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.4516 - accuracy: 0.1823\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.4507 - accuracy: 0.2083\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.4564 - accuracy: 0.2153\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.4515 - accuracy: 0.2173\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.4562 - accuracy: 0.2161\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.4600 - accuracy: 0.2153\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.4551 - accuracy: 0.2167\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.4505 - accuracy: 0.2216\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.4483 - accuracy: 0.2309\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.4466 - accuracy: 0.2308\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.4463 - accuracy: 0.2277\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.4474 - accuracy: 0.2236\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.4426 - accuracy: 0.2292\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.4403 - accuracy: 0.2304\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.4406 - accuracy: 0.2315\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.4413 - accuracy: 0.2325\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.4405 - accuracy: 0.2313\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.4388 - accuracy: 0.2321\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.4379 - accuracy: 0.2339\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.4391 - accuracy: 0.2328\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.4371 - accuracy: 0.2352\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.4341 - accuracy: 0.2367\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.4329 - accuracy: 0.2380\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.4266 - accuracy: 0.2446\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.4306 - accuracy: 0.2426\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.4315 - accuracy: 0.2428\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.4328 - accuracy: 0.2424\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.4316 - accuracy: 0.2433\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.4289 - accuracy: 0.2487\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.4271 - accuracy: 0.2494\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.4269 - accuracy: 0.2494\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.4270 - accuracy: 0.2506\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.4254 - accuracy: 0.2535\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.4243 - accuracy: 0.2545\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.4227 - accuracy: 0.2549\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.4210 - accuracy: 0.2548\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.4206 - accuracy: 0.2547\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.4204 - accuracy: 0.2561\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.4192 - accuracy: 0.2574\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.4211 - accuracy: 0.2568\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.4201 - accuracy: 0.2566\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.4221 - accuracy: 0.2574\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.4226 - accuracy: 0.2550\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.4218 - accuracy: 0.2544\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.4219 - accuracy: 0.2548\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.4216 - accuracy: 0.2543\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.4211 - accuracy: 0.2554\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.4205 - accuracy: 0.2565\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.4192 - accuracy: 0.2596\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.4187 - accuracy: 0.2610\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.4201 - accuracy: 0.2608\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.4190 - accuracy: 0.2629\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.4186 - accuracy: 0.2634\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.4188 - accuracy: 0.2632\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.4189 - accuracy: 0.2633\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.4180 - accuracy: 0.2645\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.4181 - accuracy: 0.2642\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.4176 - accuracy: 0.2647\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.4166 - accuracy: 0.2644\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.4166 - accuracy: 0.2655\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.4161 - accuracy: 0.2663\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.4153 - accuracy: 0.2686\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.4152 - accuracy: 0.2683\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.4157 - accuracy: 0.2683\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.4162 - accuracy: 0.2669\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.4164 - accuracy: 0.2666\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.4155 - accuracy: 0.2670\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.4149 - accuracy: 0.2679\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.4144 - accuracy: 0.2679\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.4136 - accuracy: 0.2694\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.4136 - accuracy: 0.2694\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.4132 - accuracy: 0.2703\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.4124 - accuracy: 0.2728\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.4116 - accuracy: 0.2727\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.4113 - accuracy: 0.2719\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.4103 - accuracy: 0.2737\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.4101 - accuracy: 0.2740\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.4100 - accuracy: 0.2747\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.4099 - accuracy: 0.2746\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.4100 - accuracy: 0.2741\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.4102 - accuracy: 0.2733\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.4102 - accuracy: 0.2738\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.4106 - accuracy: 0.2735\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.4103 - accuracy: 0.2730\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.4100 - accuracy: 0.2734\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.4100 - accuracy: 0.2743\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.4095 - accuracy: 0.2750\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.4097 - accuracy: 0.2752\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.4097 - accuracy: 0.2758\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.4105 - accuracy: 0.2753\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.4102 - accuracy: 0.2755\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.4109 - accuracy: 0.2743\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.4106 - accuracy: 0.2750\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.4104 - accuracy: 0.2738\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.4099 - accuracy: 0.2742\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.4099 - accuracy: 0.2746\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.4100 - accuracy: 0.2744\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 1.4100 - accuracy: 0.2744 - val_loss: 1.3771 - val_accuracy: 0.2302\n",
            "\n",
            "Epoch 5/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 17s - loss: 1.4194 - accuracy: 0.2708\n",
            "  2/100 [..............................] - ETA: 13s - loss: 1.4034 - accuracy: 0.2500\n",
            "  3/100 [..............................] - ETA: 10s - loss: 1.4130 - accuracy: 0.2292\n",
            "  4/100 [>.............................] - ETA: 10s - loss: 1.4072 - accuracy: 0.2552\n",
            "  5/100 [>.............................] - ETA: 10s - loss: 1.3935 - accuracy: 0.2708\n",
            "  6/100 [>.............................] - ETA: 10s - loss: 1.3943 - accuracy: 0.2639\n",
            "  7/100 [=>............................] - ETA: 10s - loss: 1.3970 - accuracy: 0.2649\n",
            "  8/100 [=>............................] - ETA: 10s - loss: 1.4029 - accuracy: 0.2604\n",
            "  9/100 [=>............................] - ETA: 10s - loss: 1.4025 - accuracy: 0.2616\n",
            " 10/100 [==>...........................] - ETA: 9s - loss: 1.4084 - accuracy: 0.2604 \n",
            " 11/100 [==>...........................] - ETA: 9s - loss: 1.4027 - accuracy: 0.2670\n",
            " 12/100 [==>...........................] - ETA: 9s - loss: 1.4034 - accuracy: 0.2656\n",
            " 13/100 [==>...........................] - ETA: 9s - loss: 1.4025 - accuracy: 0.2628\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.4066 - accuracy: 0.2664\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.4092 - accuracy: 0.2639\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.4097 - accuracy: 0.2617\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.4072 - accuracy: 0.2635\n",
            " 18/100 [====>.........................] - ETA: 8s - loss: 1.4068 - accuracy: 0.2650\n",
            " 19/100 [====>.........................] - ETA: 8s - loss: 1.4060 - accuracy: 0.2654\n",
            " 20/100 [=====>........................] - ETA: 8s - loss: 1.4042 - accuracy: 0.2656\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.4009 - accuracy: 0.2698\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.4025 - accuracy: 0.2680\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.4054 - accuracy: 0.2663\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.4079 - accuracy: 0.2639\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.4081 - accuracy: 0.2658\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.4097 - accuracy: 0.2628\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.4110 - accuracy: 0.2616\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.4113 - accuracy: 0.2604\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.4115 - accuracy: 0.2593\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.4110 - accuracy: 0.2583\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.4111 - accuracy: 0.2601\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.4102 - accuracy: 0.2598\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.4103 - accuracy: 0.2607\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.4106 - accuracy: 0.2610\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.4116 - accuracy: 0.2583\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.4110 - accuracy: 0.2569\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.4102 - accuracy: 0.2584\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.4094 - accuracy: 0.2588\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.4102 - accuracy: 0.2564\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.4105 - accuracy: 0.2562\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.4108 - accuracy: 0.2546\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.4110 - accuracy: 0.2545\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.4100 - accuracy: 0.2544\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.4092 - accuracy: 0.2571\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.4092 - accuracy: 0.2583\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.4104 - accuracy: 0.2577\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.4118 - accuracy: 0.2553\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.4112 - accuracy: 0.2543\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.4101 - accuracy: 0.2547\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.4097 - accuracy: 0.2554\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.4089 - accuracy: 0.2569\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.4078 - accuracy: 0.2568\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.4073 - accuracy: 0.2575\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.4073 - accuracy: 0.2566\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.4071 - accuracy: 0.2561\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.4066 - accuracy: 0.2567\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.4059 - accuracy: 0.2558\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.4053 - accuracy: 0.2565\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.4058 - accuracy: 0.2567\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.4060 - accuracy: 0.2562\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.4059 - accuracy: 0.2582\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.4050 - accuracy: 0.2594\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.4059 - accuracy: 0.2593\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.4061 - accuracy: 0.2591\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.4062 - accuracy: 0.2603\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.4065 - accuracy: 0.2607\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.4063 - accuracy: 0.2615\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.4062 - accuracy: 0.2629\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.4055 - accuracy: 0.2642\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.4051 - accuracy: 0.2637\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.4057 - accuracy: 0.2626\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.4052 - accuracy: 0.2627\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.4050 - accuracy: 0.2628\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.4050 - accuracy: 0.2630\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.4049 - accuracy: 0.2622\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.4041 - accuracy: 0.2637\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.4037 - accuracy: 0.2646\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.4037 - accuracy: 0.2644\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.4037 - accuracy: 0.2648\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.4036 - accuracy: 0.2654\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.4030 - accuracy: 0.2654\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.4020 - accuracy: 0.2668\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.4014 - accuracy: 0.2663\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.4013 - accuracy: 0.2659\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.4017 - accuracy: 0.2654\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.4012 - accuracy: 0.2662\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.4008 - accuracy: 0.2663\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.4010 - accuracy: 0.2675\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.4013 - accuracy: 0.2673\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.4015 - accuracy: 0.2662\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.4016 - accuracy: 0.2663\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.4013 - accuracy: 0.2668\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.4006 - accuracy: 0.2670\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.4004 - accuracy: 0.2671\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.4011 - accuracy: 0.2664\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.4011 - accuracy: 0.2669\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.4016 - accuracy: 0.2670\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.4019 - accuracy: 0.2664\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.4017 - accuracy: 0.2662\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.4017 - accuracy: 0.2658\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 1.4017 - accuracy: 0.2658 - val_loss: 1.3740 - val_accuracy: 0.2396\n",
            "\n",
            "Epoch 6/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 18s - loss: 1.3932 - accuracy: 0.2500\n",
            "  2/100 [..............................] - ETA: 8s - loss: 1.3833 - accuracy: 0.2604 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.3869 - accuracy: 0.2500\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.3836 - accuracy: 0.2552\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3881 - accuracy: 0.2458\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3906 - accuracy: 0.2500\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3886 - accuracy: 0.2530\n",
            "  8/100 [=>............................] - ETA: 7s - loss: 1.3898 - accuracy: 0.2396\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.3926 - accuracy: 0.2338\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.3925 - accuracy: 0.2417\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3904 - accuracy: 0.2386\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3896 - accuracy: 0.2465\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3903 - accuracy: 0.2500\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3867 - accuracy: 0.2574\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3859 - accuracy: 0.2625\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3834 - accuracy: 0.2643\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3831 - accuracy: 0.2647\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3814 - accuracy: 0.2639\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3827 - accuracy: 0.2632\n",
            " 20/100 [=====>........................] - ETA: 6s - loss: 1.3828 - accuracy: 0.2635\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.3824 - accuracy: 0.2659\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3871 - accuracy: 0.2642\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3841 - accuracy: 0.2654\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3852 - accuracy: 0.2674\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3837 - accuracy: 0.2717\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3821 - accuracy: 0.2748\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3808 - accuracy: 0.2785\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3816 - accuracy: 0.2790\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3837 - accuracy: 0.2787\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3847 - accuracy: 0.2785\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3840 - accuracy: 0.2789\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3840 - accuracy: 0.2786\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3829 - accuracy: 0.2790\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3821 - accuracy: 0.2776\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3805 - accuracy: 0.2792\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3799 - accuracy: 0.2789\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3812 - accuracy: 0.2782\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3806 - accuracy: 0.2785\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3819 - accuracy: 0.2778\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3818 - accuracy: 0.2797\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3817 - accuracy: 0.2800\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3805 - accuracy: 0.2842\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3810 - accuracy: 0.2829\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3828 - accuracy: 0.2817\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3825 - accuracy: 0.2801\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3834 - accuracy: 0.2776\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3828 - accuracy: 0.2784\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3832 - accuracy: 0.2773\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3827 - accuracy: 0.2785\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3835 - accuracy: 0.2779\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3835 - accuracy: 0.2782\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3832 - accuracy: 0.2788\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3842 - accuracy: 0.2783\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3843 - accuracy: 0.2770\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3848 - accuracy: 0.2750\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3845 - accuracy: 0.2757\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3847 - accuracy: 0.2752\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3847 - accuracy: 0.2748\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3850 - accuracy: 0.2747\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3851 - accuracy: 0.2740\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3847 - accuracy: 0.2732\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3840 - accuracy: 0.2759\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3845 - accuracy: 0.2761\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3841 - accuracy: 0.2770\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3845 - accuracy: 0.2766\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3844 - accuracy: 0.2768\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3833 - accuracy: 0.2786\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3831 - accuracy: 0.2785\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3828 - accuracy: 0.2772\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3833 - accuracy: 0.2780\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3834 - accuracy: 0.2770\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3826 - accuracy: 0.2784\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3828 - accuracy: 0.2780\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3836 - accuracy: 0.2779\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3834 - accuracy: 0.2775\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3838 - accuracy: 0.2771\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3839 - accuracy: 0.2765\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3841 - accuracy: 0.2778\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3832 - accuracy: 0.2793\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3832 - accuracy: 0.2789\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3833 - accuracy: 0.2778\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3836 - accuracy: 0.2777\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3838 - accuracy: 0.2786\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3829 - accuracy: 0.2793\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3833 - accuracy: 0.2794\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3828 - accuracy: 0.2803\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3823 - accuracy: 0.2804\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3824 - accuracy: 0.2801\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3825 - accuracy: 0.2804\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3822 - accuracy: 0.2812\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3821 - accuracy: 0.2811\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3823 - accuracy: 0.2801\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3822 - accuracy: 0.2807\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3824 - accuracy: 0.2808\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3830 - accuracy: 0.2805\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3826 - accuracy: 0.2810\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3825 - accuracy: 0.2816\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3823 - accuracy: 0.2823\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3828 - accuracy: 0.2816\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3835 - accuracy: 0.2810\n",
            "100/100 [==============================] - 12s 122ms/step - loss: 1.3835 - accuracy: 0.2810 - val_loss: 1.3731 - val_accuracy: 0.2844\n",
            "\n",
            "Epoch 7/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 17s - loss: 1.4441 - accuracy: 0.2292\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.4108 - accuracy: 0.2500 \n",
            "  3/100 [..............................] - ETA: 11s - loss: 1.4087 - accuracy: 0.2639\n",
            "  4/100 [>.............................] - ETA: 10s - loss: 1.4019 - accuracy: 0.2604\n",
            "  5/100 [>.............................] - ETA: 10s - loss: 1.4030 - accuracy: 0.2667\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.4031 - accuracy: 0.2778 \n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.4020 - accuracy: 0.2827\n",
            "  8/100 [=>............................] - ETA: 9s - loss: 1.4079 - accuracy: 0.2630\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.4108 - accuracy: 0.2500\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.4056 - accuracy: 0.2604\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.4064 - accuracy: 0.2576\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.4063 - accuracy: 0.2552\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.4047 - accuracy: 0.2484\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.4062 - accuracy: 0.2485\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.4072 - accuracy: 0.2417\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.4067 - accuracy: 0.2409\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.4066 - accuracy: 0.2414\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.4035 - accuracy: 0.2500\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.4019 - accuracy: 0.2555\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.4000 - accuracy: 0.2604\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3991 - accuracy: 0.2619\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3990 - accuracy: 0.2633\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3989 - accuracy: 0.2636\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.4001 - accuracy: 0.2613\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.4017 - accuracy: 0.2642\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.4014 - accuracy: 0.2620\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.4012 - accuracy: 0.2608\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.4025 - accuracy: 0.2582\n",
            " 29/100 [=======>......................] - ETA: 7s - loss: 1.4008 - accuracy: 0.2629\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3994 - accuracy: 0.2660\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3989 - accuracy: 0.2675\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3983 - accuracy: 0.2676\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3977 - accuracy: 0.2670\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3966 - accuracy: 0.2672\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3955 - accuracy: 0.2673\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3960 - accuracy: 0.2685\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.3949 - accuracy: 0.2686\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.3957 - accuracy: 0.2675\n",
            " 39/100 [==========>...................] - ETA: 6s - loss: 1.3959 - accuracy: 0.2660\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3971 - accuracy: 0.2635\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3961 - accuracy: 0.2637\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3952 - accuracy: 0.2634\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3946 - accuracy: 0.2645\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3952 - accuracy: 0.2642\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3947 - accuracy: 0.2634\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3946 - accuracy: 0.2649\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3941 - accuracy: 0.2646\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.3937 - accuracy: 0.2639\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.3935 - accuracy: 0.2666\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3938 - accuracy: 0.2667\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3924 - accuracy: 0.2708\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3915 - accuracy: 0.2744\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3922 - accuracy: 0.2736\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3930 - accuracy: 0.2731\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3933 - accuracy: 0.2727\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3929 - accuracy: 0.2727\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3921 - accuracy: 0.2734\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.3915 - accuracy: 0.2759\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.3921 - accuracy: 0.2772\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3925 - accuracy: 0.2757\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3923 - accuracy: 0.2746\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3924 - accuracy: 0.2752\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3921 - accuracy: 0.2761\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3917 - accuracy: 0.2751\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3917 - accuracy: 0.2750\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3912 - accuracy: 0.2765\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3912 - accuracy: 0.2761\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3908 - accuracy: 0.2754\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.3907 - accuracy: 0.2742\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3904 - accuracy: 0.2729\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3902 - accuracy: 0.2732\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3900 - accuracy: 0.2717\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3898 - accuracy: 0.2717\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3892 - accuracy: 0.2725\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3895 - accuracy: 0.2719\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3900 - accuracy: 0.2711\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3896 - accuracy: 0.2716\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3893 - accuracy: 0.2732\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3887 - accuracy: 0.2729\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3890 - accuracy: 0.2729\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3883 - accuracy: 0.2737\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3874 - accuracy: 0.2757\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3878 - accuracy: 0.2743\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3880 - accuracy: 0.2733\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3881 - accuracy: 0.2730\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3882 - accuracy: 0.2730\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3880 - accuracy: 0.2735\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3870 - accuracy: 0.2746\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3869 - accuracy: 0.2748\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3867 - accuracy: 0.2752\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3864 - accuracy: 0.2754\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3859 - accuracy: 0.2767\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3857 - accuracy: 0.2778\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3853 - accuracy: 0.2786\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3853 - accuracy: 0.2787\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3856 - accuracy: 0.2778\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3854 - accuracy: 0.2779\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3863 - accuracy: 0.2764\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3865 - accuracy: 0.2765\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3861 - accuracy: 0.2763\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 1.3861 - accuracy: 0.2763 - val_loss: 1.3733 - val_accuracy: 0.2219\n",
            "\n",
            "Epoch 8/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 15s - loss: 1.3922 - accuracy: 0.3542\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.4089 - accuracy: 0.2917 \n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.4089 - accuracy: 0.2500\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.3996 - accuracy: 0.2656\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3902 - accuracy: 0.2875\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3871 - accuracy: 0.2917\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3894 - accuracy: 0.2917\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3851 - accuracy: 0.3021\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3865 - accuracy: 0.2917\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3873 - accuracy: 0.2875\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3862 - accuracy: 0.2860\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3864 - accuracy: 0.2795\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3869 - accuracy: 0.2756\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3897 - accuracy: 0.2723\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3871 - accuracy: 0.2708\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3873 - accuracy: 0.2669\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3874 - accuracy: 0.2708\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3880 - accuracy: 0.2662\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3867 - accuracy: 0.2697\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3869 - accuracy: 0.2729\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3870 - accuracy: 0.2669\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3873 - accuracy: 0.2642\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3868 - accuracy: 0.2618\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3851 - accuracy: 0.2630\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3845 - accuracy: 0.2632\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3818 - accuracy: 0.2708\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3822 - accuracy: 0.2700\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3817 - accuracy: 0.2693\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3819 - accuracy: 0.2708\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3809 - accuracy: 0.2743\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3805 - accuracy: 0.2762\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3806 - accuracy: 0.2761\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3803 - accuracy: 0.2734\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3804 - accuracy: 0.2739\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3804 - accuracy: 0.2744\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3812 - accuracy: 0.2749\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3810 - accuracy: 0.2759\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3800 - accuracy: 0.2758\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3781 - accuracy: 0.2767\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3786 - accuracy: 0.2787\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3784 - accuracy: 0.2775\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3792 - accuracy: 0.2768\n",
            " 43/100 [===========>..................] - ETA: 4s - loss: 1.3795 - accuracy: 0.2781\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3811 - accuracy: 0.2756\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3797 - accuracy: 0.2783\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3794 - accuracy: 0.2790\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3789 - accuracy: 0.2815\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3806 - accuracy: 0.2813\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3807 - accuracy: 0.2811\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3814 - accuracy: 0.2784\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3813 - accuracy: 0.2782\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3822 - accuracy: 0.2769\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3828 - accuracy: 0.2760\n",
            " 54/100 [===============>..............] - ETA: 3s - loss: 1.3823 - accuracy: 0.2747\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3820 - accuracy: 0.2739\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3821 - accuracy: 0.2727\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3819 - accuracy: 0.2741\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3825 - accuracy: 0.2737\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3824 - accuracy: 0.2740\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3831 - accuracy: 0.2729\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3833 - accuracy: 0.2719\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3834 - accuracy: 0.2722\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3841 - accuracy: 0.2692\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3841 - accuracy: 0.2695\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3843 - accuracy: 0.2705\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.3848 - accuracy: 0.2683\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3848 - accuracy: 0.2690\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3846 - accuracy: 0.2684\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3852 - accuracy: 0.2663\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3850 - accuracy: 0.2669\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3851 - accuracy: 0.2664\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3849 - accuracy: 0.2676\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3847 - accuracy: 0.2685\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3848 - accuracy: 0.2677\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3849 - accuracy: 0.2672\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3847 - accuracy: 0.2678\n",
            " 77/100 [======================>.......] - ETA: 1s - loss: 1.3847 - accuracy: 0.2673\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3844 - accuracy: 0.2681\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3845 - accuracy: 0.2674\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3842 - accuracy: 0.2674\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3845 - accuracy: 0.2659\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3837 - accuracy: 0.2683\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3833 - accuracy: 0.2676\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3831 - accuracy: 0.2676\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3835 - accuracy: 0.2681\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3835 - accuracy: 0.2691\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3838 - accuracy: 0.2699\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3836 - accuracy: 0.2692\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3830 - accuracy: 0.2701\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3833 - accuracy: 0.2699\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3833 - accuracy: 0.2690\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3838 - accuracy: 0.2688\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3840 - accuracy: 0.2688\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3841 - accuracy: 0.2686\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3845 - accuracy: 0.2684\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3843 - accuracy: 0.2693\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3843 - accuracy: 0.2691\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3843 - accuracy: 0.2698\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3847 - accuracy: 0.2687\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3847 - accuracy: 0.2696\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 1.3847 - accuracy: 0.2696 - val_loss: 1.3705 - val_accuracy: 0.2781\n",
            "\n",
            "Epoch 9/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 15s - loss: 1.3965 - accuracy: 0.2083\n",
            "  2/100 [..............................] - ETA: 11s - loss: 1.4012 - accuracy: 0.1979\n",
            "  3/100 [..............................] - ETA: 10s - loss: 1.3956 - accuracy: 0.2222\n",
            "  4/100 [>.............................] - ETA: 11s - loss: 1.3921 - accuracy: 0.2240\n",
            "  5/100 [>.............................] - ETA: 11s - loss: 1.3928 - accuracy: 0.2333\n",
            "  6/100 [>.............................] - ETA: 10s - loss: 1.3928 - accuracy: 0.2153\n",
            "  7/100 [=>............................] - ETA: 10s - loss: 1.3939 - accuracy: 0.2292\n",
            "  8/100 [=>............................] - ETA: 10s - loss: 1.3901 - accuracy: 0.2370\n",
            "  9/100 [=>............................] - ETA: 10s - loss: 1.3886 - accuracy: 0.2361\n",
            " 10/100 [==>...........................] - ETA: 9s - loss: 1.3863 - accuracy: 0.2417 \n",
            " 11/100 [==>...........................] - ETA: 9s - loss: 1.3854 - accuracy: 0.2424\n",
            " 12/100 [==>...........................] - ETA: 9s - loss: 1.3851 - accuracy: 0.2431\n",
            " 13/100 [==>...........................] - ETA: 9s - loss: 1.3855 - accuracy: 0.2404\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.3835 - accuracy: 0.2440\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.3838 - accuracy: 0.2417\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.3847 - accuracy: 0.2396\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.3846 - accuracy: 0.2439\n",
            " 18/100 [====>.........................] - ETA: 8s - loss: 1.3839 - accuracy: 0.2477\n",
            " 19/100 [====>.........................] - ETA: 8s - loss: 1.3824 - accuracy: 0.2566\n",
            " 20/100 [=====>........................] - ETA: 8s - loss: 1.3819 - accuracy: 0.2573\n",
            " 21/100 [=====>........................] - ETA: 8s - loss: 1.3826 - accuracy: 0.2540\n",
            " 22/100 [=====>........................] - ETA: 8s - loss: 1.3799 - accuracy: 0.2614\n",
            " 23/100 [=====>........................] - ETA: 8s - loss: 1.3816 - accuracy: 0.2545\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3809 - accuracy: 0.2561\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3810 - accuracy: 0.2575\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.3803 - accuracy: 0.2540\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.3809 - accuracy: 0.2523\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.3804 - accuracy: 0.2560\n",
            " 29/100 [=======>......................] - ETA: 7s - loss: 1.3809 - accuracy: 0.2565\n",
            " 30/100 [========>.....................] - ETA: 7s - loss: 1.3798 - accuracy: 0.2583\n",
            " 31/100 [========>.....................] - ETA: 7s - loss: 1.3792 - accuracy: 0.2594\n",
            " 32/100 [========>.....................] - ETA: 7s - loss: 1.3790 - accuracy: 0.2598\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3782 - accuracy: 0.2588\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3789 - accuracy: 0.2574\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3795 - accuracy: 0.2571\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3785 - accuracy: 0.2587\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.3788 - accuracy: 0.2601\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.3795 - accuracy: 0.2599\n",
            " 39/100 [==========>...................] - ETA: 6s - loss: 1.3783 - accuracy: 0.2585\n",
            " 40/100 [===========>..................] - ETA: 6s - loss: 1.3787 - accuracy: 0.2609\n",
            " 41/100 [===========>..................] - ETA: 6s - loss: 1.3800 - accuracy: 0.2607\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3792 - accuracy: 0.2614\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3787 - accuracy: 0.2592\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3785 - accuracy: 0.2599\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3787 - accuracy: 0.2606\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3782 - accuracy: 0.2627\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3789 - accuracy: 0.2615\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.3783 - accuracy: 0.2626\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.3780 - accuracy: 0.2657\n",
            " 50/100 [==============>...............] - ETA: 5s - loss: 1.3788 - accuracy: 0.2650\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3785 - accuracy: 0.2663\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3785 - accuracy: 0.2676\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3786 - accuracy: 0.2669\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3790 - accuracy: 0.2650\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3790 - accuracy: 0.2663\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3786 - accuracy: 0.2667\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3778 - accuracy: 0.2686\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.3775 - accuracy: 0.2690\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.3776 - accuracy: 0.2687\n",
            " 60/100 [=================>............] - ETA: 4s - loss: 1.3774 - accuracy: 0.2691\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3770 - accuracy: 0.2702\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3767 - accuracy: 0.2698\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3771 - accuracy: 0.2695\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3764 - accuracy: 0.2695\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3769 - accuracy: 0.2692\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3768 - accuracy: 0.2702\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3763 - accuracy: 0.2705\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3754 - accuracy: 0.2733\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.3749 - accuracy: 0.2732\n",
            " 70/100 [====================>.........] - ETA: 3s - loss: 1.3745 - accuracy: 0.2741\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3738 - accuracy: 0.2749\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3743 - accuracy: 0.2763\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3746 - accuracy: 0.2763\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3745 - accuracy: 0.2770\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3748 - accuracy: 0.2781\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3752 - accuracy: 0.2793\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3751 - accuracy: 0.2795\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3760 - accuracy: 0.2794\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3756 - accuracy: 0.2793\n",
            " 80/100 [=======================>......] - ETA: 2s - loss: 1.3752 - accuracy: 0.2802\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3756 - accuracy: 0.2796\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3757 - accuracy: 0.2792\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3761 - accuracy: 0.2784\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3761 - accuracy: 0.2793\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3756 - accuracy: 0.2797\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3756 - accuracy: 0.2796\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3757 - accuracy: 0.2792\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3760 - accuracy: 0.2786\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3760 - accuracy: 0.2779\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3759 - accuracy: 0.2778\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3762 - accuracy: 0.2768\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3765 - accuracy: 0.2758\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3766 - accuracy: 0.2753\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3769 - accuracy: 0.2739\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3773 - accuracy: 0.2737\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3773 - accuracy: 0.2743\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3779 - accuracy: 0.2738\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3781 - accuracy: 0.2734\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3782 - accuracy: 0.2729\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3783 - accuracy: 0.2727\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 1.3783 - accuracy: 0.2727 - val_loss: 1.3562 - val_accuracy: 0.3385\n",
            "\n",
            "Epoch 10/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 12s - loss: 1.3685 - accuracy: 0.2917\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.3577 - accuracy: 0.3438 \n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.3669 - accuracy: 0.3056\n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.3684 - accuracy: 0.3177\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3694 - accuracy: 0.3000\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3706 - accuracy: 0.2882\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3718 - accuracy: 0.2768\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3717 - accuracy: 0.2812\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3697 - accuracy: 0.2940\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3733 - accuracy: 0.2917\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3728 - accuracy: 0.2917\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3737 - accuracy: 0.2882\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3727 - accuracy: 0.2901\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3745 - accuracy: 0.2917\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3742 - accuracy: 0.2861\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3744 - accuracy: 0.2839\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3765 - accuracy: 0.2782\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3782 - accuracy: 0.2789\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3754 - accuracy: 0.2895\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3753 - accuracy: 0.2885\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3734 - accuracy: 0.2887\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3739 - accuracy: 0.2907\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3753 - accuracy: 0.2944\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3761 - accuracy: 0.2934\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3772 - accuracy: 0.2892\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3775 - accuracy: 0.2877\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3790 - accuracy: 0.2863\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3793 - accuracy: 0.2842\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3792 - accuracy: 0.2859\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3796 - accuracy: 0.2854\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3791 - accuracy: 0.2849\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3785 - accuracy: 0.2865\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3795 - accuracy: 0.2847\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3791 - accuracy: 0.2849\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3790 - accuracy: 0.2827\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3785 - accuracy: 0.2818\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3783 - accuracy: 0.2804\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3777 - accuracy: 0.2812\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3775 - accuracy: 0.2799\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3773 - accuracy: 0.2786\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3764 - accuracy: 0.2779\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3755 - accuracy: 0.2812\n",
            " 43/100 [===========>..................] - ETA: 4s - loss: 1.3756 - accuracy: 0.2820\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3763 - accuracy: 0.2827\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3769 - accuracy: 0.2806\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3771 - accuracy: 0.2812\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3777 - accuracy: 0.2806\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3777 - accuracy: 0.2817\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3761 - accuracy: 0.2857\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3757 - accuracy: 0.2871\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3760 - accuracy: 0.2868\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3763 - accuracy: 0.2861\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3772 - accuracy: 0.2838\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3774 - accuracy: 0.2832\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3770 - accuracy: 0.2826\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3770 - accuracy: 0.2824\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3769 - accuracy: 0.2829\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3776 - accuracy: 0.2830\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3766 - accuracy: 0.2846\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3770 - accuracy: 0.2854\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3770 - accuracy: 0.2852\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3771 - accuracy: 0.2843\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3767 - accuracy: 0.2851\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3769 - accuracy: 0.2842\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3768 - accuracy: 0.2830\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3761 - accuracy: 0.2844\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3759 - accuracy: 0.2854\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3760 - accuracy: 0.2849\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3756 - accuracy: 0.2865\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3752 - accuracy: 0.2866\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3748 - accuracy: 0.2879\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3742 - accuracy: 0.2896\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3744 - accuracy: 0.2888\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3745 - accuracy: 0.2891\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3747 - accuracy: 0.2892\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3745 - accuracy: 0.2897\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3746 - accuracy: 0.2892\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3751 - accuracy: 0.2893\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3755 - accuracy: 0.2893\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3755 - accuracy: 0.2883\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3751 - accuracy: 0.2894\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3759 - accuracy: 0.2889\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3760 - accuracy: 0.2899\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3762 - accuracy: 0.2897\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3763 - accuracy: 0.2892\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3762 - accuracy: 0.2885\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3755 - accuracy: 0.2898\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3753 - accuracy: 0.2895\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3754 - accuracy: 0.2889\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3755 - accuracy: 0.2887\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3752 - accuracy: 0.2898\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3752 - accuracy: 0.2903\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3754 - accuracy: 0.2897\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3757 - accuracy: 0.2897\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3759 - accuracy: 0.2886\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3757 - accuracy: 0.2891\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3767 - accuracy: 0.2878\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3767 - accuracy: 0.2878\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3768 - accuracy: 0.2877\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3769 - accuracy: 0.2875\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 1.3769 - accuracy: 0.2875 - val_loss: 1.3757 - val_accuracy: 0.2531\n",
            "\n",
            "Epoch 11/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 15s - loss: 1.3684 - accuracy: 0.1875\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.3626 - accuracy: 0.2500 \n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.3661 - accuracy: 0.2361\n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.3698 - accuracy: 0.2344\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3810 - accuracy: 0.2250\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.3864 - accuracy: 0.2257\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3889 - accuracy: 0.2292\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3867 - accuracy: 0.2448\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3876 - accuracy: 0.2431\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3871 - accuracy: 0.2458\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3877 - accuracy: 0.2367\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3872 - accuracy: 0.2344\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3865 - accuracy: 0.2340\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3855 - accuracy: 0.2307\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3841 - accuracy: 0.2375\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3829 - accuracy: 0.2422\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3829 - accuracy: 0.2447\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3824 - accuracy: 0.2485\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3812 - accuracy: 0.2519\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3826 - accuracy: 0.2497\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3815 - accuracy: 0.2518\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3822 - accuracy: 0.2517\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3813 - accuracy: 0.2516\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3817 - accuracy: 0.2550\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3811 - accuracy: 0.2548\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.3809 - accuracy: 0.2571\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3784 - accuracy: 0.2591\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3785 - accuracy: 0.2618\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3773 - accuracy: 0.2643\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3781 - accuracy: 0.2659\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3775 - accuracy: 0.2668\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3782 - accuracy: 0.2643\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3798 - accuracy: 0.2594\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3798 - accuracy: 0.2622\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3800 - accuracy: 0.2624\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3803 - accuracy: 0.2632\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.3804 - accuracy: 0.2640\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.3804 - accuracy: 0.2648\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3802 - accuracy: 0.2687\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3801 - accuracy: 0.2672\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3787 - accuracy: 0.2693\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3789 - accuracy: 0.2698\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3782 - accuracy: 0.2694\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3781 - accuracy: 0.2713\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3780 - accuracy: 0.2704\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3772 - accuracy: 0.2740\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3769 - accuracy: 0.2766\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.3769 - accuracy: 0.2774\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.3768 - accuracy: 0.2755\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3769 - accuracy: 0.2754\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3777 - accuracy: 0.2753\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3780 - accuracy: 0.2736\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3782 - accuracy: 0.2724\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3772 - accuracy: 0.2739\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3769 - accuracy: 0.2750\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3765 - accuracy: 0.2775\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3753 - accuracy: 0.2811\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.3754 - accuracy: 0.2809\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.3751 - accuracy: 0.2818\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3742 - accuracy: 0.2827\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3746 - accuracy: 0.2842\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3739 - accuracy: 0.2870\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3743 - accuracy: 0.2878\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3747 - accuracy: 0.2885\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3744 - accuracy: 0.2882\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3745 - accuracy: 0.2870\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3747 - accuracy: 0.2874\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3742 - accuracy: 0.2877\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.3733 - accuracy: 0.2896\n",
            " 70/100 [====================>.........] - ETA: 3s - loss: 1.3737 - accuracy: 0.2890\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3734 - accuracy: 0.2897\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3737 - accuracy: 0.2882\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3743 - accuracy: 0.2863\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3747 - accuracy: 0.2847\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3746 - accuracy: 0.2848\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3738 - accuracy: 0.2851\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3732 - accuracy: 0.2863\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3731 - accuracy: 0.2874\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3735 - accuracy: 0.2862\n",
            " 80/100 [=======================>......] - ETA: 2s - loss: 1.3732 - accuracy: 0.2873\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3735 - accuracy: 0.2860\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3730 - accuracy: 0.2882\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3728 - accuracy: 0.2877\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3730 - accuracy: 0.2882\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3730 - accuracy: 0.2883\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3727 - accuracy: 0.2890\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3727 - accuracy: 0.2888\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3728 - accuracy: 0.2889\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3725 - accuracy: 0.2884\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3724 - accuracy: 0.2880\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3723 - accuracy: 0.2874\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3725 - accuracy: 0.2881\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3725 - accuracy: 0.2883\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3737 - accuracy: 0.2875\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3732 - accuracy: 0.2878\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3729 - accuracy: 0.2893\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3731 - accuracy: 0.2881\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3734 - accuracy: 0.2874\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3738 - accuracy: 0.2862\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3731 - accuracy: 0.2873\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 1.3731 - accuracy: 0.2873 - val_loss: 1.3600 - val_accuracy: 0.2719\n",
            "\n",
            "Epoch 12/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 19s - loss: 1.3670 - accuracy: 0.3125\n",
            "  2/100 [..............................] - ETA: 10s - loss: 1.3616 - accuracy: 0.2604\n",
            "  3/100 [..............................] - ETA: 11s - loss: 1.3628 - accuracy: 0.2778\n",
            "  4/100 [>.............................] - ETA: 10s - loss: 1.3595 - accuracy: 0.3021\n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.3557 - accuracy: 0.3125 \n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3708 - accuracy: 0.2882\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3722 - accuracy: 0.2887\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3737 - accuracy: 0.2812\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3719 - accuracy: 0.2755\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3716 - accuracy: 0.2771\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3695 - accuracy: 0.2803\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.3704 - accuracy: 0.2934\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.3763 - accuracy: 0.2804\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3750 - accuracy: 0.2783\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3781 - accuracy: 0.2736\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3783 - accuracy: 0.2682\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3790 - accuracy: 0.2659\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3796 - accuracy: 0.2593\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3786 - accuracy: 0.2610\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3795 - accuracy: 0.2615\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3794 - accuracy: 0.2629\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3804 - accuracy: 0.2595\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3825 - accuracy: 0.2582\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3823 - accuracy: 0.2587\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3814 - accuracy: 0.2600\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.3827 - accuracy: 0.2604\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3817 - accuracy: 0.2600\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3825 - accuracy: 0.2574\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3820 - accuracy: 0.2601\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3825 - accuracy: 0.2576\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3814 - accuracy: 0.2601\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3814 - accuracy: 0.2585\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3813 - accuracy: 0.2607\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3812 - accuracy: 0.2616\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3808 - accuracy: 0.2619\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3800 - accuracy: 0.2645\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.3806 - accuracy: 0.2630\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3808 - accuracy: 0.2615\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3807 - accuracy: 0.2618\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3807 - accuracy: 0.2609\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3813 - accuracy: 0.2612\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3811 - accuracy: 0.2609\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3818 - accuracy: 0.2616\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3824 - accuracy: 0.2604\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3829 - accuracy: 0.2606\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3827 - accuracy: 0.2609\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3827 - accuracy: 0.2620\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3832 - accuracy: 0.2613\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3833 - accuracy: 0.2615\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3832 - accuracy: 0.2604\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3832 - accuracy: 0.2610\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3831 - accuracy: 0.2604\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3827 - accuracy: 0.2598\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3824 - accuracy: 0.2604\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3823 - accuracy: 0.2617\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3825 - accuracy: 0.2612\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3825 - accuracy: 0.2621\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3827 - accuracy: 0.2622\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3824 - accuracy: 0.2624\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3817 - accuracy: 0.2639\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3812 - accuracy: 0.2647\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3812 - accuracy: 0.2648\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3809 - accuracy: 0.2659\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3801 - accuracy: 0.2676\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3801 - accuracy: 0.2683\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3804 - accuracy: 0.2680\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3803 - accuracy: 0.2690\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3794 - accuracy: 0.2696\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3793 - accuracy: 0.2699\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3798 - accuracy: 0.2688\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3794 - accuracy: 0.2685\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3797 - accuracy: 0.2688\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3794 - accuracy: 0.2691\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3794 - accuracy: 0.2689\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3789 - accuracy: 0.2697\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3795 - accuracy: 0.2700\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3794 - accuracy: 0.2698\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3797 - accuracy: 0.2695\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3794 - accuracy: 0.2719\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3791 - accuracy: 0.2732\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3790 - accuracy: 0.2737\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3789 - accuracy: 0.2736\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3793 - accuracy: 0.2731\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3789 - accuracy: 0.2741\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3787 - accuracy: 0.2738\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3782 - accuracy: 0.2740\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3780 - accuracy: 0.2752\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3777 - accuracy: 0.2758\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3774 - accuracy: 0.2767\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3776 - accuracy: 0.2769\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3776 - accuracy: 0.2761\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3776 - accuracy: 0.2760\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3772 - accuracy: 0.2758\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3772 - accuracy: 0.2750\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3771 - accuracy: 0.2746\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3772 - accuracy: 0.2765\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3767 - accuracy: 0.2781\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3764 - accuracy: 0.2785\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3766 - accuracy: 0.2782\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3771 - accuracy: 0.2786\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 1.3771 - accuracy: 0.2786 - val_loss: 1.3601 - val_accuracy: 0.3406\n",
            "\n",
            "Epoch 13/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 14s - loss: 1.3736 - accuracy: 0.3333\n",
            "  2/100 [..............................] - ETA: 8s - loss: 1.3771 - accuracy: 0.3229 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.3827 - accuracy: 0.3194\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.3822 - accuracy: 0.3229\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3807 - accuracy: 0.3208\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.3735 - accuracy: 0.3194\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3756 - accuracy: 0.3155\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3727 - accuracy: 0.3229\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3716 - accuracy: 0.3218\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3684 - accuracy: 0.3167\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3650 - accuracy: 0.3201\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3671 - accuracy: 0.3194\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3679 - accuracy: 0.3157\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.3693 - accuracy: 0.3095\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.3684 - accuracy: 0.3125\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3686 - accuracy: 0.3086\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3717 - accuracy: 0.3076\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3693 - accuracy: 0.3125\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3687 - accuracy: 0.3158\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3693 - accuracy: 0.3135\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3699 - accuracy: 0.3165\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3694 - accuracy: 0.3172\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3693 - accuracy: 0.3161\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3673 - accuracy: 0.3160\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3679 - accuracy: 0.3142\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3690 - accuracy: 0.3109\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3706 - accuracy: 0.3079\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3698 - accuracy: 0.3080\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3698 - accuracy: 0.3075\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3690 - accuracy: 0.3063\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3682 - accuracy: 0.3071\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3674 - accuracy: 0.3034\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.3672 - accuracy: 0.3011\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.3667 - accuracy: 0.3002\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.3665 - accuracy: 0.3018\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.3656 - accuracy: 0.3015\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.3659 - accuracy: 0.2979\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3656 - accuracy: 0.2955\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3657 - accuracy: 0.2943\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3651 - accuracy: 0.2922\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3635 - accuracy: 0.2937\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3649 - accuracy: 0.2922\n",
            " 43/100 [===========>..................] - ETA: 4s - loss: 1.3647 - accuracy: 0.2951\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3635 - accuracy: 0.2973\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3654 - accuracy: 0.2958\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3676 - accuracy: 0.2944\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3671 - accuracy: 0.2943\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3682 - accuracy: 0.2912\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3682 - accuracy: 0.2921\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3679 - accuracy: 0.2925\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3678 - accuracy: 0.2913\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3676 - accuracy: 0.2921\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3668 - accuracy: 0.2921\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3664 - accuracy: 0.2913\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3659 - accuracy: 0.2920\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.3671 - accuracy: 0.2920\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.3669 - accuracy: 0.2917\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3665 - accuracy: 0.2917\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3656 - accuracy: 0.2913\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3653 - accuracy: 0.2913\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3645 - accuracy: 0.2913\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3646 - accuracy: 0.2897\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3644 - accuracy: 0.2897\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3648 - accuracy: 0.2897\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3640 - accuracy: 0.2907\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.3633 - accuracy: 0.2904\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.3640 - accuracy: 0.2910\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.3636 - accuracy: 0.2911\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3633 - accuracy: 0.2905\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3636 - accuracy: 0.2905\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3646 - accuracy: 0.2902\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3638 - accuracy: 0.2899\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3637 - accuracy: 0.2914\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3638 - accuracy: 0.2914\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3650 - accuracy: 0.2914\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3652 - accuracy: 0.2922\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3650 - accuracy: 0.2936\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.3651 - accuracy: 0.2954\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.3663 - accuracy: 0.2951\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3660 - accuracy: 0.2964\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3656 - accuracy: 0.2976\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3660 - accuracy: 0.2973\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3654 - accuracy: 0.2984\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3661 - accuracy: 0.2979\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3661 - accuracy: 0.2975\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3663 - accuracy: 0.2965\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3662 - accuracy: 0.2969\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3668 - accuracy: 0.2962\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.3670 - accuracy: 0.2961\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3670 - accuracy: 0.2965\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3665 - accuracy: 0.2974\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3665 - accuracy: 0.2980\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3672 - accuracy: 0.2970\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3674 - accuracy: 0.2968\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3678 - accuracy: 0.2963\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3676 - accuracy: 0.2973\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3681 - accuracy: 0.2966\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3679 - accuracy: 0.2966\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3681 - accuracy: 0.2957\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3680 - accuracy: 0.2965\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 1.3680 - accuracy: 0.2965 - val_loss: 1.3733 - val_accuracy: 0.2271\n",
            "\n",
            "Epoch 14/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 14s - loss: 1.3482 - accuracy: 0.3958\n",
            "  2/100 [..............................] - ETA: 8s - loss: 1.3525 - accuracy: 0.3229 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.3572 - accuracy: 0.3333\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.3576 - accuracy: 0.3333\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3574 - accuracy: 0.3125\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.3626 - accuracy: 0.2882\n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.3695 - accuracy: 0.2768\n",
            "  8/100 [=>............................] - ETA: 9s - loss: 1.3698 - accuracy: 0.2734\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3676 - accuracy: 0.2824\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3672 - accuracy: 0.2875\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3671 - accuracy: 0.2898\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.3639 - accuracy: 0.2917\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.3607 - accuracy: 0.3061\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.3572 - accuracy: 0.3095\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.3594 - accuracy: 0.3042\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.3564 - accuracy: 0.3086\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.3559 - accuracy: 0.3100\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3544 - accuracy: 0.3125\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3566 - accuracy: 0.3070\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3572 - accuracy: 0.3063\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3596 - accuracy: 0.3046\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3585 - accuracy: 0.3040\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3607 - accuracy: 0.2989\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3618 - accuracy: 0.2951\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3591 - accuracy: 0.2958\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.3585 - accuracy: 0.2997\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.3595 - accuracy: 0.2994\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3616 - accuracy: 0.2976\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3606 - accuracy: 0.3010\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3596 - accuracy: 0.3042\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3591 - accuracy: 0.3038\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3619 - accuracy: 0.2995\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3623 - accuracy: 0.2942\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3606 - accuracy: 0.2941\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3612 - accuracy: 0.2940\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3594 - accuracy: 0.2963\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.3583 - accuracy: 0.2950\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.3585 - accuracy: 0.2955\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3579 - accuracy: 0.2933\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3567 - accuracy: 0.2932\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3585 - accuracy: 0.2927\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3570 - accuracy: 0.2932\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3556 - accuracy: 0.2970\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3546 - accuracy: 0.2969\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3528 - accuracy: 0.2995\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3508 - accuracy: 0.2998\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3480 - accuracy: 0.3023\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3466 - accuracy: 0.3043\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3476 - accuracy: 0.3027\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3504 - accuracy: 0.3046\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3484 - accuracy: 0.3056\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3509 - accuracy: 0.3045\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3513 - accuracy: 0.3062\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3506 - accuracy: 0.3090\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3498 - accuracy: 0.3095\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3491 - accuracy: 0.3103\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3492 - accuracy: 0.3103\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.3498 - accuracy: 0.3096\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.3500 - accuracy: 0.3097\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3496 - accuracy: 0.3097\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3482 - accuracy: 0.3108\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3479 - accuracy: 0.3128\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3476 - accuracy: 0.3125\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3471 - accuracy: 0.3122\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3469 - accuracy: 0.3115\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3473 - accuracy: 0.3122\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3476 - accuracy: 0.3119\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3474 - accuracy: 0.3113\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.3469 - accuracy: 0.3110\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3464 - accuracy: 0.3095\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3463 - accuracy: 0.3096\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3454 - accuracy: 0.3105\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3461 - accuracy: 0.3088\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3458 - accuracy: 0.3086\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3446 - accuracy: 0.3097\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3446 - accuracy: 0.3098\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3440 - accuracy: 0.3090\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3425 - accuracy: 0.3093\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3424 - accuracy: 0.3105\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3420 - accuracy: 0.3116\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3413 - accuracy: 0.3124\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3407 - accuracy: 0.3126\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3406 - accuracy: 0.3121\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3403 - accuracy: 0.3121\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3395 - accuracy: 0.3119\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3394 - accuracy: 0.3109\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3389 - accuracy: 0.3119\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3383 - accuracy: 0.3124\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3377 - accuracy: 0.3128\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3376 - accuracy: 0.3126\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3381 - accuracy: 0.3121\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3383 - accuracy: 0.3115\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3381 - accuracy: 0.3110\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3387 - accuracy: 0.3113\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3385 - accuracy: 0.3111\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3372 - accuracy: 0.3117\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.3387 - accuracy: 0.3122\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.3374 - accuracy: 0.3128\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.3370 - accuracy: 0.3134\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.3368 - accuracy: 0.3132\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 1.3368 - accuracy: 0.3132 - val_loss: 1.4646 - val_accuracy: 0.3604\n",
            "\n",
            "Epoch 15/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 18s - loss: 1.2687 - accuracy: 0.3958\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.2882 - accuracy: 0.3854 \n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.2901 - accuracy: 0.3472\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.2862 - accuracy: 0.3229\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.2845 - accuracy: 0.3458\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.2959 - accuracy: 0.3333\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.2883 - accuracy: 0.3393\n",
            "  8/100 [=>............................] - ETA: 9s - loss: 1.3032 - accuracy: 0.3333\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3102 - accuracy: 0.3171\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.3134 - accuracy: 0.3208\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.3162 - accuracy: 0.3182\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.3260 - accuracy: 0.3177\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.3296 - accuracy: 0.3125\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.3252 - accuracy: 0.3140\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.3261 - accuracy: 0.3153\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.3226 - accuracy: 0.3216\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.3246 - accuracy: 0.3223\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.3243 - accuracy: 0.3229\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.3259 - accuracy: 0.3235\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.3283 - accuracy: 0.3187\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.3242 - accuracy: 0.3244\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.3279 - accuracy: 0.3277\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.3236 - accuracy: 0.3342\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.3226 - accuracy: 0.3359\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.3200 - accuracy: 0.3375\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.3205 - accuracy: 0.3381\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.3205 - accuracy: 0.3356\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.3181 - accuracy: 0.3371\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.3157 - accuracy: 0.3362\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.3162 - accuracy: 0.3333\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.3155 - accuracy: 0.3320\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.3185 - accuracy: 0.3288\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.3162 - accuracy: 0.3308\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.3129 - accuracy: 0.3315\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.3144 - accuracy: 0.3310\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.3131 - accuracy: 0.3304\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.3114 - accuracy: 0.3322\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.3090 - accuracy: 0.3328\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3081 - accuracy: 0.3328\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3067 - accuracy: 0.3313\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3096 - accuracy: 0.3283\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.3088 - accuracy: 0.3299\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.3096 - accuracy: 0.3295\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.3077 - accuracy: 0.3319\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.3098 - accuracy: 0.3292\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.3095 - accuracy: 0.3320\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.3101 - accuracy: 0.3311\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.3099 - accuracy: 0.3320\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.3117 - accuracy: 0.3312\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3108 - accuracy: 0.3317\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3095 - accuracy: 0.3329\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3082 - accuracy: 0.3349\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3081 - accuracy: 0.3357\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.3071 - accuracy: 0.3356\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.3079 - accuracy: 0.3337\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.3071 - accuracy: 0.3330\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.3090 - accuracy: 0.3337\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.3129 - accuracy: 0.3323\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.3113 - accuracy: 0.3333\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3115 - accuracy: 0.3326\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3106 - accuracy: 0.3330\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.3108 - accuracy: 0.3327\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3098 - accuracy: 0.3333\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.3091 - accuracy: 0.3337\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.3094 - accuracy: 0.3349\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.3101 - accuracy: 0.3343\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.3093 - accuracy: 0.3336\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.3091 - accuracy: 0.3333\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.3092 - accuracy: 0.3324\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.3096 - accuracy: 0.3318\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.3085 - accuracy: 0.3327\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.3075 - accuracy: 0.3336\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.3077 - accuracy: 0.3319\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.3076 - accuracy: 0.3328\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.3067 - accuracy: 0.3336\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.3061 - accuracy: 0.3355\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.3057 - accuracy: 0.3360\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.3056 - accuracy: 0.3365\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.3048 - accuracy: 0.3376\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.3039 - accuracy: 0.3391\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.3022 - accuracy: 0.3400\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.3031 - accuracy: 0.3399\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.3018 - accuracy: 0.3409\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.3037 - accuracy: 0.3403\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.3039 - accuracy: 0.3400\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.3043 - accuracy: 0.3396\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.3041 - accuracy: 0.3417\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.3034 - accuracy: 0.3423\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.3018 - accuracy: 0.3420\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.3013 - accuracy: 0.3431\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.3033 - accuracy: 0.3432\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.3023 - accuracy: 0.3444\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.3025 - accuracy: 0.3448\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.3018 - accuracy: 0.3449\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.3012 - accuracy: 0.3458\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.3002 - accuracy: 0.3459\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.2999 - accuracy: 0.3462\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.2987 - accuracy: 0.3469\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.2991 - accuracy: 0.3472\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2994 - accuracy: 0.3477\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 1.2994 - accuracy: 0.3477 - val_loss: 1.4875 - val_accuracy: 0.2125\n",
            "\n",
            "Epoch 16/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 13s - loss: 1.2105 - accuracy: 0.4583\n",
            "  2/100 [..............................] - ETA: 6s - loss: 1.2508 - accuracy: 0.4167 \n",
            "  3/100 [..............................] - ETA: 6s - loss: 1.2784 - accuracy: 0.3819\n",
            "  4/100 [>.............................] - ETA: 7s - loss: 1.2917 - accuracy: 0.3750\n",
            "  5/100 [>.............................] - ETA: 7s - loss: 1.2864 - accuracy: 0.3833\n",
            "  6/100 [>.............................] - ETA: 7s - loss: 1.2752 - accuracy: 0.3889\n",
            "  7/100 [=>............................] - ETA: 7s - loss: 1.2811 - accuracy: 0.4048\n",
            "  8/100 [=>............................] - ETA: 7s - loss: 1.2971 - accuracy: 0.3984\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.2981 - accuracy: 0.3935\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.2904 - accuracy: 0.3938\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.2909 - accuracy: 0.3939\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.2996 - accuracy: 0.3819\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3029 - accuracy: 0.3814\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.2993 - accuracy: 0.3795\n",
            " 15/100 [===>..........................] - ETA: 6s - loss: 1.3075 - accuracy: 0.3806\n",
            " 16/100 [===>..........................] - ETA: 6s - loss: 1.3066 - accuracy: 0.3789\n",
            " 17/100 [====>.........................] - ETA: 6s - loss: 1.3067 - accuracy: 0.3824\n",
            " 18/100 [====>.........................] - ETA: 6s - loss: 1.3063 - accuracy: 0.3866\n",
            " 19/100 [====>.........................] - ETA: 6s - loss: 1.3033 - accuracy: 0.3893\n",
            " 20/100 [=====>........................] - ETA: 6s - loss: 1.2999 - accuracy: 0.3885\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.3029 - accuracy: 0.3879\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.3088 - accuracy: 0.3797\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.3063 - accuracy: 0.3804\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.3056 - accuracy: 0.3819\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.3035 - accuracy: 0.3833\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.3031 - accuracy: 0.3790\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.2999 - accuracy: 0.3819\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.3054 - accuracy: 0.3765\n",
            " 29/100 [=======>......................] - ETA: 5s - loss: 1.3044 - accuracy: 0.3750\n",
            " 30/100 [========>.....................] - ETA: 5s - loss: 1.3040 - accuracy: 0.3750\n",
            " 31/100 [========>.....................] - ETA: 5s - loss: 1.3003 - accuracy: 0.3777\n",
            " 32/100 [========>.....................] - ETA: 5s - loss: 1.2969 - accuracy: 0.3809\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.2994 - accuracy: 0.3801\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.2973 - accuracy: 0.3811\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.2969 - accuracy: 0.3804\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.2985 - accuracy: 0.3779\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.2990 - accuracy: 0.3789\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.3045 - accuracy: 0.3734\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.3075 - accuracy: 0.3718\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.3089 - accuracy: 0.3703\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.3082 - accuracy: 0.3684\n",
            " 42/100 [===========>..................] - ETA: 4s - loss: 1.3075 - accuracy: 0.3661\n",
            " 43/100 [===========>..................] - ETA: 4s - loss: 1.3071 - accuracy: 0.3639\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.3073 - accuracy: 0.3636\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.3067 - accuracy: 0.3644\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.3060 - accuracy: 0.3637\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.3056 - accuracy: 0.3613\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.3047 - accuracy: 0.3624\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.3054 - accuracy: 0.3601\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.3050 - accuracy: 0.3583\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.3060 - accuracy: 0.3570\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.3045 - accuracy: 0.3586\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.3041 - accuracy: 0.3585\n",
            " 54/100 [===============>..............] - ETA: 3s - loss: 1.3014 - accuracy: 0.3603\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.3009 - accuracy: 0.3595\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.2999 - accuracy: 0.3586\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.2977 - accuracy: 0.3582\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.3005 - accuracy: 0.3563\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.2984 - accuracy: 0.3577\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.3000 - accuracy: 0.3556\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.3011 - accuracy: 0.3531\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.2998 - accuracy: 0.3555\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.3002 - accuracy: 0.3532\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.2997 - accuracy: 0.3522\n",
            " 65/100 [==================>...........] - ETA: 2s - loss: 1.2993 - accuracy: 0.3519\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.2982 - accuracy: 0.3520\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.2961 - accuracy: 0.3529\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.2973 - accuracy: 0.3532\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.2959 - accuracy: 0.3527\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.2954 - accuracy: 0.3527\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.2962 - accuracy: 0.3506\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.2954 - accuracy: 0.3507\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.2939 - accuracy: 0.3519\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.2915 - accuracy: 0.3533\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.2914 - accuracy: 0.3533\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.2903 - accuracy: 0.3536\n",
            " 77/100 [======================>.......] - ETA: 1s - loss: 1.2900 - accuracy: 0.3550\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.2899 - accuracy: 0.3558\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.2894 - accuracy: 0.3557\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.2904 - accuracy: 0.3552\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.2903 - accuracy: 0.3542\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.2890 - accuracy: 0.3554\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.2886 - accuracy: 0.3549\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.2870 - accuracy: 0.3554\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.2873 - accuracy: 0.3549\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.2870 - accuracy: 0.3542\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.2862 - accuracy: 0.3542\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.2877 - accuracy: 0.3542\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.2877 - accuracy: 0.3539\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.2872 - accuracy: 0.3542\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.2864 - accuracy: 0.3546\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.2858 - accuracy: 0.3544\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.2867 - accuracy: 0.3553\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.2866 - accuracy: 0.3562\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.2871 - accuracy: 0.3559\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.2864 - accuracy: 0.3557\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.2870 - accuracy: 0.3552\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.2862 - accuracy: 0.3550\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.2870 - accuracy: 0.3540\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2861 - accuracy: 0.3544\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 1.2861 - accuracy: 0.3544 - val_loss: 1.7163 - val_accuracy: 0.2542\n",
            "\n",
            "Epoch 17/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 16s - loss: 1.3583 - accuracy: 0.2500\n",
            "  2/100 [..............................] - ETA: 10s - loss: 1.3126 - accuracy: 0.3333\n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.3407 - accuracy: 0.3125 \n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.3111 - accuracy: 0.3229\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.3127 - accuracy: 0.3208\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.2996 - accuracy: 0.3229\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.3124 - accuracy: 0.3185\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.3270 - accuracy: 0.3151\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.3127 - accuracy: 0.3310\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.3110 - accuracy: 0.3333\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.3067 - accuracy: 0.3390\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.3052 - accuracy: 0.3403\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.3016 - accuracy: 0.3413\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.2998 - accuracy: 0.3363\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.2997 - accuracy: 0.3389\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.2991 - accuracy: 0.3372\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.2944 - accuracy: 0.3382\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.2879 - accuracy: 0.3426\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.2857 - accuracy: 0.3465\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.2815 - accuracy: 0.3417\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.2796 - accuracy: 0.3413\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.2767 - accuracy: 0.3428\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.2743 - accuracy: 0.3424\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.2729 - accuracy: 0.3392\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.2713 - accuracy: 0.3465\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.2701 - accuracy: 0.3468\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.2734 - accuracy: 0.3432\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.2720 - accuracy: 0.3436\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.2735 - accuracy: 0.3418\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.2713 - accuracy: 0.3429\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.2690 - accuracy: 0.3460\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.2683 - accuracy: 0.3443\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.2655 - accuracy: 0.3477\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.2643 - accuracy: 0.3479\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.2633 - accuracy: 0.3499\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.2623 - accuracy: 0.3494\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.2621 - accuracy: 0.3490\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.2626 - accuracy: 0.3475\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.2607 - accuracy: 0.3503\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.2569 - accuracy: 0.3504\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.2547 - accuracy: 0.3510\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.2532 - accuracy: 0.3546\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.2506 - accuracy: 0.3566\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.2508 - accuracy: 0.3565\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.2497 - accuracy: 0.3606\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.2510 - accuracy: 0.3587\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.2505 - accuracy: 0.3590\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.2503 - accuracy: 0.3585\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.2505 - accuracy: 0.3592\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.2484 - accuracy: 0.3583\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.2493 - accuracy: 0.3574\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.2468 - accuracy: 0.3602\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.2459 - accuracy: 0.3604\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.2491 - accuracy: 0.3599\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.2479 - accuracy: 0.3587\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.2539 - accuracy: 0.3575\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.2544 - accuracy: 0.3567\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.2545 - accuracy: 0.3556\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.2549 - accuracy: 0.3559\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.2566 - accuracy: 0.3555\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.2568 - accuracy: 0.3548\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.2576 - accuracy: 0.3551\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.2590 - accuracy: 0.3558\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.2605 - accuracy: 0.3548\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.2627 - accuracy: 0.3554\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.2644 - accuracy: 0.3560\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.2655 - accuracy: 0.3538\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.2668 - accuracy: 0.3532\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.2666 - accuracy: 0.3517\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.2670 - accuracy: 0.3506\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.2670 - accuracy: 0.3506\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.2672 - accuracy: 0.3512\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.2679 - accuracy: 0.3496\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.2689 - accuracy: 0.3488\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.2684 - accuracy: 0.3491\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.2686 - accuracy: 0.3489\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.2690 - accuracy: 0.3509\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.2698 - accuracy: 0.3499\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.2700 - accuracy: 0.3494\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.2697 - accuracy: 0.3500\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.2696 - accuracy: 0.3510\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.2691 - accuracy: 0.3526\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.2694 - accuracy: 0.3526\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.2704 - accuracy: 0.3524\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.2712 - accuracy: 0.3527\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.2719 - accuracy: 0.3520\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.2717 - accuracy: 0.3517\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.2710 - accuracy: 0.3515\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.2713 - accuracy: 0.3520\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.2714 - accuracy: 0.3523\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.2706 - accuracy: 0.3532\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.2694 - accuracy: 0.3548\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.2703 - accuracy: 0.3539\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.2700 - accuracy: 0.3544\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.2713 - accuracy: 0.3539\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.2721 - accuracy: 0.3548\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.2722 - accuracy: 0.3548\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.2728 - accuracy: 0.3548\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.2737 - accuracy: 0.3539\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2737 - accuracy: 0.3546\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 1.2737 - accuracy: 0.3546 - val_loss: 1.2731 - val_accuracy: 0.3615\n",
            "\n",
            "Epoch 18/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 11s - loss: 1.3029 - accuracy: 0.3514\n",
            "  2/100 [..............................] - ETA: 10s - loss: 1.2619 - accuracy: 0.3882\n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.2293 - accuracy: 0.4060 \n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.2226 - accuracy: 0.4199\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.2303 - accuracy: 0.4148\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.2431 - accuracy: 0.4116\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.2478 - accuracy: 0.3969\n",
            "  8/100 [=>............................] - ETA: 7s - loss: 1.2617 - accuracy: 0.3887\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.2491 - accuracy: 0.3919\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.2487 - accuracy: 0.3859\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.2580 - accuracy: 0.3752\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.2523 - accuracy: 0.3770\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.2504 - accuracy: 0.3899\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.2458 - accuracy: 0.3949\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.2415 - accuracy: 0.4006\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.2444 - accuracy: 0.3989\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.2507 - accuracy: 0.3975\n",
            " 18/100 [====>.........................] - ETA: 6s - loss: 1.2450 - accuracy: 0.3986\n",
            " 19/100 [====>.........................] - ETA: 6s - loss: 1.2406 - accuracy: 0.4018\n",
            " 20/100 [=====>........................] - ETA: 6s - loss: 1.2379 - accuracy: 0.4057\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.2442 - accuracy: 0.4012\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.2457 - accuracy: 0.4010\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.2437 - accuracy: 0.4016\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.2420 - accuracy: 0.4058\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.2400 - accuracy: 0.4054\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.2406 - accuracy: 0.4066\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.2395 - accuracy: 0.4047\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.2391 - accuracy: 0.4059\n",
            " 29/100 [=======>......................] - ETA: 5s - loss: 1.2386 - accuracy: 0.4084\n",
            " 30/100 [========>.....................] - ETA: 5s - loss: 1.2362 - accuracy: 0.4094\n",
            " 31/100 [========>.....................] - ETA: 5s - loss: 1.2350 - accuracy: 0.4062\n",
            " 32/100 [========>.....................] - ETA: 5s - loss: 1.2369 - accuracy: 0.4046\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.2372 - accuracy: 0.4050\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.2352 - accuracy: 0.4072\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.2340 - accuracy: 0.4074\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.2354 - accuracy: 0.4077\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.2371 - accuracy: 0.4062\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.2378 - accuracy: 0.4038\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.2383 - accuracy: 0.4030\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.2376 - accuracy: 0.4034\n",
            " 41/100 [===========>..................] - ETA: 4s - loss: 1.2383 - accuracy: 0.4042\n",
            " 42/100 [===========>..................] - ETA: 4s - loss: 1.2363 - accuracy: 0.4060\n",
            " 43/100 [===========>..................] - ETA: 4s - loss: 1.2389 - accuracy: 0.4043\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.2391 - accuracy: 0.4055\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.2419 - accuracy: 0.4039\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.2417 - accuracy: 0.4042\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.2409 - accuracy: 0.4040\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.2404 - accuracy: 0.4043\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.2383 - accuracy: 0.4062\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.2397 - accuracy: 0.4069\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.2401 - accuracy: 0.4062\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.2402 - accuracy: 0.4052\n",
            " 53/100 [==============>...............] - ETA: 3s - loss: 1.2414 - accuracy: 0.4031\n",
            " 54/100 [===============>..............] - ETA: 3s - loss: 1.2405 - accuracy: 0.4022\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.2388 - accuracy: 0.4024\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.2398 - accuracy: 0.4023\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.2399 - accuracy: 0.4007\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.2389 - accuracy: 0.4010\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.2395 - accuracy: 0.3991\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.2386 - accuracy: 0.3998\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.2379 - accuracy: 0.4004\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.2374 - accuracy: 0.3993\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.2374 - accuracy: 0.3979\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.2413 - accuracy: 0.3959\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.2395 - accuracy: 0.3976\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.2394 - accuracy: 0.3975\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.2389 - accuracy: 0.3978\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.2410 - accuracy: 0.3962\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.2413 - accuracy: 0.3962\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.2397 - accuracy: 0.3962\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.2405 - accuracy: 0.3945\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.2443 - accuracy: 0.3919\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.2437 - accuracy: 0.3925\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.2442 - accuracy: 0.3923\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.2442 - accuracy: 0.3929\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.2435 - accuracy: 0.3940\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.2439 - accuracy: 0.3935\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.2433 - accuracy: 0.3935\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.2445 - accuracy: 0.3922\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.2436 - accuracy: 0.3923\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.2437 - accuracy: 0.3923\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.2442 - accuracy: 0.3908\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.2439 - accuracy: 0.3927\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.2438 - accuracy: 0.3929\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.2434 - accuracy: 0.3925\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.2433 - accuracy: 0.3923\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.2439 - accuracy: 0.3921\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.2436 - accuracy: 0.3924\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.2424 - accuracy: 0.3929\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.2422 - accuracy: 0.3927\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.2421 - accuracy: 0.3927\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.2424 - accuracy: 0.3925\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.2421 - accuracy: 0.3925\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.2425 - accuracy: 0.3919\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.2416 - accuracy: 0.3928\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.2414 - accuracy: 0.3931\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.2415 - accuracy: 0.3944\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.2411 - accuracy: 0.3951\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.2416 - accuracy: 0.3942\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2425 - accuracy: 0.3936\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 1.2425 - accuracy: 0.3936 - val_loss: 1.2825 - val_accuracy: 0.3792\n",
            "\n",
            "Epoch 19/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 14s - loss: 1.2826 - accuracy: 0.3333\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.2262 - accuracy: 0.3854 \n",
            "  3/100 [..............................] - ETA: 10s - loss: 1.2413 - accuracy: 0.3681\n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.2577 - accuracy: 0.3229 \n",
            "  5/100 [>.............................] - ETA: 10s - loss: 1.3142 - accuracy: 0.3417\n",
            "  6/100 [>.............................] - ETA: 10s - loss: 1.3194 - accuracy: 0.3438\n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.3142 - accuracy: 0.3571 \n",
            "  8/100 [=>............................] - ETA: 9s - loss: 1.3087 - accuracy: 0.3672\n",
            "  9/100 [=>............................] - ETA: 9s - loss: 1.2980 - accuracy: 0.3773\n",
            " 10/100 [==>...........................] - ETA: 9s - loss: 1.2841 - accuracy: 0.3833\n",
            " 11/100 [==>...........................] - ETA: 9s - loss: 1.2821 - accuracy: 0.3864\n",
            " 12/100 [==>...........................] - ETA: 9s - loss: 1.2844 - accuracy: 0.3802\n",
            " 13/100 [==>...........................] - ETA: 9s - loss: 1.2794 - accuracy: 0.3862\n",
            " 14/100 [===>..........................] - ETA: 9s - loss: 1.2787 - accuracy: 0.3795\n",
            " 15/100 [===>..........................] - ETA: 9s - loss: 1.2753 - accuracy: 0.3764\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.2739 - accuracy: 0.3711\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.2737 - accuracy: 0.3701\n",
            " 18/100 [====>.........................] - ETA: 8s - loss: 1.2738 - accuracy: 0.3681\n",
            " 19/100 [====>.........................] - ETA: 8s - loss: 1.2766 - accuracy: 0.3651\n",
            " 20/100 [=====>........................] - ETA: 8s - loss: 1.2724 - accuracy: 0.3656\n",
            " 21/100 [=====>........................] - ETA: 8s - loss: 1.2739 - accuracy: 0.3641\n",
            " 22/100 [=====>........................] - ETA: 8s - loss: 1.2750 - accuracy: 0.3598\n",
            " 23/100 [=====>........................] - ETA: 8s - loss: 1.2692 - accuracy: 0.3668\n",
            " 24/100 [======>.......................] - ETA: 8s - loss: 1.2643 - accuracy: 0.3707\n",
            " 25/100 [======>.......................] - ETA: 8s - loss: 1.2619 - accuracy: 0.3733\n",
            " 26/100 [======>.......................] - ETA: 8s - loss: 1.2575 - accuracy: 0.3774\n",
            " 27/100 [=======>......................] - ETA: 8s - loss: 1.2549 - accuracy: 0.3796\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.2499 - accuracy: 0.3832\n",
            " 29/100 [=======>......................] - ETA: 7s - loss: 1.2556 - accuracy: 0.3836\n",
            " 30/100 [========>.....................] - ETA: 7s - loss: 1.2543 - accuracy: 0.3868\n",
            " 31/100 [========>.....................] - ETA: 7s - loss: 1.2536 - accuracy: 0.3905\n",
            " 32/100 [========>.....................] - ETA: 7s - loss: 1.2494 - accuracy: 0.3932\n",
            " 33/100 [========>.....................] - ETA: 7s - loss: 1.2466 - accuracy: 0.3952\n",
            " 34/100 [=========>....................] - ETA: 7s - loss: 1.2461 - accuracy: 0.3946\n",
            " 35/100 [=========>....................] - ETA: 7s - loss: 1.2452 - accuracy: 0.3917\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.2426 - accuracy: 0.3941\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.2481 - accuracy: 0.3941\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.2445 - accuracy: 0.3958\n",
            " 39/100 [==========>...................] - ETA: 6s - loss: 1.2485 - accuracy: 0.3942\n",
            " 40/100 [===========>..................] - ETA: 6s - loss: 1.2516 - accuracy: 0.3938\n",
            " 41/100 [===========>..................] - ETA: 6s - loss: 1.2507 - accuracy: 0.3943\n",
            " 42/100 [===========>..................] - ETA: 6s - loss: 1.2486 - accuracy: 0.3938\n",
            " 43/100 [===========>..................] - ETA: 6s - loss: 1.2491 - accuracy: 0.3939\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.2490 - accuracy: 0.3949\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.2499 - accuracy: 0.3931\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.2482 - accuracy: 0.3945\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.2456 - accuracy: 0.3963\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.2440 - accuracy: 0.3963\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.2431 - accuracy: 0.3963\n",
            " 50/100 [==============>...............] - ETA: 5s - loss: 1.2437 - accuracy: 0.3971\n",
            " 51/100 [==============>...............] - ETA: 5s - loss: 1.2434 - accuracy: 0.3983\n",
            " 52/100 [==============>...............] - ETA: 5s - loss: 1.2433 - accuracy: 0.3986\n",
            " 53/100 [==============>...............] - ETA: 5s - loss: 1.2414 - accuracy: 0.4009\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.2408 - accuracy: 0.4016\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.2421 - accuracy: 0.4015\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.2455 - accuracy: 0.3996\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.2447 - accuracy: 0.3995\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.2478 - accuracy: 0.3980\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.2460 - accuracy: 0.4001\n",
            " 60/100 [=================>............] - ETA: 4s - loss: 1.2433 - accuracy: 0.4031\n",
            " 61/100 [=================>............] - ETA: 4s - loss: 1.2420 - accuracy: 0.4044\n",
            " 62/100 [=================>............] - ETA: 4s - loss: 1.2418 - accuracy: 0.4042\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.2404 - accuracy: 0.4061\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.2381 - accuracy: 0.4089\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.2387 - accuracy: 0.4067\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.2388 - accuracy: 0.4056\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.2382 - accuracy: 0.4064\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.2384 - accuracy: 0.4066\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.2382 - accuracy: 0.4073\n",
            " 70/100 [====================>.........] - ETA: 3s - loss: 1.2399 - accuracy: 0.4057\n",
            " 71/100 [====================>.........] - ETA: 3s - loss: 1.2403 - accuracy: 0.4055\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.2401 - accuracy: 0.4060\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.2384 - accuracy: 0.4064\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.2394 - accuracy: 0.4043\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.2392 - accuracy: 0.4044\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.2372 - accuracy: 0.4049\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.2380 - accuracy: 0.4037\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.2387 - accuracy: 0.4044\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.2401 - accuracy: 0.4032\n",
            " 80/100 [=======================>......] - ETA: 2s - loss: 1.2394 - accuracy: 0.4023\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.2385 - accuracy: 0.4017\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.2401 - accuracy: 0.4004\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.2402 - accuracy: 0.3988\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.2410 - accuracy: 0.3986\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.2414 - accuracy: 0.3988\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.2412 - accuracy: 0.3992\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.2406 - accuracy: 0.4011\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.2404 - accuracy: 0.4013\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.2408 - accuracy: 0.4012\n",
            " 90/100 [==========================>...] - ETA: 1s - loss: 1.2401 - accuracy: 0.4005\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.2403 - accuracy: 0.3995\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.2394 - accuracy: 0.4006\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.2398 - accuracy: 0.4005\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.2397 - accuracy: 0.4007\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.2395 - accuracy: 0.4009\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.2420 - accuracy: 0.3995\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.2416 - accuracy: 0.3995\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.2411 - accuracy: 0.3997\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.2414 - accuracy: 0.3996\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2399 - accuracy: 0.4002\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 1.2399 - accuracy: 0.4002 - val_loss: 1.2390 - val_accuracy: 0.3125\n",
            "\n",
            "Epoch 20/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 12s - loss: 1.2513 - accuracy: 0.4792\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.1995 - accuracy: 0.4792 \n",
            "  3/100 [..............................] - ETA: 9s - loss: 1.2006 - accuracy: 0.4653\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.1922 - accuracy: 0.4688\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.1723 - accuracy: 0.4500\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.2303 - accuracy: 0.4167\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.2309 - accuracy: 0.3988\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.2367 - accuracy: 0.4036\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.2375 - accuracy: 0.4005\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.2205 - accuracy: 0.4083\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.2282 - accuracy: 0.3996\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.2331 - accuracy: 0.3976\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.2283 - accuracy: 0.3990\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.2329 - accuracy: 0.4062\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.2331 - accuracy: 0.4111\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.2285 - accuracy: 0.4115\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.2229 - accuracy: 0.4142\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.2245 - accuracy: 0.4144\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.2209 - accuracy: 0.4167\n",
            " 20/100 [=====>........................] - ETA: 6s - loss: 1.2182 - accuracy: 0.4167\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.2167 - accuracy: 0.4167\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.2145 - accuracy: 0.4157\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.2142 - accuracy: 0.4158\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.2145 - accuracy: 0.4123\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.2137 - accuracy: 0.4142\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.2158 - accuracy: 0.4087\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.2153 - accuracy: 0.4090\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.2127 - accuracy: 0.4122\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.2112 - accuracy: 0.4188\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.2098 - accuracy: 0.4153\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.2052 - accuracy: 0.4160\n",
            " 32/100 [========>.....................] - ETA: 5s - loss: 1.2073 - accuracy: 0.4128\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.2061 - accuracy: 0.4129\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.2103 - accuracy: 0.4112\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.2097 - accuracy: 0.4125\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.2102 - accuracy: 0.4149\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.2141 - accuracy: 0.4144\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.2145 - accuracy: 0.4156\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.2133 - accuracy: 0.4167\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.2132 - accuracy: 0.4161\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.2133 - accuracy: 0.4187\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.2178 - accuracy: 0.4172\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.2166 - accuracy: 0.4167\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.2188 - accuracy: 0.4176\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.2172 - accuracy: 0.4181\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.2207 - accuracy: 0.4180\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.2215 - accuracy: 0.4176\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.2224 - accuracy: 0.4162\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.2215 - accuracy: 0.4154\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.2200 - accuracy: 0.4171\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.2199 - accuracy: 0.4165\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.2187 - accuracy: 0.4181\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.2200 - accuracy: 0.4161\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.2203 - accuracy: 0.4165\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.2189 - accuracy: 0.4176\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.2236 - accuracy: 0.4169\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.2229 - accuracy: 0.4180\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.2245 - accuracy: 0.4154\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.2229 - accuracy: 0.4186\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.2235 - accuracy: 0.4176\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.2235 - accuracy: 0.4169\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.2262 - accuracy: 0.4152\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.2247 - accuracy: 0.4152\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.2247 - accuracy: 0.4142\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.2242 - accuracy: 0.4146\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.2228 - accuracy: 0.4150\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.2224 - accuracy: 0.4147\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.2231 - accuracy: 0.4150\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.2239 - accuracy: 0.4156\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.2243 - accuracy: 0.4145\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.2237 - accuracy: 0.4145\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.2226 - accuracy: 0.4139\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.2216 - accuracy: 0.4145\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.2211 - accuracy: 0.4137\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.2183 - accuracy: 0.4157\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.2184 - accuracy: 0.4174\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.2169 - accuracy: 0.4187\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.2148 - accuracy: 0.4203\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.2144 - accuracy: 0.4205\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.2148 - accuracy: 0.4215\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.2148 - accuracy: 0.4220\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.2153 - accuracy: 0.4211\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.2150 - accuracy: 0.4216\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.2151 - accuracy: 0.4228\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.2138 - accuracy: 0.4234\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.2139 - accuracy: 0.4239\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.2148 - accuracy: 0.4223\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.2151 - accuracy: 0.4225\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.2143 - accuracy: 0.4238\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.2141 - accuracy: 0.4242\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.2143 - accuracy: 0.4246\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.2150 - accuracy: 0.4247\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.2140 - accuracy: 0.4256\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.2129 - accuracy: 0.4263\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.2129 - accuracy: 0.4258\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.2135 - accuracy: 0.4264\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.2147 - accuracy: 0.4254\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.2152 - accuracy: 0.4247\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.2145 - accuracy: 0.4246\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2138 - accuracy: 0.4247\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 1.2138 - accuracy: 0.4247 - val_loss: 1.1649 - val_accuracy: 0.4594\n",
            "\n",
            "Epoch 21/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 14s - loss: 1.1273 - accuracy: 0.4792\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.0936 - accuracy: 0.4896 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.1423 - accuracy: 0.4375\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.1576 - accuracy: 0.4323\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.1380 - accuracy: 0.4500\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.1518 - accuracy: 0.4340\n",
            "  7/100 [=>............................] - ETA: 7s - loss: 1.1503 - accuracy: 0.4435\n",
            "  8/100 [=>............................] - ETA: 7s - loss: 1.1507 - accuracy: 0.4401\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.1540 - accuracy: 0.4375\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.1611 - accuracy: 0.4417\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.1629 - accuracy: 0.4413\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.1906 - accuracy: 0.4358\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.1993 - accuracy: 0.4375\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.2033 - accuracy: 0.4330\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.2026 - accuracy: 0.4389\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.2037 - accuracy: 0.4388\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.2101 - accuracy: 0.4277\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.2025 - accuracy: 0.4306\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.2032 - accuracy: 0.4320\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.2066 - accuracy: 0.4302\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.2141 - accuracy: 0.4266\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.2189 - accuracy: 0.4252\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.2177 - accuracy: 0.4266\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.2180 - accuracy: 0.4280\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.2178 - accuracy: 0.4250\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.2183 - accuracy: 0.4239\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.2149 - accuracy: 0.4282\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.2146 - accuracy: 0.4293\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.2182 - accuracy: 0.4253\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.2172 - accuracy: 0.4257\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.2146 - accuracy: 0.4288\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.2171 - accuracy: 0.4271\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.2177 - accuracy: 0.4261\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.2178 - accuracy: 0.4271\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.2134 - accuracy: 0.4327\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.2122 - accuracy: 0.4329\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.2103 - accuracy: 0.4313\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.2123 - accuracy: 0.4287\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.2153 - accuracy: 0.4268\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.2145 - accuracy: 0.4260\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.2134 - accuracy: 0.4258\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.2131 - accuracy: 0.4276\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.2193 - accuracy: 0.4239\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.2199 - accuracy: 0.4238\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.2201 - accuracy: 0.4227\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.2179 - accuracy: 0.4248\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.2193 - accuracy: 0.4238\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.2189 - accuracy: 0.4236\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.2170 - accuracy: 0.4243\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.2149 - accuracy: 0.4258\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.2126 - accuracy: 0.4277\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.2141 - accuracy: 0.4263\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.2144 - accuracy: 0.4273\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.2135 - accuracy: 0.4263\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.2131 - accuracy: 0.4265\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.2114 - accuracy: 0.4260\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.2129 - accuracy: 0.4269\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.2115 - accuracy: 0.4264\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.2108 - accuracy: 0.4276\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.2112 - accuracy: 0.4285\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.2149 - accuracy: 0.4262\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.2116 - accuracy: 0.4274\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.2136 - accuracy: 0.4246\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.2132 - accuracy: 0.4277\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.2130 - accuracy: 0.4282\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.2130 - accuracy: 0.4283\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.2148 - accuracy: 0.4279\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.2129 - accuracy: 0.4292\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.2141 - accuracy: 0.4278\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.2144 - accuracy: 0.4283\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.2132 - accuracy: 0.4278\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.2129 - accuracy: 0.4277\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.2122 - accuracy: 0.4275\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.2116 - accuracy: 0.4282\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.2098 - accuracy: 0.4289\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.2100 - accuracy: 0.4279\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.2119 - accuracy: 0.4275\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.2131 - accuracy: 0.4265\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.2129 - accuracy: 0.4264\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.2114 - accuracy: 0.4284\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.2123 - accuracy: 0.4275\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.2111 - accuracy: 0.4271\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.2121 - accuracy: 0.4262\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.2129 - accuracy: 0.4258\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.2116 - accuracy: 0.4262\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.2107 - accuracy: 0.4264\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.2096 - accuracy: 0.4267\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.2084 - accuracy: 0.4276\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.2110 - accuracy: 0.4265\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.2101 - accuracy: 0.4273\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.2097 - accuracy: 0.4278\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.2113 - accuracy: 0.4261\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.2102 - accuracy: 0.4262\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.2104 - accuracy: 0.4255\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.2106 - accuracy: 0.4254\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.2102 - accuracy: 0.4255\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.2094 - accuracy: 0.4263\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.2092 - accuracy: 0.4264\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.2088 - accuracy: 0.4269\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.2083 - accuracy: 0.4272\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 1.2083 - accuracy: 0.4272 - val_loss: 1.1832 - val_accuracy: 0.4958\n",
            "\n",
            "Epoch 22/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 12s - loss: 1.1792 - accuracy: 0.4167\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.1362 - accuracy: 0.4375 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.1271 - accuracy: 0.4583\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.1199 - accuracy: 0.4844\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.1609 - accuracy: 0.4625\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.1750 - accuracy: 0.4444\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.1612 - accuracy: 0.4405\n",
            "  8/100 [=>............................] - ETA: 7s - loss: 1.1662 - accuracy: 0.4323\n",
            "  9/100 [=>............................] - ETA: 7s - loss: 1.1605 - accuracy: 0.4491\n",
            " 10/100 [==>...........................] - ETA: 7s - loss: 1.1862 - accuracy: 0.4292\n",
            " 11/100 [==>...........................] - ETA: 7s - loss: 1.1869 - accuracy: 0.4261\n",
            " 12/100 [==>...........................] - ETA: 7s - loss: 1.1791 - accuracy: 0.4288\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.1745 - accuracy: 0.4295\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.1643 - accuracy: 0.4360\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.1599 - accuracy: 0.4389\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.1580 - accuracy: 0.4349\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.1724 - accuracy: 0.4289\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.1697 - accuracy: 0.4340\n",
            " 19/100 [====>.........................] - ETA: 6s - loss: 1.1721 - accuracy: 0.4320\n",
            " 20/100 [=====>........................] - ETA: 6s - loss: 1.1695 - accuracy: 0.4302\n",
            " 21/100 [=====>........................] - ETA: 6s - loss: 1.1699 - accuracy: 0.4345\n",
            " 22/100 [=====>........................] - ETA: 6s - loss: 1.1648 - accuracy: 0.4394\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.1678 - accuracy: 0.4375\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.1658 - accuracy: 0.4375\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.1703 - accuracy: 0.4333\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.1706 - accuracy: 0.4343\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.1733 - accuracy: 0.4336\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.1689 - accuracy: 0.4360\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.1732 - accuracy: 0.4318\n",
            " 30/100 [========>.....................] - ETA: 5s - loss: 1.1715 - accuracy: 0.4340\n",
            " 31/100 [========>.....................] - ETA: 5s - loss: 1.1742 - accuracy: 0.4315\n",
            " 32/100 [========>.....................] - ETA: 5s - loss: 1.1737 - accuracy: 0.4310\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.1755 - accuracy: 0.4299\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.1790 - accuracy: 0.4295\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.1787 - accuracy: 0.4298\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.1782 - accuracy: 0.4306\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.1801 - accuracy: 0.4291\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.1818 - accuracy: 0.4249\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.1793 - accuracy: 0.4263\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.1814 - accuracy: 0.4255\n",
            " 41/100 [===========>..................] - ETA: 4s - loss: 1.1834 - accuracy: 0.4253\n",
            " 42/100 [===========>..................] - ETA: 4s - loss: 1.1818 - accuracy: 0.4251\n",
            " 43/100 [===========>..................] - ETA: 4s - loss: 1.1813 - accuracy: 0.4244\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.1794 - accuracy: 0.4252\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.1779 - accuracy: 0.4259\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.1773 - accuracy: 0.4275\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.1752 - accuracy: 0.4304\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.1722 - accuracy: 0.4345\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.1735 - accuracy: 0.4324\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.1734 - accuracy: 0.4317\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.1737 - accuracy: 0.4346\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.1704 - accuracy: 0.4375\n",
            " 53/100 [==============>...............] - ETA: 3s - loss: 1.1691 - accuracy: 0.4371\n",
            " 54/100 [===============>..............] - ETA: 3s - loss: 1.1683 - accuracy: 0.4375\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.1694 - accuracy: 0.4379\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.1716 - accuracy: 0.4364\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.1712 - accuracy: 0.4375\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.1709 - accuracy: 0.4382\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.1726 - accuracy: 0.4389\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.1746 - accuracy: 0.4399\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.1736 - accuracy: 0.4395\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.1729 - accuracy: 0.4402\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.1723 - accuracy: 0.4408\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.1722 - accuracy: 0.4417\n",
            " 65/100 [==================>...........] - ETA: 2s - loss: 1.1739 - accuracy: 0.4417\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.1741 - accuracy: 0.4419\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.1737 - accuracy: 0.4419\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.1736 - accuracy: 0.4427\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.1706 - accuracy: 0.4441\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.1696 - accuracy: 0.4455\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.1717 - accuracy: 0.4442\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.1715 - accuracy: 0.4439\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.1695 - accuracy: 0.4441\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.1673 - accuracy: 0.4445\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.1675 - accuracy: 0.4458\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.1674 - accuracy: 0.4463\n",
            " 77/100 [======================>.......] - ETA: 1s - loss: 1.1673 - accuracy: 0.4462\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.1684 - accuracy: 0.4471\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.1680 - accuracy: 0.4475\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.1678 - accuracy: 0.4466\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.1669 - accuracy: 0.4486\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.1676 - accuracy: 0.4482\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.1683 - accuracy: 0.4480\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.1688 - accuracy: 0.4484\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.1693 - accuracy: 0.4488\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.1718 - accuracy: 0.4482\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.1733 - accuracy: 0.4476\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.1734 - accuracy: 0.4477\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.1752 - accuracy: 0.4476\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.1755 - accuracy: 0.4475\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.1751 - accuracy: 0.4476\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.1745 - accuracy: 0.4488\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.1742 - accuracy: 0.4483\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.1748 - accuracy: 0.4481\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.1743 - accuracy: 0.4478\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.1740 - accuracy: 0.4492\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.1731 - accuracy: 0.4497\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.1726 - accuracy: 0.4496\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.1766 - accuracy: 0.4476\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.1758 - accuracy: 0.4471\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 1.1758 - accuracy: 0.4471 - val_loss: 1.1121 - val_accuracy: 0.5208\n",
            "\n",
            "Epoch 23/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 19s - loss: 1.3780 - accuracy: 0.3333\n",
            "  2/100 [..............................] - ETA: 10s - loss: 1.2030 - accuracy: 0.4688\n",
            "  3/100 [..............................] - ETA: 10s - loss: 1.2012 - accuracy: 0.4514\n",
            "  4/100 [>.............................] - ETA: 9s - loss: 1.1969 - accuracy: 0.4010 \n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.1744 - accuracy: 0.4208\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.1725 - accuracy: 0.4271\n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.1646 - accuracy: 0.4286\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.1518 - accuracy: 0.4323\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.1569 - accuracy: 0.4329\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.1545 - accuracy: 0.4292\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.1577 - accuracy: 0.4318\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.1516 - accuracy: 0.4392\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.1527 - accuracy: 0.4519\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.1458 - accuracy: 0.4479\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.1436 - accuracy: 0.4597\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.1515 - accuracy: 0.4531\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.1448 - accuracy: 0.4559\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.1473 - accuracy: 0.4549\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.1457 - accuracy: 0.4496\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.1395 - accuracy: 0.4531\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.1390 - accuracy: 0.4563\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.1356 - accuracy: 0.4574\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.1401 - accuracy: 0.4529\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.1442 - accuracy: 0.4531\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.1452 - accuracy: 0.4542\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.1430 - accuracy: 0.4575\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.1463 - accuracy: 0.4583\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.1482 - accuracy: 0.4568\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.1481 - accuracy: 0.4562\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.1471 - accuracy: 0.4569\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.1455 - accuracy: 0.4583\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.1489 - accuracy: 0.4596\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.1522 - accuracy: 0.4609\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.1510 - accuracy: 0.4602\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.1537 - accuracy: 0.4625\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.1575 - accuracy: 0.4630\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.1599 - accuracy: 0.4617\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.1599 - accuracy: 0.4627\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.1648 - accuracy: 0.4599\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.1672 - accuracy: 0.4578\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.1699 - accuracy: 0.4578\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.1693 - accuracy: 0.4588\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.1689 - accuracy: 0.4578\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.1675 - accuracy: 0.4583\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.1676 - accuracy: 0.4588\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.1684 - accuracy: 0.4592\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.1671 - accuracy: 0.4601\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.1680 - accuracy: 0.4592\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.1652 - accuracy: 0.4609\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.1655 - accuracy: 0.4596\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.1649 - accuracy: 0.4587\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.1676 - accuracy: 0.4607\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.1651 - accuracy: 0.4627\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.1635 - accuracy: 0.4618\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.1632 - accuracy: 0.4617\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.1644 - accuracy: 0.4606\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.1651 - accuracy: 0.4602\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.1654 - accuracy: 0.4598\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.1646 - accuracy: 0.4605\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.1604 - accuracy: 0.4628\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.1620 - accuracy: 0.4624\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.1627 - accuracy: 0.4637\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.1621 - accuracy: 0.4640\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.1636 - accuracy: 0.4632\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.1635 - accuracy: 0.4631\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.1654 - accuracy: 0.4621\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.1665 - accuracy: 0.4627\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.1646 - accuracy: 0.4635\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.1628 - accuracy: 0.4650\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.1612 - accuracy: 0.4667\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.1612 - accuracy: 0.4660\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.1621 - accuracy: 0.4659\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.1609 - accuracy: 0.4672\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.1606 - accuracy: 0.4665\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.1622 - accuracy: 0.4664\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.1603 - accuracy: 0.4674\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.1586 - accuracy: 0.4686\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.1605 - accuracy: 0.4666\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.1602 - accuracy: 0.4668\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.1589 - accuracy: 0.4688\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.1577 - accuracy: 0.4702\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.1583 - accuracy: 0.4685\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.1593 - accuracy: 0.4677\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.1567 - accuracy: 0.4693\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.1588 - accuracy: 0.4684\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.1599 - accuracy: 0.4678\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.1610 - accuracy: 0.4667\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.1624 - accuracy: 0.4659\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.1616 - accuracy: 0.4666\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.1622 - accuracy: 0.4672\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.1617 - accuracy: 0.4684\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.1611 - accuracy: 0.4672\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.1610 - accuracy: 0.4669\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.1605 - accuracy: 0.4663\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.1598 - accuracy: 0.4658\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.1593 - accuracy: 0.4668\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.1600 - accuracy: 0.4652\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.1611 - accuracy: 0.4647\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.1625 - accuracy: 0.4640\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.1611 - accuracy: 0.4650\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 1.1611 - accuracy: 0.4650 - val_loss: 1.1833 - val_accuracy: 0.4333\n",
            "\n",
            "Epoch 24/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 11s - loss: 1.0352 - accuracy: 0.5208\n",
            "  2/100 [..............................] - ETA: 9s - loss: 1.0403 - accuracy: 0.5104 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.1052 - accuracy: 0.4444\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.1056 - accuracy: 0.4740\n",
            "  5/100 [>.............................] - ETA: 9s - loss: 1.1010 - accuracy: 0.4833\n",
            "  6/100 [>.............................] - ETA: 9s - loss: 1.1156 - accuracy: 0.4792\n",
            "  7/100 [=>............................] - ETA: 9s - loss: 1.1158 - accuracy: 0.4762\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.1123 - accuracy: 0.4870\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.1204 - accuracy: 0.4815\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.1038 - accuracy: 0.4875\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.0982 - accuracy: 0.4905\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.1021 - accuracy: 0.4931\n",
            " 13/100 [==>...........................] - ETA: 7s - loss: 1.1099 - accuracy: 0.4872\n",
            " 14/100 [===>..........................] - ETA: 7s - loss: 1.1091 - accuracy: 0.4911\n",
            " 15/100 [===>..........................] - ETA: 7s - loss: 1.1078 - accuracy: 0.4903\n",
            " 16/100 [===>..........................] - ETA: 7s - loss: 1.1067 - accuracy: 0.4909\n",
            " 17/100 [====>.........................] - ETA: 7s - loss: 1.1055 - accuracy: 0.4902\n",
            " 18/100 [====>.........................] - ETA: 7s - loss: 1.1128 - accuracy: 0.4838\n",
            " 19/100 [====>.........................] - ETA: 7s - loss: 1.1176 - accuracy: 0.4857\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.1162 - accuracy: 0.4885\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.1257 - accuracy: 0.4841\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.1270 - accuracy: 0.4830\n",
            " 23/100 [=====>........................] - ETA: 6s - loss: 1.1243 - accuracy: 0.4855\n",
            " 24/100 [======>.......................] - ETA: 6s - loss: 1.1228 - accuracy: 0.4861\n",
            " 25/100 [======>.......................] - ETA: 6s - loss: 1.1250 - accuracy: 0.4825\n",
            " 26/100 [======>.......................] - ETA: 6s - loss: 1.1279 - accuracy: 0.4784\n",
            " 27/100 [=======>......................] - ETA: 6s - loss: 1.1235 - accuracy: 0.4792\n",
            " 28/100 [=======>......................] - ETA: 6s - loss: 1.1201 - accuracy: 0.4807\n",
            " 29/100 [=======>......................] - ETA: 6s - loss: 1.1197 - accuracy: 0.4828\n",
            " 30/100 [========>.....................] - ETA: 6s - loss: 1.1191 - accuracy: 0.4819\n",
            " 31/100 [========>.....................] - ETA: 6s - loss: 1.1192 - accuracy: 0.4825\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.1214 - accuracy: 0.4818\n",
            " 33/100 [========>.....................] - ETA: 5s - loss: 1.1232 - accuracy: 0.4830\n",
            " 34/100 [=========>....................] - ETA: 5s - loss: 1.1240 - accuracy: 0.4810\n",
            " 35/100 [=========>....................] - ETA: 5s - loss: 1.1248 - accuracy: 0.4804\n",
            " 36/100 [=========>....................] - ETA: 5s - loss: 1.1254 - accuracy: 0.4803\n",
            " 37/100 [==========>...................] - ETA: 5s - loss: 1.1232 - accuracy: 0.4831\n",
            " 38/100 [==========>...................] - ETA: 5s - loss: 1.1259 - accuracy: 0.4814\n",
            " 39/100 [==========>...................] - ETA: 5s - loss: 1.1252 - accuracy: 0.4834\n",
            " 40/100 [===========>..................] - ETA: 5s - loss: 1.1276 - accuracy: 0.4823\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.1286 - accuracy: 0.4827\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.1285 - accuracy: 0.4807\n",
            " 43/100 [===========>..................] - ETA: 4s - loss: 1.1318 - accuracy: 0.4787\n",
            " 44/100 [============>.................] - ETA: 4s - loss: 1.1336 - accuracy: 0.4773\n",
            " 45/100 [============>.................] - ETA: 4s - loss: 1.1366 - accuracy: 0.4755\n",
            " 46/100 [============>.................] - ETA: 4s - loss: 1.1369 - accuracy: 0.4746\n",
            " 47/100 [=============>................] - ETA: 4s - loss: 1.1364 - accuracy: 0.4765\n",
            " 48/100 [=============>................] - ETA: 4s - loss: 1.1350 - accuracy: 0.4779\n",
            " 49/100 [=============>................] - ETA: 4s - loss: 1.1362 - accuracy: 0.4766\n",
            " 50/100 [==============>...............] - ETA: 4s - loss: 1.1360 - accuracy: 0.4771\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.1391 - accuracy: 0.4739\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.1413 - accuracy: 0.4728\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.1416 - accuracy: 0.4744\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.1423 - accuracy: 0.4749\n",
            " 55/100 [===============>..............] - ETA: 3s - loss: 1.1421 - accuracy: 0.4758\n",
            " 56/100 [===============>..............] - ETA: 3s - loss: 1.1433 - accuracy: 0.4736\n",
            " 57/100 [================>.............] - ETA: 3s - loss: 1.1437 - accuracy: 0.4737\n",
            " 58/100 [================>.............] - ETA: 3s - loss: 1.1461 - accuracy: 0.4727\n",
            " 59/100 [================>.............] - ETA: 3s - loss: 1.1472 - accuracy: 0.4728\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.1461 - accuracy: 0.4733\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.1463 - accuracy: 0.4740\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.1453 - accuracy: 0.4751\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.1449 - accuracy: 0.4759\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.1456 - accuracy: 0.4769\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.1451 - accuracy: 0.4769\n",
            " 66/100 [==================>...........] - ETA: 2s - loss: 1.1454 - accuracy: 0.4782\n",
            " 67/100 [===================>..........] - ETA: 2s - loss: 1.1470 - accuracy: 0.4757\n",
            " 68/100 [===================>..........] - ETA: 2s - loss: 1.1470 - accuracy: 0.4758\n",
            " 69/100 [===================>..........] - ETA: 2s - loss: 1.1481 - accuracy: 0.4758\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.1498 - accuracy: 0.4747\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.1528 - accuracy: 0.4733\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.1530 - accuracy: 0.4745\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.1511 - accuracy: 0.4749\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.1509 - accuracy: 0.4758\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.1495 - accuracy: 0.4764\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.1499 - accuracy: 0.4775\n",
            " 77/100 [======================>.......] - ETA: 1s - loss: 1.1486 - accuracy: 0.4784\n",
            " 78/100 [======================>.......] - ETA: 1s - loss: 1.1478 - accuracy: 0.4786\n",
            " 79/100 [======================>.......] - ETA: 1s - loss: 1.1468 - accuracy: 0.4789\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.1461 - accuracy: 0.4786\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.1464 - accuracy: 0.4787\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.1483 - accuracy: 0.4780\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.1491 - accuracy: 0.4780\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.1494 - accuracy: 0.4777\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.1488 - accuracy: 0.4783\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.1483 - accuracy: 0.4778\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.1466 - accuracy: 0.4792\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.1456 - accuracy: 0.4799\n",
            " 89/100 [=========================>....] - ETA: 0s - loss: 1.1453 - accuracy: 0.4802\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.1451 - accuracy: 0.4799\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.1453 - accuracy: 0.4806\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.1445 - accuracy: 0.4804\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.1436 - accuracy: 0.4812\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.1436 - accuracy: 0.4817\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.1431 - accuracy: 0.4823\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.1433 - accuracy: 0.4821\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.1452 - accuracy: 0.4827\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.1462 - accuracy: 0.4826\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.1457 - accuracy: 0.4832\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.1454 - accuracy: 0.4838\n",
            "100/100 [==============================] - 10s 101ms/step - loss: 1.1454 - accuracy: 0.4838 - val_loss: 1.3313 - val_accuracy: 0.3521\n",
            "\n",
            "Epoch 25/25\n",
            "\n",
            "  1/100 [..............................] - ETA: 11s - loss: 1.1504 - accuracy: 0.5208\n",
            "  2/100 [..............................] - ETA: 8s - loss: 1.1355 - accuracy: 0.5000 \n",
            "  3/100 [..............................] - ETA: 8s - loss: 1.1470 - accuracy: 0.4861\n",
            "  4/100 [>.............................] - ETA: 8s - loss: 1.1082 - accuracy: 0.5104\n",
            "  5/100 [>.............................] - ETA: 8s - loss: 1.1294 - accuracy: 0.4958\n",
            "  6/100 [>.............................] - ETA: 8s - loss: 1.1445 - accuracy: 0.4896\n",
            "  7/100 [=>............................] - ETA: 8s - loss: 1.1558 - accuracy: 0.4851\n",
            "  8/100 [=>............................] - ETA: 8s - loss: 1.1494 - accuracy: 0.4870\n",
            "  9/100 [=>............................] - ETA: 8s - loss: 1.1564 - accuracy: 0.4815\n",
            " 10/100 [==>...........................] - ETA: 8s - loss: 1.1622 - accuracy: 0.4708\n",
            " 11/100 [==>...........................] - ETA: 8s - loss: 1.1481 - accuracy: 0.4697\n",
            " 12/100 [==>...........................] - ETA: 8s - loss: 1.1413 - accuracy: 0.4774\n",
            " 13/100 [==>...........................] - ETA: 8s - loss: 1.1324 - accuracy: 0.4824\n",
            " 14/100 [===>..........................] - ETA: 8s - loss: 1.1321 - accuracy: 0.4747\n",
            " 15/100 [===>..........................] - ETA: 8s - loss: 1.1309 - accuracy: 0.4722\n",
            " 16/100 [===>..........................] - ETA: 8s - loss: 1.1382 - accuracy: 0.4740\n",
            " 17/100 [====>.........................] - ETA: 8s - loss: 1.1349 - accuracy: 0.4792\n",
            " 18/100 [====>.........................] - ETA: 8s - loss: 1.1278 - accuracy: 0.4803\n",
            " 19/100 [====>.........................] - ETA: 8s - loss: 1.1204 - accuracy: 0.4846\n",
            " 20/100 [=====>........................] - ETA: 7s - loss: 1.1162 - accuracy: 0.4906\n",
            " 21/100 [=====>........................] - ETA: 7s - loss: 1.1119 - accuracy: 0.4931\n",
            " 22/100 [=====>........................] - ETA: 7s - loss: 1.1198 - accuracy: 0.4896\n",
            " 23/100 [=====>........................] - ETA: 7s - loss: 1.1250 - accuracy: 0.4882\n",
            " 24/100 [======>.......................] - ETA: 7s - loss: 1.1248 - accuracy: 0.4861\n",
            " 25/100 [======>.......................] - ETA: 7s - loss: 1.1293 - accuracy: 0.4825\n",
            " 26/100 [======>.......................] - ETA: 7s - loss: 1.1345 - accuracy: 0.4808\n",
            " 27/100 [=======>......................] - ETA: 7s - loss: 1.1351 - accuracy: 0.4761\n",
            " 28/100 [=======>......................] - ETA: 7s - loss: 1.1284 - accuracy: 0.4792\n",
            " 29/100 [=======>......................] - ETA: 7s - loss: 1.1314 - accuracy: 0.4770\n",
            " 30/100 [========>.....................] - ETA: 7s - loss: 1.1338 - accuracy: 0.4799\n",
            " 31/100 [========>.....................] - ETA: 7s - loss: 1.1410 - accuracy: 0.4765\n",
            " 32/100 [========>.....................] - ETA: 6s - loss: 1.1491 - accuracy: 0.4766\n",
            " 33/100 [========>.....................] - ETA: 6s - loss: 1.1454 - accuracy: 0.4792\n",
            " 34/100 [=========>....................] - ETA: 6s - loss: 1.1450 - accuracy: 0.4810\n",
            " 35/100 [=========>....................] - ETA: 6s - loss: 1.1415 - accuracy: 0.4827\n",
            " 36/100 [=========>....................] - ETA: 6s - loss: 1.1404 - accuracy: 0.4832\n",
            " 37/100 [==========>...................] - ETA: 6s - loss: 1.1385 - accuracy: 0.4842\n",
            " 38/100 [==========>...................] - ETA: 6s - loss: 1.1394 - accuracy: 0.4836\n",
            " 39/100 [==========>...................] - ETA: 6s - loss: 1.1408 - accuracy: 0.4818\n",
            " 40/100 [===========>..................] - ETA: 6s - loss: 1.1438 - accuracy: 0.4807\n",
            " 41/100 [===========>..................] - ETA: 5s - loss: 1.1446 - accuracy: 0.4797\n",
            " 42/100 [===========>..................] - ETA: 5s - loss: 1.1420 - accuracy: 0.4802\n",
            " 43/100 [===========>..................] - ETA: 5s - loss: 1.1438 - accuracy: 0.4772\n",
            " 44/100 [============>.................] - ETA: 5s - loss: 1.1405 - accuracy: 0.4801\n",
            " 45/100 [============>.................] - ETA: 5s - loss: 1.1398 - accuracy: 0.4787\n",
            " 46/100 [============>.................] - ETA: 5s - loss: 1.1381 - accuracy: 0.4792\n",
            " 47/100 [=============>................] - ETA: 5s - loss: 1.1355 - accuracy: 0.4818\n",
            " 48/100 [=============>................] - ETA: 5s - loss: 1.1393 - accuracy: 0.4796\n",
            " 49/100 [=============>................] - ETA: 5s - loss: 1.1420 - accuracy: 0.4775\n",
            " 50/100 [==============>...............] - ETA: 5s - loss: 1.1415 - accuracy: 0.4779\n",
            " 51/100 [==============>...............] - ETA: 4s - loss: 1.1417 - accuracy: 0.4792\n",
            " 52/100 [==============>...............] - ETA: 4s - loss: 1.1420 - accuracy: 0.4784\n",
            " 53/100 [==============>...............] - ETA: 4s - loss: 1.1444 - accuracy: 0.4784\n",
            " 54/100 [===============>..............] - ETA: 4s - loss: 1.1438 - accuracy: 0.4772\n",
            " 55/100 [===============>..............] - ETA: 4s - loss: 1.1433 - accuracy: 0.4758\n",
            " 56/100 [===============>..............] - ETA: 4s - loss: 1.1435 - accuracy: 0.4773\n",
            " 57/100 [================>.............] - ETA: 4s - loss: 1.1455 - accuracy: 0.4762\n",
            " 58/100 [================>.............] - ETA: 4s - loss: 1.1455 - accuracy: 0.4763\n",
            " 59/100 [================>.............] - ETA: 4s - loss: 1.1474 - accuracy: 0.4763\n",
            " 60/100 [=================>............] - ETA: 3s - loss: 1.1459 - accuracy: 0.4778\n",
            " 61/100 [=================>............] - ETA: 3s - loss: 1.1448 - accuracy: 0.4788\n",
            " 62/100 [=================>............] - ETA: 3s - loss: 1.1433 - accuracy: 0.4808\n",
            " 63/100 [=================>............] - ETA: 3s - loss: 1.1432 - accuracy: 0.4798\n",
            " 64/100 [==================>...........] - ETA: 3s - loss: 1.1431 - accuracy: 0.4795\n",
            " 65/100 [==================>...........] - ETA: 3s - loss: 1.1428 - accuracy: 0.4804\n",
            " 66/100 [==================>...........] - ETA: 3s - loss: 1.1421 - accuracy: 0.4820\n",
            " 67/100 [===================>..........] - ETA: 3s - loss: 1.1451 - accuracy: 0.4810\n",
            " 68/100 [===================>..........] - ETA: 3s - loss: 1.1425 - accuracy: 0.4822\n",
            " 69/100 [===================>..........] - ETA: 3s - loss: 1.1452 - accuracy: 0.4804\n",
            " 70/100 [====================>.........] - ETA: 2s - loss: 1.1458 - accuracy: 0.4807\n",
            " 71/100 [====================>.........] - ETA: 2s - loss: 1.1451 - accuracy: 0.4803\n",
            " 72/100 [====================>.........] - ETA: 2s - loss: 1.1439 - accuracy: 0.4812\n",
            " 73/100 [====================>.........] - ETA: 2s - loss: 1.1450 - accuracy: 0.4812\n",
            " 74/100 [=====================>........] - ETA: 2s - loss: 1.1431 - accuracy: 0.4825\n",
            " 75/100 [=====================>........] - ETA: 2s - loss: 1.1429 - accuracy: 0.4828\n",
            " 76/100 [=====================>........] - ETA: 2s - loss: 1.1428 - accuracy: 0.4825\n",
            " 77/100 [======================>.......] - ETA: 2s - loss: 1.1439 - accuracy: 0.4813\n",
            " 78/100 [======================>.......] - ETA: 2s - loss: 1.1443 - accuracy: 0.4816\n",
            " 79/100 [======================>.......] - ETA: 2s - loss: 1.1428 - accuracy: 0.4826\n",
            " 80/100 [=======================>......] - ETA: 1s - loss: 1.1429 - accuracy: 0.4836\n",
            " 81/100 [=======================>......] - ETA: 1s - loss: 1.1408 - accuracy: 0.4848\n",
            " 82/100 [=======================>......] - ETA: 1s - loss: 1.1393 - accuracy: 0.4853\n",
            " 83/100 [=======================>......] - ETA: 1s - loss: 1.1384 - accuracy: 0.4857\n",
            " 84/100 [========================>.....] - ETA: 1s - loss: 1.1380 - accuracy: 0.4856\n",
            " 85/100 [========================>.....] - ETA: 1s - loss: 1.1397 - accuracy: 0.4841\n",
            " 86/100 [========================>.....] - ETA: 1s - loss: 1.1404 - accuracy: 0.4835\n",
            " 87/100 [=========================>....] - ETA: 1s - loss: 1.1405 - accuracy: 0.4837\n",
            " 88/100 [=========================>....] - ETA: 1s - loss: 1.1420 - accuracy: 0.4827\n",
            " 89/100 [=========================>....] - ETA: 1s - loss: 1.1409 - accuracy: 0.4846\n",
            " 90/100 [==========================>...] - ETA: 0s - loss: 1.1397 - accuracy: 0.4868\n",
            " 91/100 [==========================>...] - ETA: 0s - loss: 1.1388 - accuracy: 0.4870\n",
            " 92/100 [==========================>...] - ETA: 0s - loss: 1.1380 - accuracy: 0.4880\n",
            " 93/100 [==========================>...] - ETA: 0s - loss: 1.1369 - accuracy: 0.4879\n",
            " 94/100 [===========================>..] - ETA: 0s - loss: 1.1384 - accuracy: 0.4871\n",
            " 95/100 [===========================>..] - ETA: 0s - loss: 1.1376 - accuracy: 0.4882\n",
            " 96/100 [===========================>..] - ETA: 0s - loss: 1.1372 - accuracy: 0.4881\n",
            " 97/100 [============================>.] - ETA: 0s - loss: 1.1380 - accuracy: 0.4875\n",
            " 98/100 [============================>.] - ETA: 0s - loss: 1.1378 - accuracy: 0.4875\n",
            " 99/100 [============================>.] - ETA: 0s - loss: 1.1363 - accuracy: 0.4882\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.1368 - accuracy: 0.4883\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 1.1368 - accuracy: 0.4883 - val_loss: 1.0997 - val_accuracy: 0.4917\n",
            "\n",
            "100%|██████████| 10/10 [1:01:43<00:00, 370.34s/trial, best loss: -121.70133209228516]\n",
            "Best hyperparameters:\n",
            "{'learning_rate': 0.000110599529645911}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IYDJwZWmKSK6"
      },
      "outputs": [],
      "source": [
        "# Writing code to compile your model3. Using categorical crossentropy as the loss function, Adam Optimizer with  learning rate 0.000110599529645911), and set metrics to 'accuracy' as start.\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.000110599529645911) #0.0018876351674999116) #0.008663720076310137) #0.0000725) At the end the best learning rate was 0.000110599529645911\n",
        "model3.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "**Model3 was tested with different learning rates too to get the faster convergence and better performance, so learning rates tested were 0.001,0.0005, 0.000072, 0.0000725, 0.00003, 0.00002 start and Bayessian optmization was used to found even better learning rates as what is Bayessian Optimization is used in hyperparameter optimization, after Bayessian Optimization we obtained better learning rates with better results, 0.000110599529645911, #0.0018876351674999116, #0.008663720076310137, #0.0000725. In the next lines is shown 2 of the best results that were for the learning rates of 0.000110599529645911 and #0.0018876351674999116**"
      ],
      "metadata": {
        "id": "2SpVFhL9d05P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backend.clear_session() #we clean the previous session"
      ],
      "metadata": {
        "id": "LTjOs1MHEsaa"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tB9HX5sKjUL",
        "outputId": "529aa07b-809d-46ee-e4c7-1907c7ef1b0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "100/100 [==============================] - 28s 80ms/step - loss: 1.5659 - accuracy: 0.2596 - val_loss: 1.3636 - val_accuracy: 0.3754\n",
            "Epoch 2/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.4968 - accuracy: 0.2696 - val_loss: 1.3762 - val_accuracy: 0.2383\n",
            "Epoch 3/300\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 1.4682 - accuracy: 0.2723 - val_loss: 1.3611 - val_accuracy: 0.3617\n",
            "Epoch 4/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.4654 - accuracy: 0.2681 - val_loss: 1.4175 - val_accuracy: 0.2458\n",
            "Epoch 5/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.4584 - accuracy: 0.2779 - val_loss: 1.3758 - val_accuracy: 0.2454\n",
            "Epoch 6/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4587 - accuracy: 0.2604 - val_loss: 1.3855 - val_accuracy: 0.2275\n",
            "Epoch 7/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.4473 - accuracy: 0.2692 - val_loss: 1.3650 - val_accuracy: 0.3254\n",
            "Epoch 8/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.4295 - accuracy: 0.2806 - val_loss: 1.3617 - val_accuracy: 0.3237\n",
            "Epoch 9/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.4291 - accuracy: 0.2758 - val_loss: 1.3559 - val_accuracy: 0.2958\n",
            "Epoch 10/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.4133 - accuracy: 0.2802 - val_loss: 1.3687 - val_accuracy: 0.2629\n",
            "Epoch 11/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 1.4171 - accuracy: 0.2842 - val_loss: 1.4573 - val_accuracy: 0.2738\n",
            "Epoch 12/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.4005 - accuracy: 0.2994 - val_loss: 1.3236 - val_accuracy: 0.3796\n",
            "Epoch 13/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.3729 - accuracy: 0.3181 - val_loss: 1.3294 - val_accuracy: 0.3288\n",
            "Epoch 14/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.3362 - accuracy: 0.3402 - val_loss: 1.2772 - val_accuracy: 0.4067\n",
            "Epoch 15/300\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 1.3444 - accuracy: 0.3379 - val_loss: 1.2784 - val_accuracy: 0.3417\n",
            "Epoch 16/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.2928 - accuracy: 0.3606 - val_loss: 1.2917 - val_accuracy: 0.3562\n",
            "Epoch 17/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.2635 - accuracy: 0.3923 - val_loss: 1.2432 - val_accuracy: 0.4000\n",
            "Epoch 18/300\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 1.2695 - accuracy: 0.4004 - val_loss: 1.2815 - val_accuracy: 0.3950\n",
            "Epoch 19/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 1.2549 - accuracy: 0.3977 - val_loss: 1.2495 - val_accuracy: 0.4133\n",
            "Epoch 20/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.2334 - accuracy: 0.4069 - val_loss: 1.2116 - val_accuracy: 0.4421\n",
            "Epoch 21/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.2106 - accuracy: 0.4310 - val_loss: 1.1810 - val_accuracy: 0.4546\n",
            "Epoch 22/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 1.1855 - accuracy: 0.4487 - val_loss: 1.2809 - val_accuracy: 0.3375\n",
            "Epoch 23/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 1.2036 - accuracy: 0.4360 - val_loss: 1.3231 - val_accuracy: 0.3667\n",
            "Epoch 24/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.1621 - accuracy: 0.4583 - val_loss: 1.2074 - val_accuracy: 0.4367\n",
            "Epoch 25/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 1.1368 - accuracy: 0.4929 - val_loss: 1.0777 - val_accuracy: 0.5217\n",
            "Epoch 26/300\n",
            "100/100 [==============================] - 12s 115ms/step - loss: 1.1303 - accuracy: 0.4955 - val_loss: 1.0361 - val_accuracy: 0.5500\n",
            "Epoch 27/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.0966 - accuracy: 0.5033 - val_loss: 1.1745 - val_accuracy: 0.4658\n",
            "Epoch 28/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.0599 - accuracy: 0.5187 - val_loss: 1.0998 - val_accuracy: 0.4983\n",
            "Epoch 29/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.0729 - accuracy: 0.5192 - val_loss: 1.0758 - val_accuracy: 0.5346\n",
            "Epoch 30/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0530 - accuracy: 0.5294 - val_loss: 1.0592 - val_accuracy: 0.5283\n",
            "Epoch 31/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.0419 - accuracy: 0.5306 - val_loss: 1.0258 - val_accuracy: 0.5292\n",
            "Epoch 32/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.0509 - accuracy: 0.5366 - val_loss: 0.9596 - val_accuracy: 0.5913\n",
            "Epoch 33/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.0150 - accuracy: 0.5479 - val_loss: 1.0049 - val_accuracy: 0.5600\n",
            "Epoch 34/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 1.0245 - accuracy: 0.5385 - val_loss: 1.0115 - val_accuracy: 0.5387\n",
            "Epoch 35/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.9829 - accuracy: 0.5537 - val_loss: 0.9921 - val_accuracy: 0.5483\n",
            "Epoch 36/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.9881 - accuracy: 0.5679 - val_loss: 1.0248 - val_accuracy: 0.5471\n",
            "Epoch 37/300\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.9498 - accuracy: 0.5940 - val_loss: 0.9006 - val_accuracy: 0.6171\n",
            "Epoch 38/300\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.9814 - accuracy: 0.5763 - val_loss: 0.9162 - val_accuracy: 0.6083\n",
            "Epoch 39/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.9444 - accuracy: 0.5844 - val_loss: 0.9679 - val_accuracy: 0.5825\n",
            "Epoch 40/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.9363 - accuracy: 0.5958 - val_loss: 0.8750 - val_accuracy: 0.6183\n",
            "Epoch 41/300\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 0.9363 - accuracy: 0.6021 - val_loss: 0.8928 - val_accuracy: 0.6225\n",
            "Epoch 42/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.9317 - accuracy: 0.5942 - val_loss: 0.8977 - val_accuracy: 0.6133\n",
            "Epoch 43/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9120 - accuracy: 0.6079 - val_loss: 0.8976 - val_accuracy: 0.6304\n",
            "Epoch 44/300\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.8913 - accuracy: 0.6146 - val_loss: 0.8754 - val_accuracy: 0.6133\n",
            "Epoch 45/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.9218 - accuracy: 0.6101 - val_loss: 0.8452 - val_accuracy: 0.6417\n",
            "Epoch 46/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8901 - accuracy: 0.6196 - val_loss: 0.9114 - val_accuracy: 0.6092\n",
            "Epoch 47/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8983 - accuracy: 0.6137 - val_loss: 0.8463 - val_accuracy: 0.6313\n",
            "Epoch 48/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.8699 - accuracy: 0.6139 - val_loss: 0.8268 - val_accuracy: 0.6396\n",
            "Epoch 49/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.8672 - accuracy: 0.6317 - val_loss: 0.9099 - val_accuracy: 0.6304\n",
            "Epoch 50/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8742 - accuracy: 0.6265 - val_loss: 0.8720 - val_accuracy: 0.6338\n",
            "Epoch 51/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.8611 - accuracy: 0.6338 - val_loss: 0.8195 - val_accuracy: 0.6604\n",
            "Epoch 52/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8496 - accuracy: 0.6392 - val_loss: 0.8220 - val_accuracy: 0.6579\n",
            "Epoch 53/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8368 - accuracy: 0.6381 - val_loss: 0.7970 - val_accuracy: 0.6696\n",
            "Epoch 54/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.8427 - accuracy: 0.6381 - val_loss: 0.8441 - val_accuracy: 0.6442\n",
            "Epoch 55/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.8339 - accuracy: 0.6515 - val_loss: 0.7997 - val_accuracy: 0.6771\n",
            "Epoch 56/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8250 - accuracy: 0.6415 - val_loss: 0.7770 - val_accuracy: 0.6804\n",
            "Epoch 57/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.8175 - accuracy: 0.6583 - val_loss: 0.8067 - val_accuracy: 0.6662\n",
            "Epoch 58/300\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.8106 - accuracy: 0.6556 - val_loss: 0.8294 - val_accuracy: 0.6767\n",
            "Epoch 59/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8248 - accuracy: 0.6496 - val_loss: 0.8215 - val_accuracy: 0.6546\n",
            "Epoch 60/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.8181 - accuracy: 0.6504 - val_loss: 0.8384 - val_accuracy: 0.6667\n",
            "Epoch 61/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.8202 - accuracy: 0.6587 - val_loss: 0.7637 - val_accuracy: 0.6829\n",
            "Epoch 62/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.7996 - accuracy: 0.6642 - val_loss: 0.7754 - val_accuracy: 0.6750\n",
            "Epoch 63/300\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.8076 - accuracy: 0.6660 - val_loss: 0.7871 - val_accuracy: 0.6687\n",
            "Epoch 64/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7876 - accuracy: 0.6681 - val_loss: 0.7597 - val_accuracy: 0.6867\n",
            "Epoch 65/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7956 - accuracy: 0.6758 - val_loss: 0.7552 - val_accuracy: 0.6779\n",
            "Epoch 66/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.7799 - accuracy: 0.6791 - val_loss: 0.8175 - val_accuracy: 0.6683\n",
            "Epoch 67/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7572 - accuracy: 0.6834 - val_loss: 0.7778 - val_accuracy: 0.6842\n",
            "Epoch 68/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7639 - accuracy: 0.6860 - val_loss: 0.8017 - val_accuracy: 0.6617\n",
            "Epoch 69/300\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.7487 - accuracy: 0.6857 - val_loss: 0.7571 - val_accuracy: 0.7004\n",
            "Epoch 70/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7538 - accuracy: 0.6915 - val_loss: 0.7537 - val_accuracy: 0.6767\n",
            "Epoch 71/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7549 - accuracy: 0.6738 - val_loss: 0.7899 - val_accuracy: 0.6829\n",
            "Epoch 72/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.7397 - accuracy: 0.6930 - val_loss: 0.7796 - val_accuracy: 0.6783\n",
            "Epoch 73/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7346 - accuracy: 0.6915 - val_loss: 0.7889 - val_accuracy: 0.6800\n",
            "Epoch 74/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7368 - accuracy: 0.6972 - val_loss: 0.7760 - val_accuracy: 0.6858\n",
            "Epoch 75/300\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.7203 - accuracy: 0.7058 - val_loss: 0.8056 - val_accuracy: 0.6567\n",
            "Epoch 76/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7406 - accuracy: 0.6981 - val_loss: 0.7671 - val_accuracy: 0.6892\n",
            "Epoch 77/300\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.7106 - accuracy: 0.7040 - val_loss: 0.7270 - val_accuracy: 0.7117\n",
            "Epoch 78/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6982 - accuracy: 0.7171 - val_loss: 0.7901 - val_accuracy: 0.6988\n",
            "Epoch 79/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7043 - accuracy: 0.7162 - val_loss: 0.7456 - val_accuracy: 0.7050\n",
            "Epoch 80/300\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.7004 - accuracy: 0.7065 - val_loss: 0.7083 - val_accuracy: 0.7021\n",
            "Epoch 81/300\n",
            "100/100 [==============================] - 13s 133ms/step - loss: 0.6852 - accuracy: 0.7250 - val_loss: 0.7961 - val_accuracy: 0.6829\n",
            "Epoch 82/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6788 - accuracy: 0.7233 - val_loss: 0.7645 - val_accuracy: 0.6879\n",
            "Epoch 83/300\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6821 - accuracy: 0.7233 - val_loss: 0.7433 - val_accuracy: 0.7004\n",
            "Epoch 84/300\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6638 - accuracy: 0.7306 - val_loss: 0.7270 - val_accuracy: 0.7088\n",
            "Epoch 85/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6984 - accuracy: 0.7148 - val_loss: 0.7549 - val_accuracy: 0.7050\n",
            "Epoch 86/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6670 - accuracy: 0.7229 - val_loss: 0.7587 - val_accuracy: 0.7013\n",
            "Epoch 87/300\n",
            "100/100 [==============================] - 7s 73ms/step - loss: 0.6829 - accuracy: 0.7169 - val_loss: 0.7546 - val_accuracy: 0.6892\n",
            "Epoch 88/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.6549 - accuracy: 0.7360 - val_loss: 0.7823 - val_accuracy: 0.6954\n",
            "Epoch 89/300\n",
            "100/100 [==============================] - 12s 123ms/step - loss: 0.6616 - accuracy: 0.7279 - val_loss: 0.7210 - val_accuracy: 0.7212\n",
            "Epoch 90/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.6459 - accuracy: 0.7387 - val_loss: 0.7692 - val_accuracy: 0.7000\n",
            "Epoch 91/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.6635 - accuracy: 0.7304 - val_loss: 0.7675 - val_accuracy: 0.6983\n",
            "Epoch 92/300\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.6451 - accuracy: 0.7496 - val_loss: 0.7987 - val_accuracy: 0.6883\n",
            "Epoch 93/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.6590 - accuracy: 0.7215 - val_loss: 0.7451 - val_accuracy: 0.7058\n",
            "Epoch 94/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.6460 - accuracy: 0.7444 - val_loss: 0.7120 - val_accuracy: 0.7113\n",
            "Epoch 95/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6225 - accuracy: 0.7404 - val_loss: 0.6906 - val_accuracy: 0.7229\n",
            "Epoch 96/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6227 - accuracy: 0.7462 - val_loss: 0.7256 - val_accuracy: 0.7183\n",
            "Epoch 97/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.6067 - accuracy: 0.7540 - val_loss: 0.7288 - val_accuracy: 0.7267\n",
            "Epoch 98/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.6199 - accuracy: 0.7510 - val_loss: 0.7192 - val_accuracy: 0.7275\n",
            "Epoch 99/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.6090 - accuracy: 0.7555 - val_loss: 0.7542 - val_accuracy: 0.7071\n",
            "Epoch 100/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.6054 - accuracy: 0.7621 - val_loss: 0.7492 - val_accuracy: 0.6996\n",
            "Epoch 101/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.5952 - accuracy: 0.7617 - val_loss: 0.7530 - val_accuracy: 0.6929\n",
            "Epoch 102/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5867 - accuracy: 0.7713 - val_loss: 0.7716 - val_accuracy: 0.7113\n",
            "Epoch 103/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6022 - accuracy: 0.7579 - val_loss: 0.7542 - val_accuracy: 0.6946\n",
            "Epoch 104/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5949 - accuracy: 0.7582 - val_loss: 0.7203 - val_accuracy: 0.7221\n",
            "Epoch 105/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.5772 - accuracy: 0.7717 - val_loss: 0.7387 - val_accuracy: 0.7046\n",
            "Epoch 106/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5551 - accuracy: 0.7769 - val_loss: 0.7560 - val_accuracy: 0.7154\n",
            "Epoch 107/300\n",
            "100/100 [==============================] - 12s 119ms/step - loss: 0.5619 - accuracy: 0.7817 - val_loss: 0.7409 - val_accuracy: 0.7138\n",
            "Epoch 108/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.5474 - accuracy: 0.7793 - val_loss: 0.8110 - val_accuracy: 0.7021\n",
            "Epoch 109/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.5637 - accuracy: 0.7704 - val_loss: 0.7601 - val_accuracy: 0.6875\n",
            "Epoch 110/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.5693 - accuracy: 0.7732 - val_loss: 0.7680 - val_accuracy: 0.6958\n",
            "Epoch 111/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5462 - accuracy: 0.7810 - val_loss: 0.7824 - val_accuracy: 0.7008\n",
            "Epoch 112/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5324 - accuracy: 0.7899 - val_loss: 0.7985 - val_accuracy: 0.7038\n",
            "Epoch 113/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5427 - accuracy: 0.7862 - val_loss: 0.8230 - val_accuracy: 0.6825\n",
            "Epoch 114/300\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.5491 - accuracy: 0.7837 - val_loss: 0.7833 - val_accuracy: 0.6892\n",
            "Epoch 115/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.5216 - accuracy: 0.7925 - val_loss: 0.7417 - val_accuracy: 0.7100\n",
            "Epoch 116/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.5195 - accuracy: 0.7925 - val_loss: 0.7302 - val_accuracy: 0.7192\n",
            "Epoch 117/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5372 - accuracy: 0.7904 - val_loss: 0.8345 - val_accuracy: 0.6950\n",
            "Epoch 118/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5001 - accuracy: 0.8029 - val_loss: 0.7644 - val_accuracy: 0.7096\n",
            "Epoch 119/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5019 - accuracy: 0.8025 - val_loss: 0.7983 - val_accuracy: 0.7129\n",
            "Epoch 120/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5098 - accuracy: 0.7958 - val_loss: 0.7420 - val_accuracy: 0.7113\n",
            "Epoch 121/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4955 - accuracy: 0.8065 - val_loss: 0.7865 - val_accuracy: 0.7075\n",
            "Epoch 122/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4932 - accuracy: 0.8027 - val_loss: 0.7355 - val_accuracy: 0.7221\n",
            "Epoch 123/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4836 - accuracy: 0.8106 - val_loss: 0.7911 - val_accuracy: 0.7208\n",
            "Epoch 124/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5219 - accuracy: 0.7981 - val_loss: 0.7748 - val_accuracy: 0.7262\n",
            "Epoch 125/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4749 - accuracy: 0.8115 - val_loss: 0.7315 - val_accuracy: 0.7212\n",
            "Epoch 126/300\n",
            "100/100 [==============================] - 12s 119ms/step - loss: 0.4905 - accuracy: 0.8127 - val_loss: 0.7772 - val_accuracy: 0.7071\n",
            "Epoch 127/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4786 - accuracy: 0.8146 - val_loss: 0.7790 - val_accuracy: 0.6904\n",
            "Epoch 128/300\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.4543 - accuracy: 0.8233 - val_loss: 0.7790 - val_accuracy: 0.7221\n",
            "Epoch 129/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4771 - accuracy: 0.8104 - val_loss: 0.7286 - val_accuracy: 0.7079\n",
            "Epoch 130/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4349 - accuracy: 0.8298 - val_loss: 0.7758 - val_accuracy: 0.7354\n",
            "Epoch 131/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4488 - accuracy: 0.8238 - val_loss: 0.8019 - val_accuracy: 0.7283\n",
            "Epoch 132/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4460 - accuracy: 0.8242 - val_loss: 0.8078 - val_accuracy: 0.7204\n",
            "Epoch 133/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4385 - accuracy: 0.8298 - val_loss: 0.8409 - val_accuracy: 0.7367\n",
            "Epoch 134/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4176 - accuracy: 0.8373 - val_loss: 0.8396 - val_accuracy: 0.7083\n",
            "Epoch 135/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.4441 - accuracy: 0.8308 - val_loss: 0.8711 - val_accuracy: 0.7104\n",
            "Epoch 136/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.4390 - accuracy: 0.8288 - val_loss: 0.7699 - val_accuracy: 0.7163\n",
            "Epoch 137/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4132 - accuracy: 0.8444 - val_loss: 0.7953 - val_accuracy: 0.7271\n",
            "Epoch 138/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4095 - accuracy: 0.8442 - val_loss: 0.8245 - val_accuracy: 0.7063\n",
            "Epoch 139/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.4126 - accuracy: 0.8406 - val_loss: 0.8002 - val_accuracy: 0.7142\n",
            "Epoch 140/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.4233 - accuracy: 0.8375 - val_loss: 0.7734 - val_accuracy: 0.7237\n",
            "Epoch 141/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.4034 - accuracy: 0.8411 - val_loss: 0.7837 - val_accuracy: 0.7279\n",
            "Epoch 142/300\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.4019 - accuracy: 0.8492 - val_loss: 0.8708 - val_accuracy: 0.7125\n",
            "Epoch 143/300\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4061 - accuracy: 0.8471 - val_loss: 0.8547 - val_accuracy: 0.6846\n",
            "Epoch 144/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.3968 - accuracy: 0.8506 - val_loss: 0.8504 - val_accuracy: 0.7100\n",
            "Epoch 145/300\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.3958 - accuracy: 0.8480 - val_loss: 0.8481 - val_accuracy: 0.7108\n",
            "Epoch 146/300\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.3732 - accuracy: 0.8616 - val_loss: 0.8020 - val_accuracy: 0.7217\n",
            "Epoch 147/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.3650 - accuracy: 0.8636 - val_loss: 0.8134 - val_accuracy: 0.7025\n",
            "Epoch 148/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3746 - accuracy: 0.8593 - val_loss: 0.8701 - val_accuracy: 0.7092\n",
            "Epoch 149/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3593 - accuracy: 0.8635 - val_loss: 0.9982 - val_accuracy: 0.6975\n",
            "Epoch 150/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.3567 - accuracy: 0.8635 - val_loss: 0.8502 - val_accuracy: 0.7275\n",
            "Epoch 151/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.3590 - accuracy: 0.8682 - val_loss: 0.8819 - val_accuracy: 0.7079\n",
            "Epoch 152/300\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.3528 - accuracy: 0.8667 - val_loss: 0.9260 - val_accuracy: 0.7100\n",
            "Epoch 153/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.3488 - accuracy: 0.8658 - val_loss: 0.8852 - val_accuracy: 0.6996\n",
            "Epoch 154/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.3505 - accuracy: 0.8712 - val_loss: 0.9078 - val_accuracy: 0.7175\n",
            "Epoch 155/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.3531 - accuracy: 0.8657 - val_loss: 0.9923 - val_accuracy: 0.6742\n",
            "Epoch 156/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3640 - accuracy: 0.8611 - val_loss: 0.9318 - val_accuracy: 0.7075\n",
            "Epoch 157/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3361 - accuracy: 0.8755 - val_loss: 0.8847 - val_accuracy: 0.7138\n",
            "Epoch 158/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.3389 - accuracy: 0.8725 - val_loss: 0.9537 - val_accuracy: 0.7075\n",
            "Epoch 159/300\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.3413 - accuracy: 0.8729 - val_loss: 0.9732 - val_accuracy: 0.7108\n",
            "Epoch 160/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.3240 - accuracy: 0.8775 - val_loss: 0.8707 - val_accuracy: 0.7150\n",
            "Epoch 161/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3140 - accuracy: 0.8822 - val_loss: 0.9092 - val_accuracy: 0.6925\n",
            "Epoch 162/300\n",
            "100/100 [==============================] - 13s 126ms/step - loss: 0.3457 - accuracy: 0.8744 - val_loss: 0.9429 - val_accuracy: 0.7188\n",
            "Epoch 163/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.3144 - accuracy: 0.8806 - val_loss: 0.9447 - val_accuracy: 0.7079\n",
            "Epoch 164/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3016 - accuracy: 0.8864 - val_loss: 0.9436 - val_accuracy: 0.7096\n",
            "Epoch 165/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3120 - accuracy: 0.8839 - val_loss: 1.0250 - val_accuracy: 0.7071\n",
            "Epoch 166/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.3114 - accuracy: 0.8842 - val_loss: 0.8942 - val_accuracy: 0.7125\n",
            "Epoch 167/300\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.2866 - accuracy: 0.8944 - val_loss: 0.9301 - val_accuracy: 0.7075\n",
            "Epoch 168/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.3154 - accuracy: 0.8821 - val_loss: 0.9251 - val_accuracy: 0.7075\n",
            "Epoch 169/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2882 - accuracy: 0.8917 - val_loss: 0.9369 - val_accuracy: 0.7138\n",
            "Epoch 170/300\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.2878 - accuracy: 0.8925 - val_loss: 0.9392 - val_accuracy: 0.7088\n",
            "Epoch 171/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2855 - accuracy: 0.8935 - val_loss: 1.0256 - val_accuracy: 0.7025\n",
            "Epoch 172/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.2986 - accuracy: 0.8908 - val_loss: 0.9400 - val_accuracy: 0.7113\n",
            "Epoch 173/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.2951 - accuracy: 0.8910 - val_loss: 0.9802 - val_accuracy: 0.7008\n",
            "Epoch 174/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2639 - accuracy: 0.8964 - val_loss: 0.9872 - val_accuracy: 0.7117\n",
            "Epoch 175/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2660 - accuracy: 0.8981 - val_loss: 0.9719 - val_accuracy: 0.7025\n",
            "Epoch 176/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.2688 - accuracy: 0.9002 - val_loss: 0.9856 - val_accuracy: 0.7200\n",
            "Epoch 177/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.2715 - accuracy: 0.8968 - val_loss: 1.0521 - val_accuracy: 0.7008\n",
            "Epoch 178/300\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2664 - accuracy: 0.9021 - val_loss: 0.9747 - val_accuracy: 0.7308\n",
            "Epoch 179/300\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.2523 - accuracy: 0.9067 - val_loss: 0.9932 - val_accuracy: 0.7250\n",
            "Epoch 180/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.2455 - accuracy: 0.9112 - val_loss: 1.0833 - val_accuracy: 0.6913\n",
            "Epoch 181/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.2475 - accuracy: 0.9040 - val_loss: 0.9720 - val_accuracy: 0.7212\n",
            "Epoch 182/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2500 - accuracy: 0.9098 - val_loss: 0.9425 - val_accuracy: 0.7271\n",
            "Epoch 183/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.2714 - accuracy: 0.8998 - val_loss: 0.9837 - val_accuracy: 0.7204\n",
            "Epoch 184/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.2560 - accuracy: 0.9050 - val_loss: 1.0072 - val_accuracy: 0.6967\n",
            "Epoch 185/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.2395 - accuracy: 0.9119 - val_loss: 1.0254 - val_accuracy: 0.7150\n",
            "Epoch 186/300\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.2361 - accuracy: 0.9100 - val_loss: 0.9620 - val_accuracy: 0.7204\n",
            "Epoch 187/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2690 - accuracy: 0.8977 - val_loss: 0.9798 - val_accuracy: 0.7242\n",
            "Epoch 188/300\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.2424 - accuracy: 0.9108 - val_loss: 1.0578 - val_accuracy: 0.7154\n",
            "Epoch 189/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.2328 - accuracy: 0.9144 - val_loss: 1.0545 - val_accuracy: 0.6996\n",
            "Epoch 190/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.2399 - accuracy: 0.9110 - val_loss: 0.9650 - val_accuracy: 0.7196\n",
            "Epoch 191/300\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2376 - accuracy: 0.9094 - val_loss: 1.1089 - val_accuracy: 0.7108\n",
            "Epoch 192/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2303 - accuracy: 0.9108 - val_loss: 1.1719 - val_accuracy: 0.7050\n",
            "Epoch 193/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.2472 - accuracy: 0.9058 - val_loss: 1.0478 - val_accuracy: 0.7212\n",
            "Epoch 194/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.2340 - accuracy: 0.9127 - val_loss: 1.0744 - val_accuracy: 0.7083\n",
            "Epoch 195/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2365 - accuracy: 0.9148 - val_loss: 1.0936 - val_accuracy: 0.7054\n",
            "Epoch 196/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.2437 - accuracy: 0.9071 - val_loss: 1.0618 - val_accuracy: 0.7100\n",
            "Epoch 197/300\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2064 - accuracy: 0.9204 - val_loss: 1.0785 - val_accuracy: 0.7113\n",
            "Epoch 198/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.2197 - accuracy: 0.9183 - val_loss: 1.0552 - val_accuracy: 0.7246\n",
            "Epoch 199/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2072 - accuracy: 0.9184 - val_loss: 1.1908 - val_accuracy: 0.7096\n",
            "Epoch 200/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.2048 - accuracy: 0.9208 - val_loss: 1.0703 - val_accuracy: 0.7325\n",
            "Epoch 201/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1998 - accuracy: 0.9240 - val_loss: 1.0394 - val_accuracy: 0.7142\n",
            "Epoch 202/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2134 - accuracy: 0.9192 - val_loss: 1.0469 - val_accuracy: 0.7167\n",
            "Epoch 203/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.2134 - accuracy: 0.9215 - val_loss: 1.0712 - val_accuracy: 0.7125\n",
            "Epoch 204/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.2055 - accuracy: 0.9244 - val_loss: 1.0973 - val_accuracy: 0.7329\n",
            "Epoch 205/300\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.2078 - accuracy: 0.9231 - val_loss: 1.1049 - val_accuracy: 0.7129\n",
            "Epoch 206/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2048 - accuracy: 0.9259 - val_loss: 1.1850 - val_accuracy: 0.6950\n",
            "Epoch 207/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.2101 - accuracy: 0.9256 - val_loss: 1.0582 - val_accuracy: 0.7058\n",
            "Epoch 208/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.2093 - accuracy: 0.9242 - val_loss: 0.9442 - val_accuracy: 0.7163\n",
            "Epoch 209/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2014 - accuracy: 0.9265 - val_loss: 1.1389 - val_accuracy: 0.7054\n",
            "Epoch 210/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2013 - accuracy: 0.9279 - val_loss: 1.1786 - val_accuracy: 0.7138\n",
            "Epoch 211/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1787 - accuracy: 0.9346 - val_loss: 1.1317 - val_accuracy: 0.7117\n",
            "Epoch 212/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2029 - accuracy: 0.9240 - val_loss: 1.1404 - val_accuracy: 0.6958\n",
            "Epoch 213/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.2004 - accuracy: 0.9263 - val_loss: 1.0015 - val_accuracy: 0.7283\n",
            "Epoch 214/300\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1992 - accuracy: 0.9242 - val_loss: 1.0627 - val_accuracy: 0.7212\n",
            "Epoch 215/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1883 - accuracy: 0.9326 - val_loss: 1.1488 - val_accuracy: 0.7167\n",
            "Epoch 216/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1836 - accuracy: 0.9330 - val_loss: 1.0956 - val_accuracy: 0.7233\n",
            "Epoch 217/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1896 - accuracy: 0.9298 - val_loss: 1.0833 - val_accuracy: 0.7133\n",
            "Epoch 218/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2081 - accuracy: 0.9258 - val_loss: 1.1512 - val_accuracy: 0.7237\n",
            "Epoch 219/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1859 - accuracy: 0.9310 - val_loss: 1.2211 - val_accuracy: 0.7125\n",
            "Epoch 220/300\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1822 - accuracy: 0.9337 - val_loss: 1.0918 - val_accuracy: 0.7117\n",
            "Epoch 221/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1855 - accuracy: 0.9337 - val_loss: 1.1505 - val_accuracy: 0.7108\n",
            "Epoch 222/300\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1879 - accuracy: 0.9310 - val_loss: 1.2404 - val_accuracy: 0.7188\n",
            "Epoch 223/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1938 - accuracy: 0.9302 - val_loss: 1.1153 - val_accuracy: 0.7100\n",
            "Epoch 224/300\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.1736 - accuracy: 0.9362 - val_loss: 1.2360 - val_accuracy: 0.7142\n",
            "Epoch 225/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1903 - accuracy: 0.9312 - val_loss: 1.3190 - val_accuracy: 0.6921\n",
            "Epoch 226/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1800 - accuracy: 0.9358 - val_loss: 1.2249 - val_accuracy: 0.7167\n",
            "Epoch 227/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1671 - accuracy: 0.9337 - val_loss: 1.2206 - val_accuracy: 0.7042\n",
            "Epoch 228/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1760 - accuracy: 0.9346 - val_loss: 1.2392 - val_accuracy: 0.7054\n",
            "Epoch 229/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1687 - accuracy: 0.9369 - val_loss: 1.0753 - val_accuracy: 0.7287\n",
            "Epoch 230/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1775 - accuracy: 0.9319 - val_loss: 1.2182 - val_accuracy: 0.7092\n",
            "Epoch 231/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.1664 - accuracy: 0.9376 - val_loss: 1.1198 - val_accuracy: 0.7096\n",
            "Epoch 232/300\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.1594 - accuracy: 0.9367 - val_loss: 1.1801 - val_accuracy: 0.7121\n",
            "Epoch 233/300\n",
            "100/100 [==============================] - 7s 74ms/step - loss: 0.1693 - accuracy: 0.9383 - val_loss: 1.3079 - val_accuracy: 0.7042\n",
            "Epoch 234/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.1683 - accuracy: 0.9331 - val_loss: 1.1846 - val_accuracy: 0.7217\n",
            "Epoch 235/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1617 - accuracy: 0.9419 - val_loss: 1.2865 - val_accuracy: 0.7096\n",
            "Epoch 236/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1846 - accuracy: 0.9323 - val_loss: 1.1276 - val_accuracy: 0.7129\n",
            "Epoch 237/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.1519 - accuracy: 0.9483 - val_loss: 1.2219 - val_accuracy: 0.7212\n",
            "Epoch 238/300\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.1666 - accuracy: 0.9386 - val_loss: 1.1231 - val_accuracy: 0.7138\n",
            "Epoch 239/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.1790 - accuracy: 0.9321 - val_loss: 1.2236 - val_accuracy: 0.7221\n",
            "Epoch 240/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1628 - accuracy: 0.9401 - val_loss: 1.3153 - val_accuracy: 0.7050\n",
            "Epoch 241/300\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.1682 - accuracy: 0.9369 - val_loss: 1.0400 - val_accuracy: 0.7346\n",
            "Epoch 242/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1462 - accuracy: 0.9473 - val_loss: 1.2490 - val_accuracy: 0.7008\n",
            "Epoch 243/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1378 - accuracy: 0.9500 - val_loss: 1.1770 - val_accuracy: 0.7325\n",
            "Epoch 244/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1665 - accuracy: 0.9373 - val_loss: 1.0519 - val_accuracy: 0.7312\n",
            "Epoch 245/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.1652 - accuracy: 0.9440 - val_loss: 1.2759 - val_accuracy: 0.7188\n",
            "Epoch 246/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1421 - accuracy: 0.9479 - val_loss: 1.2021 - val_accuracy: 0.7304\n",
            "Epoch 247/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.1522 - accuracy: 0.9463 - val_loss: 1.2406 - val_accuracy: 0.6975\n",
            "Epoch 248/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1711 - accuracy: 0.9349 - val_loss: 1.1331 - val_accuracy: 0.7183\n",
            "Epoch 249/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1500 - accuracy: 0.9465 - val_loss: 1.1867 - val_accuracy: 0.7129\n",
            "Epoch 250/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.1523 - accuracy: 0.9456 - val_loss: 1.2282 - val_accuracy: 0.7071\n",
            "Epoch 251/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1476 - accuracy: 0.9465 - val_loss: 1.2442 - val_accuracy: 0.7175\n",
            "Epoch 252/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1555 - accuracy: 0.9446 - val_loss: 1.1768 - val_accuracy: 0.7146\n",
            "Epoch 253/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1732 - accuracy: 0.9365 - val_loss: 1.1871 - val_accuracy: 0.7046\n",
            "Epoch 254/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1617 - accuracy: 0.9392 - val_loss: 1.1604 - val_accuracy: 0.7117\n",
            "Epoch 255/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1270 - accuracy: 0.9548 - val_loss: 1.4015 - val_accuracy: 0.7258\n",
            "Epoch 256/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1390 - accuracy: 0.9472 - val_loss: 1.3152 - val_accuracy: 0.7212\n",
            "Epoch 257/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.1273 - accuracy: 0.9533 - val_loss: 1.3430 - val_accuracy: 0.7150\n",
            "Epoch 258/300\n",
            "100/100 [==============================] - 10s 99ms/step - loss: 0.1524 - accuracy: 0.9456 - val_loss: 1.1809 - val_accuracy: 0.7204\n",
            "Epoch 259/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.1547 - accuracy: 0.9434 - val_loss: 1.1394 - val_accuracy: 0.7279\n",
            "Epoch 260/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.1431 - accuracy: 0.9502 - val_loss: 1.3512 - val_accuracy: 0.7025\n",
            "Epoch 261/300\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1444 - accuracy: 0.9450 - val_loss: 1.2221 - val_accuracy: 0.7246\n",
            "Epoch 262/300\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.1390 - accuracy: 0.9477 - val_loss: 1.3794 - val_accuracy: 0.7142\n",
            "Epoch 263/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.1426 - accuracy: 0.9499 - val_loss: 1.2614 - val_accuracy: 0.7025\n",
            "Epoch 264/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1164 - accuracy: 0.9533 - val_loss: 1.2007 - val_accuracy: 0.7217\n",
            "Epoch 265/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1327 - accuracy: 0.9510 - val_loss: 1.3184 - val_accuracy: 0.7025\n",
            "Epoch 266/300\n",
            "100/100 [==============================] - 12s 115ms/step - loss: 0.1388 - accuracy: 0.9524 - val_loss: 1.1812 - val_accuracy: 0.7221\n",
            "Epoch 267/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.1465 - accuracy: 0.9460 - val_loss: 1.3871 - val_accuracy: 0.7079\n",
            "Epoch 268/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1448 - accuracy: 0.9450 - val_loss: 1.0444 - val_accuracy: 0.7221\n",
            "Epoch 269/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1381 - accuracy: 0.9492 - val_loss: 1.3843 - val_accuracy: 0.7029\n",
            "Epoch 270/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.1429 - accuracy: 0.9458 - val_loss: 1.2176 - val_accuracy: 0.7188\n",
            "Epoch 271/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1345 - accuracy: 0.9527 - val_loss: 1.4045 - val_accuracy: 0.6917\n",
            "Epoch 272/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1251 - accuracy: 0.9542 - val_loss: 1.3006 - val_accuracy: 0.7196\n",
            "Epoch 273/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1310 - accuracy: 0.9521 - val_loss: 1.2008 - val_accuracy: 0.7150\n",
            "Epoch 274/300\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1389 - accuracy: 0.9500 - val_loss: 1.2776 - val_accuracy: 0.7096\n",
            "Epoch 275/300\n",
            "100/100 [==============================] - 11s 115ms/step - loss: 0.1226 - accuracy: 0.9581 - val_loss: 1.2248 - val_accuracy: 0.7242\n",
            "Epoch 276/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1396 - accuracy: 0.9460 - val_loss: 1.2572 - val_accuracy: 0.7196\n",
            "Epoch 277/300\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.1341 - accuracy: 0.9527 - val_loss: 1.2190 - val_accuracy: 0.7212\n",
            "Epoch 278/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1244 - accuracy: 0.9521 - val_loss: 1.3397 - val_accuracy: 0.7204\n",
            "Epoch 279/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1243 - accuracy: 0.9544 - val_loss: 1.3563 - val_accuracy: 0.7167\n",
            "Epoch 280/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.1456 - accuracy: 0.9449 - val_loss: 1.1725 - val_accuracy: 0.7171\n",
            "Epoch 281/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.1188 - accuracy: 0.9577 - val_loss: 1.2514 - val_accuracy: 0.7346\n",
            "Epoch 282/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1516 - accuracy: 0.9456 - val_loss: 1.1476 - val_accuracy: 0.7171\n",
            "Epoch 283/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.1275 - accuracy: 0.9508 - val_loss: 1.2630 - val_accuracy: 0.7233\n",
            "Epoch 284/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.1166 - accuracy: 0.9584 - val_loss: 1.2617 - val_accuracy: 0.7212\n",
            "Epoch 285/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1192 - accuracy: 0.9560 - val_loss: 1.2813 - val_accuracy: 0.7192\n",
            "Epoch 286/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.1227 - accuracy: 0.9557 - val_loss: 1.1754 - val_accuracy: 0.7242\n",
            "Epoch 287/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1200 - accuracy: 0.9552 - val_loss: 1.3118 - val_accuracy: 0.7212\n",
            "Epoch 288/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.1268 - accuracy: 0.9548 - val_loss: 1.2483 - val_accuracy: 0.7254\n",
            "Epoch 289/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1299 - accuracy: 0.9521 - val_loss: 1.3296 - val_accuracy: 0.7092\n",
            "Epoch 290/300\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.1216 - accuracy: 0.9546 - val_loss: 1.3356 - val_accuracy: 0.7167\n",
            "Epoch 291/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1071 - accuracy: 0.9591 - val_loss: 1.3250 - val_accuracy: 0.7258\n",
            "Epoch 292/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.1216 - accuracy: 0.9503 - val_loss: 1.1542 - val_accuracy: 0.7279\n",
            "Epoch 293/300\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.1074 - accuracy: 0.9625 - val_loss: 1.2303 - val_accuracy: 0.7121\n",
            "Epoch 294/300\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.1245 - accuracy: 0.9542 - val_loss: 1.3913 - val_accuracy: 0.7192\n",
            "Epoch 295/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.1290 - accuracy: 0.9503 - val_loss: 1.2099 - val_accuracy: 0.7183\n",
            "Epoch 296/300\n",
            "100/100 [==============================] - 13s 125ms/step - loss: 0.1111 - accuracy: 0.9578 - val_loss: 1.4562 - val_accuracy: 0.7029\n",
            "Epoch 297/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.1340 - accuracy: 0.9520 - val_loss: 1.3270 - val_accuracy: 0.6921\n",
            "Epoch 298/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1169 - accuracy: 0.9588 - val_loss: 1.3046 - val_accuracy: 0.7171\n",
            "Epoch 299/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1241 - accuracy: 0.9569 - val_loss: 1.2179 - val_accuracy: 0.7092\n",
            "Epoch 300/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.1160 - accuracy: 0.9575 - val_loss: 1.3766 - val_accuracy: 0.7083\n"
          ]
        }
      ],
      "source": [
        "epochs = 300\n",
        "history_model3 = model3.fit(train_set,\n",
        "        steps_per_epoch=100,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_set,\n",
        "        validation_steps=50\n",
        "        )# Writing code to fit the model. Using train_set as the training data and validation_set as the validation data. Training the model for 300 epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbAqrAQQVjIR"
      },
      "source": [
        "### **Evaluating the Model on Test Set**\n",
        "\n",
        "**Finally the model3 improved got a 0.95 accuracy showing an improving from the Resnet and VGG16 models that it was 0.50 around**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "uO26AYRuVm7F",
        "outputId": "6dbd43c3-1a91-400c-ea60-3273395da5cc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Writing code to evaluate the model performance on the test set\n",
        "\n",
        "# Plotting the accuracies\n",
        "\n",
        "dict_hist = history_model3.history\n",
        "\n",
        "list_ep = [i for i in range(1, 301)]\n",
        "\n",
        "plt.figure(figsize = (8, 8))\n",
        "\n",
        "plt.plot(list_ep, dict_hist['accuracy'], ls = '--', label = 'accuracy')\n",
        "\n",
        "plt.plot(list_ep, dict_hist['val_accuracy'], ls = '--', label = 'val_accuracy')\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNWc6agwxJ_z"
      },
      "source": [
        "### **Plotting the Confusion Matrix for the chosen final model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "id": "SFTRyIk-yjoQ",
        "outputId": "cfedcde5-c9c9-465f-c85e-6ec6e041aa54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 128 images belonging to 4 classes.\n",
            "4/4 [==============================] - 0s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.78      0.79        32\n",
            "           1       0.66      0.59      0.62        32\n",
            "           2       0.56      0.62      0.59        32\n",
            "           3       0.88      0.88      0.88        32\n",
            "\n",
            "    accuracy                           0.72       128\n",
            "   macro avg       0.72      0.72      0.72       128\n",
            "weighted avg       0.72      0.72      0.72       128\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting the confusion matrix and generate a classification report for the model\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "test_set = datagen_test.flow_from_directory(folder_path + \"test\",\n",
        "                                                              target_size = (img_size,img_size),\n",
        "                                                              color_mode = 'grayscale',\n",
        "                                                              batch_size = 128,\n",
        "                                                              class_mode = 'categorical',\n",
        "                                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n",
        "                                                              shuffle = True)\n",
        "test_images, test_labels = next(test_set)\n",
        "\n",
        "# Writing the name of the chosen model for predict\n",
        "pred = model3.predict(test_images)\n",
        "pred = np.argmax(pred, axis = 1)\n",
        "y_true = np.argmax(test_labels, axis = 1)\n",
        "\n",
        "# Printing the classification report\n",
        "#_____________\n",
        "print(classification_report(y_true, pred))\n",
        "\n",
        "\n",
        "# Plotting the heatmap using confusion matrix\n",
        "cm = confusion_matrix(y_true, pred)\n",
        "plt.figure(figsize = (8, 5))\n",
        "sns.heatmap(cm, annot = True,  fmt = '.0f', xticklabels = ['happy', 'sad', 'neutral', 'surprise'], yticklabels = ['happy', 'sad', 'neutral', 'surprise'])\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NEXT TEST with the other learning rate 0.0018876351674999116 to show that is good but not as good as the previous one**"
      ],
      "metadata": {
        "id": "BlxYZcaWvleK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backend.clear_session()"
      ],
      "metadata": {
        "id": "AD8QnymhH-aT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = create_model('params')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGv8At9fIm4M",
        "outputId": "26c21a74-1ab4-4ef3-916b-18e560d51caa"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 48, 48, 64)        320       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 48, 48, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 128)       32896     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 512)       262656    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 12, 12, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 12, 12, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 6, 6, 512)         1049088   \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 6, 6, 512)         1049088   \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 6, 6, 512)         1049088   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 6, 6, 256)         524544    \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 6, 6, 256)         262400    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 6, 6, 256)         262400    \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 6, 6, 256)         262400    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 6, 6, 256)         262400    \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 6, 6, 256)         262400    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 9216)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               2359552   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,842,500\n",
            "Trainable params: 7,840,068\n",
            "Non-trainable params: 2,432\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Writing code to compile model3. Using categorical crossentropy as the loss function, Adam Optimizer with 0.0018876351674999116 learning rate, and set metrics to 'accuracy'.\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0018876351674999116) #0.000110599529645911) #0.008663720076310137) #0.0000725)\n",
        "model3.compile(loss = 'categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "st1iPjRBIw5_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 300\n",
        "history_model3 = model3.fit(train_set,\n",
        "        steps_per_epoch=100,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_set,\n",
        "        validation_steps=50\n",
        "        )# Writing code to fit the model. Using train_set as the training data and validation_set as the validation data. Training model for 300 epochs.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLQ6dltXIDCz",
        "outputId": "849420da-e143-46eb-8df4-d7b3a1931e00"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "100/100 [==============================] - 17s 92ms/step - loss: 1.5986 - accuracy: 0.2658 - val_loss: 1.3845 - val_accuracy: 0.3800\n",
            "Epoch 2/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.4919 - accuracy: 0.2552 - val_loss: 1.9151 - val_accuracy: 0.2183\n",
            "Epoch 3/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.4450 - accuracy: 0.2627 - val_loss: 1.4396 - val_accuracy: 0.2029\n",
            "Epoch 4/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 1.4231 - accuracy: 0.2512 - val_loss: 1.4640 - val_accuracy: 0.2188\n",
            "Epoch 5/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.4008 - accuracy: 0.2648 - val_loss: 1.3673 - val_accuracy: 0.2438\n",
            "Epoch 6/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 1.3941 - accuracy: 0.2675 - val_loss: 1.3618 - val_accuracy: 0.3325\n",
            "Epoch 7/300\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 1.3836 - accuracy: 0.2810 - val_loss: 1.3654 - val_accuracy: 0.2508\n",
            "Epoch 8/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.3880 - accuracy: 0.2671 - val_loss: 1.3513 - val_accuracy: 0.3329\n",
            "Epoch 9/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 1.3816 - accuracy: 0.2677 - val_loss: 1.3696 - val_accuracy: 0.2467\n",
            "Epoch 10/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3833 - accuracy: 0.2644 - val_loss: 1.3709 - val_accuracy: 0.2425\n",
            "Epoch 11/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.3818 - accuracy: 0.2767 - val_loss: 1.3681 - val_accuracy: 0.2671\n",
            "Epoch 12/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.3832 - accuracy: 0.2667 - val_loss: 1.3702 - val_accuracy: 0.3137\n",
            "Epoch 13/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 1.3825 - accuracy: 0.2625 - val_loss: 1.3740 - val_accuracy: 0.2463\n",
            "Epoch 14/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.3780 - accuracy: 0.2750 - val_loss: 1.3523 - val_accuracy: 0.3317\n",
            "Epoch 15/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3760 - accuracy: 0.2833 - val_loss: 1.3648 - val_accuracy: 0.3133\n",
            "Epoch 16/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.3811 - accuracy: 0.2685 - val_loss: 1.3733 - val_accuracy: 0.2554\n",
            "Epoch 17/300\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 1.3821 - accuracy: 0.2656 - val_loss: 1.3576 - val_accuracy: 0.3267\n",
            "Epoch 18/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.3795 - accuracy: 0.2621 - val_loss: 1.3578 - val_accuracy: 0.2367\n",
            "Epoch 19/300\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 1.3783 - accuracy: 0.2750 - val_loss: 1.3688 - val_accuracy: 0.3133\n",
            "Epoch 20/300\n",
            "100/100 [==============================] - 20s 204ms/step - loss: 1.3730 - accuracy: 0.2738 - val_loss: 1.3635 - val_accuracy: 0.2367\n",
            "Epoch 21/300\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 1.3686 - accuracy: 0.2838 - val_loss: 1.3546 - val_accuracy: 0.2567\n",
            "Epoch 22/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.3485 - accuracy: 0.3194 - val_loss: 1.4165 - val_accuracy: 0.3325\n",
            "Epoch 23/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.3138 - accuracy: 0.3600 - val_loss: 3.9614 - val_accuracy: 0.3067\n",
            "Epoch 24/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.2666 - accuracy: 0.3890 - val_loss: 1.3124 - val_accuracy: 0.3904\n",
            "Epoch 25/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.2654 - accuracy: 0.3908 - val_loss: 1.2686 - val_accuracy: 0.3996\n",
            "Epoch 26/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 1.2591 - accuracy: 0.4035 - val_loss: 5.3299 - val_accuracy: 0.3975\n",
            "Epoch 27/300\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 1.2406 - accuracy: 0.4114 - val_loss: 1.3266 - val_accuracy: 0.4071\n",
            "Epoch 28/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 1.2080 - accuracy: 0.4331 - val_loss: 3.3110 - val_accuracy: 0.4767\n",
            "Epoch 29/300\n",
            "100/100 [==============================] - 13s 127ms/step - loss: 1.1914 - accuracy: 0.4552 - val_loss: 1.1996 - val_accuracy: 0.4504\n",
            "Epoch 30/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.1580 - accuracy: 0.4723 - val_loss: 1.4237 - val_accuracy: 0.3413\n",
            "Epoch 31/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.1526 - accuracy: 0.4696 - val_loss: 1.1503 - val_accuracy: 0.4708\n",
            "Epoch 32/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 1.1389 - accuracy: 0.4779 - val_loss: 1.0931 - val_accuracy: 0.5071\n",
            "Epoch 33/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 1.1214 - accuracy: 0.4805 - val_loss: 1.1187 - val_accuracy: 0.4804\n",
            "Epoch 34/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 1.0879 - accuracy: 0.5020 - val_loss: 1.2098 - val_accuracy: 0.4462\n",
            "Epoch 35/300\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 1.0919 - accuracy: 0.5004 - val_loss: 1.1465 - val_accuracy: 0.4971\n",
            "Epoch 36/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 1.0523 - accuracy: 0.5273 - val_loss: 1.0184 - val_accuracy: 0.5429\n",
            "Epoch 37/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 1.0547 - accuracy: 0.5402 - val_loss: 1.0598 - val_accuracy: 0.5246\n",
            "Epoch 38/300\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 1.0325 - accuracy: 0.5433 - val_loss: 16.2001 - val_accuracy: 0.5317\n",
            "Epoch 39/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0136 - accuracy: 0.5519 - val_loss: 70.7729 - val_accuracy: 0.5412\n",
            "Epoch 40/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 1.0036 - accuracy: 0.5496 - val_loss: 0.9908 - val_accuracy: 0.5717\n",
            "Epoch 41/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 1.0013 - accuracy: 0.5560 - val_loss: 163.4275 - val_accuracy: 0.4479\n",
            "Epoch 42/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9874 - accuracy: 0.5646 - val_loss: 1.0122 - val_accuracy: 0.5596\n",
            "Epoch 43/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9842 - accuracy: 0.5763 - val_loss: 1.0815 - val_accuracy: 0.4967\n",
            "Epoch 44/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.9570 - accuracy: 0.5732 - val_loss: 0.9155 - val_accuracy: 0.5938\n",
            "Epoch 45/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.9553 - accuracy: 0.5939 - val_loss: 8.6112 - val_accuracy: 0.6108\n",
            "Epoch 46/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.9679 - accuracy: 0.5869 - val_loss: 1.0748 - val_accuracy: 0.4650\n",
            "Epoch 47/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.9485 - accuracy: 0.5895 - val_loss: 0.9198 - val_accuracy: 0.6217\n",
            "Epoch 48/300\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 0.9449 - accuracy: 0.5891 - val_loss: 0.9312 - val_accuracy: 0.6050\n",
            "Epoch 49/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.9519 - accuracy: 0.5860 - val_loss: 0.9221 - val_accuracy: 0.6117\n",
            "Epoch 50/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.9197 - accuracy: 0.6019 - val_loss: 0.9605 - val_accuracy: 0.5958\n",
            "Epoch 51/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.8956 - accuracy: 0.6223 - val_loss: 0.9260 - val_accuracy: 0.5904\n",
            "Epoch 52/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.8971 - accuracy: 0.6181 - val_loss: 1.0390 - val_accuracy: 0.5246\n",
            "Epoch 53/300\n",
            "100/100 [==============================] - 7s 75ms/step - loss: 0.8917 - accuracy: 0.6148 - val_loss: 0.8868 - val_accuracy: 0.6229\n",
            "Epoch 54/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.8959 - accuracy: 0.6177 - val_loss: 2739.0125 - val_accuracy: 0.6042\n",
            "Epoch 55/300\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.8841 - accuracy: 0.6119 - val_loss: 122.6970 - val_accuracy: 0.6458\n",
            "Epoch 56/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.8812 - accuracy: 0.6269 - val_loss: 0.9112 - val_accuracy: 0.6142\n",
            "Epoch 57/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.8912 - accuracy: 0.6217 - val_loss: 21.7297 - val_accuracy: 0.6150\n",
            "Epoch 58/300\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.8566 - accuracy: 0.6294 - val_loss: 0.9322 - val_accuracy: 0.5821\n",
            "Epoch 59/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8503 - accuracy: 0.6298 - val_loss: 261.0467 - val_accuracy: 0.6596\n",
            "Epoch 60/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.8348 - accuracy: 0.6431 - val_loss: 0.8954 - val_accuracy: 0.6162\n",
            "Epoch 61/300\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.8430 - accuracy: 0.6448 - val_loss: 1.3274 - val_accuracy: 0.6029\n",
            "Epoch 62/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8550 - accuracy: 0.6373 - val_loss: 1.5757 - val_accuracy: 0.6350\n",
            "Epoch 63/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.8476 - accuracy: 0.6436 - val_loss: 0.8107 - val_accuracy: 0.6792\n",
            "Epoch 64/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.8343 - accuracy: 0.6507 - val_loss: 0.7944 - val_accuracy: 0.6725\n",
            "Epoch 65/300\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 0.8110 - accuracy: 0.6553 - val_loss: 0.9006 - val_accuracy: 0.6208\n",
            "Epoch 66/300\n",
            "100/100 [==============================] - 8s 75ms/step - loss: 0.8076 - accuracy: 0.6606 - val_loss: 241.6117 - val_accuracy: 0.6242\n",
            "Epoch 67/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.7950 - accuracy: 0.6626 - val_loss: 0.7891 - val_accuracy: 0.6612\n",
            "Epoch 68/300\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.8168 - accuracy: 0.6536 - val_loss: 0.8519 - val_accuracy: 0.6633\n",
            "Epoch 69/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.8011 - accuracy: 0.6681 - val_loss: 0.9246 - val_accuracy: 0.6204\n",
            "Epoch 70/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.7983 - accuracy: 0.6629 - val_loss: 4.1299 - val_accuracy: 0.3446\n",
            "Epoch 71/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.7896 - accuracy: 0.6792 - val_loss: 0.8478 - val_accuracy: 0.6321\n",
            "Epoch 72/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.8140 - accuracy: 0.6590 - val_loss: 17317.1016 - val_accuracy: 0.6500\n",
            "Epoch 73/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7979 - accuracy: 0.6669 - val_loss: 28.5369 - val_accuracy: 0.6758\n",
            "Epoch 74/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7861 - accuracy: 0.6788 - val_loss: 2589.5325 - val_accuracy: 0.6704\n",
            "Epoch 75/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.7715 - accuracy: 0.6873 - val_loss: 0.8346 - val_accuracy: 0.6612\n",
            "Epoch 76/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.7625 - accuracy: 0.6806 - val_loss: 7319.2427 - val_accuracy: 0.6179\n",
            "Epoch 77/300\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.7745 - accuracy: 0.6796 - val_loss: 3684.1345 - val_accuracy: 0.6658\n",
            "Epoch 78/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.7431 - accuracy: 0.6904 - val_loss: 75.3128 - val_accuracy: 0.6879\n",
            "Epoch 79/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.7501 - accuracy: 0.6873 - val_loss: 0.7699 - val_accuracy: 0.6758\n",
            "Epoch 80/300\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.7567 - accuracy: 0.6867 - val_loss: 0.8717 - val_accuracy: 0.6187\n",
            "Epoch 81/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.7513 - accuracy: 0.6862 - val_loss: 937.6514 - val_accuracy: 0.6408\n",
            "Epoch 82/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7535 - accuracy: 0.6905 - val_loss: 758.3258 - val_accuracy: 0.6871\n",
            "Epoch 83/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7393 - accuracy: 0.7006 - val_loss: 0.8793 - val_accuracy: 0.6267\n",
            "Epoch 84/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7498 - accuracy: 0.6917 - val_loss: 0.8831 - val_accuracy: 0.6292\n",
            "Epoch 85/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.7262 - accuracy: 0.7002 - val_loss: 0.7988 - val_accuracy: 0.6787\n",
            "Epoch 86/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7299 - accuracy: 0.7027 - val_loss: 0.7583 - val_accuracy: 0.6825\n",
            "Epoch 87/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.7663 - accuracy: 0.6841 - val_loss: 0.8353 - val_accuracy: 0.6579\n",
            "Epoch 88/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.7610 - accuracy: 0.6893 - val_loss: 1.7860 - val_accuracy: 0.6600\n",
            "Epoch 89/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.7206 - accuracy: 0.7023 - val_loss: 9261.7656 - val_accuracy: 0.6846\n",
            "Epoch 90/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.7158 - accuracy: 0.6992 - val_loss: 0.7482 - val_accuracy: 0.6900\n",
            "Epoch 91/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.7433 - accuracy: 0.7033 - val_loss: 0.8887 - val_accuracy: 0.6233\n",
            "Epoch 92/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.7171 - accuracy: 0.7046 - val_loss: 0.7549 - val_accuracy: 0.7017\n",
            "Epoch 93/300\n",
            "100/100 [==============================] - 12s 115ms/step - loss: 0.7037 - accuracy: 0.7125 - val_loss: 799.7562 - val_accuracy: 0.6633\n",
            "Epoch 94/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6957 - accuracy: 0.7121 - val_loss: 0.9796 - val_accuracy: 0.5992\n",
            "Epoch 95/300\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.7170 - accuracy: 0.7044 - val_loss: 0.7735 - val_accuracy: 0.6733\n",
            "Epoch 96/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6997 - accuracy: 0.7081 - val_loss: 41.9996 - val_accuracy: 0.6862\n",
            "Epoch 97/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6942 - accuracy: 0.7204 - val_loss: 0.8506 - val_accuracy: 0.6854\n",
            "Epoch 98/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6869 - accuracy: 0.7210 - val_loss: 0.8229 - val_accuracy: 0.7113\n",
            "Epoch 99/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6963 - accuracy: 0.7192 - val_loss: 975.1570 - val_accuracy: 0.6450\n",
            "Epoch 100/300\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6890 - accuracy: 0.7260 - val_loss: 0.8287 - val_accuracy: 0.6517\n",
            "Epoch 101/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.6816 - accuracy: 0.7244 - val_loss: 22.5847 - val_accuracy: 0.6983\n",
            "Epoch 102/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6710 - accuracy: 0.7285 - val_loss: 0.7850 - val_accuracy: 0.6842\n",
            "Epoch 103/300\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.6604 - accuracy: 0.7385 - val_loss: 0.8186 - val_accuracy: 0.6650\n",
            "Epoch 104/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6635 - accuracy: 0.7275 - val_loss: 149.2762 - val_accuracy: 0.6950\n",
            "Epoch 105/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6497 - accuracy: 0.7437 - val_loss: 0.7759 - val_accuracy: 0.6958\n",
            "Epoch 106/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6657 - accuracy: 0.7319 - val_loss: 1174.7426 - val_accuracy: 0.6633\n",
            "Epoch 107/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6611 - accuracy: 0.7323 - val_loss: 4036.4038 - val_accuracy: 0.7063\n",
            "Epoch 108/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6708 - accuracy: 0.7254 - val_loss: 0.7767 - val_accuracy: 0.6975\n",
            "Epoch 109/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.6459 - accuracy: 0.7455 - val_loss: 0.8107 - val_accuracy: 0.7038\n",
            "Epoch 110/300\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.6357 - accuracy: 0.7469 - val_loss: 0.7502 - val_accuracy: 0.7083\n",
            "Epoch 111/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.6291 - accuracy: 0.7408 - val_loss: 26.2814 - val_accuracy: 0.6892\n",
            "Epoch 112/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6256 - accuracy: 0.7579 - val_loss: 0.7173 - val_accuracy: 0.7183\n",
            "Epoch 113/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.6374 - accuracy: 0.7419 - val_loss: 1.7450 - val_accuracy: 0.6821\n",
            "Epoch 114/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6279 - accuracy: 0.7508 - val_loss: 0.9755 - val_accuracy: 0.6771\n",
            "Epoch 115/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.6252 - accuracy: 0.7503 - val_loss: 0.7514 - val_accuracy: 0.6933\n",
            "Epoch 116/300\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.6208 - accuracy: 0.7485 - val_loss: 3.4016 - val_accuracy: 0.6879\n",
            "Epoch 117/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.6042 - accuracy: 0.7535 - val_loss: 0.7441 - val_accuracy: 0.6988\n",
            "Epoch 118/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.6026 - accuracy: 0.7529 - val_loss: 0.7661 - val_accuracy: 0.7008\n",
            "Epoch 119/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.6013 - accuracy: 0.7556 - val_loss: 0.9316 - val_accuracy: 0.6804\n",
            "Epoch 120/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.6171 - accuracy: 0.7503 - val_loss: 0.7299 - val_accuracy: 0.7192\n",
            "Epoch 121/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.5865 - accuracy: 0.7668 - val_loss: 0.7569 - val_accuracy: 0.6942\n",
            "Epoch 122/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5973 - accuracy: 0.7668 - val_loss: 0.8188 - val_accuracy: 0.6558\n",
            "Epoch 123/300\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5866 - accuracy: 0.7606 - val_loss: 0.7819 - val_accuracy: 0.6796\n",
            "Epoch 124/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.5925 - accuracy: 0.7608 - val_loss: 8089.8501 - val_accuracy: 0.6796\n",
            "Epoch 125/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5885 - accuracy: 0.7644 - val_loss: 1.6253 - val_accuracy: 0.7175\n",
            "Epoch 126/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.5756 - accuracy: 0.7741 - val_loss: 0.7371 - val_accuracy: 0.7133\n",
            "Epoch 127/300\n",
            "100/100 [==============================] - 11s 114ms/step - loss: 0.5737 - accuracy: 0.7700 - val_loss: 0.7792 - val_accuracy: 0.6992\n",
            "Epoch 128/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.5779 - accuracy: 0.7700 - val_loss: 0.7883 - val_accuracy: 0.6958\n",
            "Epoch 129/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.5719 - accuracy: 0.7679 - val_loss: 0.8058 - val_accuracy: 0.6913\n",
            "Epoch 130/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.5540 - accuracy: 0.7827 - val_loss: 1442.5220 - val_accuracy: 0.6963\n",
            "Epoch 131/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5636 - accuracy: 0.7807 - val_loss: 0.7567 - val_accuracy: 0.7008\n",
            "Epoch 132/300\n",
            "100/100 [==============================] - 11s 115ms/step - loss: 0.5543 - accuracy: 0.7837 - val_loss: 0.7103 - val_accuracy: 0.7179\n",
            "Epoch 133/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.5506 - accuracy: 0.7774 - val_loss: 0.7150 - val_accuracy: 0.7125\n",
            "Epoch 134/300\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.5565 - accuracy: 0.7812 - val_loss: 0.8113 - val_accuracy: 0.6938\n",
            "Epoch 135/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5679 - accuracy: 0.7716 - val_loss: 0.7487 - val_accuracy: 0.7042\n",
            "Epoch 136/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.5476 - accuracy: 0.7848 - val_loss: 1.1015 - val_accuracy: 0.6946\n",
            "Epoch 137/300\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5581 - accuracy: 0.7787 - val_loss: 0.8188 - val_accuracy: 0.7017\n",
            "Epoch 138/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.5398 - accuracy: 0.7829 - val_loss: 3.2194 - val_accuracy: 0.6754\n",
            "Epoch 139/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.5552 - accuracy: 0.7812 - val_loss: 0.8675 - val_accuracy: 0.6904\n",
            "Epoch 140/300\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.5254 - accuracy: 0.7922 - val_loss: 0.7798 - val_accuracy: 0.7038\n",
            "Epoch 141/300\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.5036 - accuracy: 0.8008 - val_loss: 0.7955 - val_accuracy: 0.7096\n",
            "Epoch 142/300\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.5163 - accuracy: 0.7956 - val_loss: 0.7961 - val_accuracy: 0.6979\n",
            "Epoch 143/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.5029 - accuracy: 0.8096 - val_loss: 0.9486 - val_accuracy: 0.6883\n",
            "Epoch 144/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4987 - accuracy: 0.8056 - val_loss: 6565.3823 - val_accuracy: 0.7083\n",
            "Epoch 145/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.5034 - accuracy: 0.8079 - val_loss: 925.4606 - val_accuracy: 0.6942\n",
            "Epoch 146/300\n",
            "100/100 [==============================] - 11s 113ms/step - loss: 0.4902 - accuracy: 0.8071 - val_loss: 0.7601 - val_accuracy: 0.7079\n",
            "Epoch 147/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.4964 - accuracy: 0.8018 - val_loss: 0.8938 - val_accuracy: 0.7179\n",
            "Epoch 148/300\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.5102 - accuracy: 0.8006 - val_loss: 1283.6466 - val_accuracy: 0.7033\n",
            "Epoch 149/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4834 - accuracy: 0.8087 - val_loss: 6863.1646 - val_accuracy: 0.7158\n",
            "Epoch 150/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4960 - accuracy: 0.8077 - val_loss: 0.8497 - val_accuracy: 0.6963\n",
            "Epoch 151/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4684 - accuracy: 0.8131 - val_loss: 0.8299 - val_accuracy: 0.6958\n",
            "Epoch 152/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4965 - accuracy: 0.8023 - val_loss: 0.8083 - val_accuracy: 0.6983\n",
            "Epoch 153/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4699 - accuracy: 0.8152 - val_loss: 0.7927 - val_accuracy: 0.6979\n",
            "Epoch 154/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4707 - accuracy: 0.8163 - val_loss: 0.8278 - val_accuracy: 0.6983\n",
            "Epoch 155/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4608 - accuracy: 0.8238 - val_loss: 15.1193 - val_accuracy: 0.7050\n",
            "Epoch 156/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4767 - accuracy: 0.8123 - val_loss: 94.9580 - val_accuracy: 0.7142\n",
            "Epoch 157/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.4715 - accuracy: 0.8144 - val_loss: 0.8200 - val_accuracy: 0.7158\n",
            "Epoch 158/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4390 - accuracy: 0.8327 - val_loss: 0.7904 - val_accuracy: 0.7171\n",
            "Epoch 159/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4511 - accuracy: 0.8238 - val_loss: 0.8067 - val_accuracy: 0.7308\n",
            "Epoch 160/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4273 - accuracy: 0.8352 - val_loss: 0.9849 - val_accuracy: 0.7200\n",
            "Epoch 161/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.4401 - accuracy: 0.8358 - val_loss: 0.8873 - val_accuracy: 0.7063\n",
            "Epoch 162/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.4315 - accuracy: 0.8267 - val_loss: 6907.8936 - val_accuracy: 0.6862\n",
            "Epoch 163/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.4377 - accuracy: 0.8352 - val_loss: 0.8022 - val_accuracy: 0.6979\n",
            "Epoch 164/300\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.4452 - accuracy: 0.8256 - val_loss: 0.8477 - val_accuracy: 0.7058\n",
            "Epoch 165/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.4390 - accuracy: 0.8310 - val_loss: 1.3366 - val_accuracy: 0.7029\n",
            "Epoch 166/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.4286 - accuracy: 0.8417 - val_loss: 0.8755 - val_accuracy: 0.7150\n",
            "Epoch 167/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4266 - accuracy: 0.8390 - val_loss: 0.7620 - val_accuracy: 0.7225\n",
            "Epoch 168/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.4172 - accuracy: 0.8410 - val_loss: 0.9837 - val_accuracy: 0.7033\n",
            "Epoch 169/300\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.4206 - accuracy: 0.8396 - val_loss: 0.7877 - val_accuracy: 0.7204\n",
            "Epoch 170/300\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.4136 - accuracy: 0.8438 - val_loss: 39892.5312 - val_accuracy: 0.7108\n",
            "Epoch 171/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.4133 - accuracy: 0.8454 - val_loss: 0.7365 - val_accuracy: 0.7342\n",
            "Epoch 172/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.4167 - accuracy: 0.8408 - val_loss: 1922.4805 - val_accuracy: 0.6921\n",
            "Epoch 173/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.4090 - accuracy: 0.8456 - val_loss: 0.8026 - val_accuracy: 0.7129\n",
            "Epoch 174/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3892 - accuracy: 0.8520 - val_loss: 0.9478 - val_accuracy: 0.7142\n",
            "Epoch 175/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.3987 - accuracy: 0.8521 - val_loss: 0.9577 - val_accuracy: 0.6833\n",
            "Epoch 176/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3948 - accuracy: 0.8525 - val_loss: 0.8576 - val_accuracy: 0.6967\n",
            "Epoch 177/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.3918 - accuracy: 0.8459 - val_loss: 1.0527 - val_accuracy: 0.7192\n",
            "Epoch 178/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.3934 - accuracy: 0.8454 - val_loss: 0.9423 - val_accuracy: 0.6954\n",
            "Epoch 179/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.3848 - accuracy: 0.8522 - val_loss: 5.8975 - val_accuracy: 0.6988\n",
            "Epoch 180/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.3662 - accuracy: 0.8644 - val_loss: 1.0746 - val_accuracy: 0.7196\n",
            "Epoch 181/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3740 - accuracy: 0.8600 - val_loss: 1.5151 - val_accuracy: 0.6971\n",
            "Epoch 182/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3797 - accuracy: 0.8578 - val_loss: 0.9085 - val_accuracy: 0.6996\n",
            "Epoch 183/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.3885 - accuracy: 0.8506 - val_loss: 0.8618 - val_accuracy: 0.7050\n",
            "Epoch 184/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.3714 - accuracy: 0.8556 - val_loss: 0.8565 - val_accuracy: 0.7237\n",
            "Epoch 185/300\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.3626 - accuracy: 0.8603 - val_loss: 0.9015 - val_accuracy: 0.6913\n",
            "Epoch 186/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.3767 - accuracy: 0.8562 - val_loss: 16.4260 - val_accuracy: 0.7196\n",
            "Epoch 187/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3443 - accuracy: 0.8722 - val_loss: 0.8394 - val_accuracy: 0.7079\n",
            "Epoch 188/300\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 0.3617 - accuracy: 0.8595 - val_loss: 8.4825 - val_accuracy: 0.7083\n",
            "Epoch 189/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.3667 - accuracy: 0.8644 - val_loss: 1.1966 - val_accuracy: 0.7083\n",
            "Epoch 190/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.3432 - accuracy: 0.8731 - val_loss: 0.9686 - val_accuracy: 0.6942\n",
            "Epoch 191/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3571 - accuracy: 0.8648 - val_loss: 0.8463 - val_accuracy: 0.7175\n",
            "Epoch 192/300\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.3571 - accuracy: 0.8649 - val_loss: 1.0288 - val_accuracy: 0.7158\n",
            "Epoch 193/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3309 - accuracy: 0.8774 - val_loss: 1.2190 - val_accuracy: 0.7283\n",
            "Epoch 194/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.3451 - accuracy: 0.8697 - val_loss: 0.9289 - val_accuracy: 0.6938\n",
            "Epoch 195/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.3629 - accuracy: 0.8648 - val_loss: 0.8897 - val_accuracy: 0.7033\n",
            "Epoch 196/300\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.3386 - accuracy: 0.8705 - val_loss: 0.9217 - val_accuracy: 0.7038\n",
            "Epoch 197/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3221 - accuracy: 0.8808 - val_loss: 0.9117 - val_accuracy: 0.7229\n",
            "Epoch 198/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3232 - accuracy: 0.8810 - val_loss: 1.0121 - val_accuracy: 0.7204\n",
            "Epoch 199/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.3180 - accuracy: 0.8806 - val_loss: 0.8731 - val_accuracy: 0.7154\n",
            "Epoch 200/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3197 - accuracy: 0.8797 - val_loss: 53938.9922 - val_accuracy: 0.7167\n",
            "Epoch 201/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3213 - accuracy: 0.8825 - val_loss: 0.8610 - val_accuracy: 0.7192\n",
            "Epoch 202/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.3134 - accuracy: 0.8821 - val_loss: 0.8671 - val_accuracy: 0.7025\n",
            "Epoch 203/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.3102 - accuracy: 0.8821 - val_loss: 0.9756 - val_accuracy: 0.7183\n",
            "Epoch 204/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3155 - accuracy: 0.8817 - val_loss: 0.9153 - val_accuracy: 0.7038\n",
            "Epoch 205/300\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.3123 - accuracy: 0.8777 - val_loss: 0.9393 - val_accuracy: 0.7075\n",
            "Epoch 206/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.3147 - accuracy: 0.8781 - val_loss: 0.9770 - val_accuracy: 0.7079\n",
            "Epoch 207/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.3164 - accuracy: 0.8814 - val_loss: 1.0329 - val_accuracy: 0.7000\n",
            "Epoch 208/300\n",
            "100/100 [==============================] - 12s 120ms/step - loss: 0.3002 - accuracy: 0.8865 - val_loss: 1.0320 - val_accuracy: 0.7013\n",
            "Epoch 209/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2836 - accuracy: 0.8950 - val_loss: 0.9025 - val_accuracy: 0.7092\n",
            "Epoch 210/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.3111 - accuracy: 0.8813 - val_loss: 0.9194 - val_accuracy: 0.7088\n",
            "Epoch 211/300\n",
            "100/100 [==============================] - 11s 111ms/step - loss: 0.2755 - accuracy: 0.8979 - val_loss: 0.9356 - val_accuracy: 0.7171\n",
            "Epoch 212/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3024 - accuracy: 0.8860 - val_loss: 5.4126 - val_accuracy: 0.7138\n",
            "Epoch 213/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2770 - accuracy: 0.8962 - val_loss: 1.3975 - val_accuracy: 0.7192\n",
            "Epoch 214/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.3002 - accuracy: 0.8848 - val_loss: 0.9272 - val_accuracy: 0.6979\n",
            "Epoch 215/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.2764 - accuracy: 0.8998 - val_loss: 1.3878 - val_accuracy: 0.7237\n",
            "Epoch 216/300\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 0.3121 - accuracy: 0.8790 - val_loss: 0.8918 - val_accuracy: 0.6942\n",
            "Epoch 217/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2948 - accuracy: 0.8914 - val_loss: 0.8146 - val_accuracy: 0.7358\n",
            "Epoch 218/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2881 - accuracy: 0.8912 - val_loss: 0.9940 - val_accuracy: 0.6942\n",
            "Epoch 219/300\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2802 - accuracy: 0.8956 - val_loss: 1.0558 - val_accuracy: 0.7058\n",
            "Epoch 220/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2907 - accuracy: 0.8885 - val_loss: 0.9584 - val_accuracy: 0.7183\n",
            "Epoch 221/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.2861 - accuracy: 0.8925 - val_loss: 19.2979 - val_accuracy: 0.7142\n",
            "Epoch 222/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2781 - accuracy: 0.8912 - val_loss: 0.9889 - val_accuracy: 0.6817\n",
            "Epoch 223/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.2668 - accuracy: 0.9062 - val_loss: 0.9974 - val_accuracy: 0.7108\n",
            "Epoch 224/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.2774 - accuracy: 0.8987 - val_loss: 1.0120 - val_accuracy: 0.7079\n",
            "Epoch 225/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.2711 - accuracy: 0.8994 - val_loss: 22.4315 - val_accuracy: 0.7217\n",
            "Epoch 226/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.2555 - accuracy: 0.9073 - val_loss: 0.9851 - val_accuracy: 0.6975\n",
            "Epoch 227/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.2664 - accuracy: 0.9010 - val_loss: 0.8890 - val_accuracy: 0.7217\n",
            "Epoch 228/300\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 0.2539 - accuracy: 0.9052 - val_loss: 0.8917 - val_accuracy: 0.7400\n",
            "Epoch 229/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2567 - accuracy: 0.9058 - val_loss: 0.8789 - val_accuracy: 0.7204\n",
            "Epoch 230/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2709 - accuracy: 0.8981 - val_loss: 0.9854 - val_accuracy: 0.7058\n",
            "Epoch 231/300\n",
            "100/100 [==============================] - 9s 87ms/step - loss: 0.2699 - accuracy: 0.8965 - val_loss: 1.0982 - val_accuracy: 0.6900\n",
            "Epoch 232/300\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2585 - accuracy: 0.9056 - val_loss: 13071.5391 - val_accuracy: 0.7200\n",
            "Epoch 233/300\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.2590 - accuracy: 0.9046 - val_loss: 0.9296 - val_accuracy: 0.7125\n",
            "Epoch 234/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2373 - accuracy: 0.9096 - val_loss: 51437.7383 - val_accuracy: 0.6971\n",
            "Epoch 235/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.2576 - accuracy: 0.9015 - val_loss: 82738.6484 - val_accuracy: 0.7029\n",
            "Epoch 236/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.2465 - accuracy: 0.9069 - val_loss: 1.0703 - val_accuracy: 0.6958\n",
            "Epoch 237/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2440 - accuracy: 0.9117 - val_loss: 1.0473 - val_accuracy: 0.7212\n",
            "Epoch 238/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.2469 - accuracy: 0.9069 - val_loss: 0.9673 - val_accuracy: 0.7092\n",
            "Epoch 239/300\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.2547 - accuracy: 0.9060 - val_loss: 0.9751 - val_accuracy: 0.7283\n",
            "Epoch 240/300\n",
            "100/100 [==============================] - 8s 80ms/step - loss: 0.2487 - accuracy: 0.9027 - val_loss: 1.0037 - val_accuracy: 0.7008\n",
            "Epoch 241/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.2689 - accuracy: 0.8992 - val_loss: 1.0173 - val_accuracy: 0.7067\n",
            "Epoch 242/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2460 - accuracy: 0.9060 - val_loss: 0.9731 - val_accuracy: 0.7258\n",
            "Epoch 243/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.2465 - accuracy: 0.9094 - val_loss: 0.8891 - val_accuracy: 0.7192\n",
            "Epoch 244/300\n",
            "100/100 [==============================] - 9s 89ms/step - loss: 0.2347 - accuracy: 0.9148 - val_loss: 1.3248 - val_accuracy: 0.7167\n",
            "Epoch 245/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.2555 - accuracy: 0.9027 - val_loss: 0.9136 - val_accuracy: 0.7171\n",
            "Epoch 246/300\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.2380 - accuracy: 0.9127 - val_loss: 1.1436 - val_accuracy: 0.7004\n",
            "Epoch 247/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.2333 - accuracy: 0.9150 - val_loss: 1.0459 - val_accuracy: 0.7121\n",
            "Epoch 248/300\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 0.2321 - accuracy: 0.9154 - val_loss: 0.9912 - val_accuracy: 0.7100\n",
            "Epoch 249/300\n",
            "100/100 [==============================] - 9s 86ms/step - loss: 0.2463 - accuracy: 0.9110 - val_loss: 1.1503 - val_accuracy: 0.7113\n",
            "Epoch 250/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.2166 - accuracy: 0.9158 - val_loss: 1.0045 - val_accuracy: 0.6996\n",
            "Epoch 251/300\n",
            "100/100 [==============================] - 8s 76ms/step - loss: 0.2293 - accuracy: 0.9133 - val_loss: 1.2080 - val_accuracy: 0.7158\n",
            "Epoch 252/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.2314 - accuracy: 0.9133 - val_loss: 0.9886 - val_accuracy: 0.7183\n",
            "Epoch 253/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.2216 - accuracy: 0.9150 - val_loss: 2.1860 - val_accuracy: 0.7225\n",
            "Epoch 254/300\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2146 - accuracy: 0.9179 - val_loss: 1.7411 - val_accuracy: 0.7158\n",
            "Epoch 255/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.2230 - accuracy: 0.9161 - val_loss: 1.0750 - val_accuracy: 0.7225\n",
            "Epoch 256/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.2203 - accuracy: 0.9200 - val_loss: 5.4210 - val_accuracy: 0.7204\n",
            "Epoch 257/300\n",
            "100/100 [==============================] - 10s 98ms/step - loss: 0.2442 - accuracy: 0.9133 - val_loss: 1.0523 - val_accuracy: 0.7138\n",
            "Epoch 258/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.2272 - accuracy: 0.9183 - val_loss: 1.0464 - val_accuracy: 0.6950\n",
            "Epoch 259/300\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 0.2331 - accuracy: 0.9152 - val_loss: 1.0427 - val_accuracy: 0.7108\n",
            "Epoch 260/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.2099 - accuracy: 0.9194 - val_loss: 1.9341 - val_accuracy: 0.7013\n",
            "Epoch 261/300\n",
            "100/100 [==============================] - 11s 110ms/step - loss: 0.2213 - accuracy: 0.9156 - val_loss: 281.9527 - val_accuracy: 0.7125\n",
            "Epoch 262/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2174 - accuracy: 0.9156 - val_loss: 1.0228 - val_accuracy: 0.7196\n",
            "Epoch 263/300\n",
            "100/100 [==============================] - 9s 94ms/step - loss: 0.2139 - accuracy: 0.9225 - val_loss: 0.9083 - val_accuracy: 0.7237\n",
            "Epoch 264/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.2253 - accuracy: 0.9210 - val_loss: 1.0614 - val_accuracy: 0.7163\n",
            "Epoch 265/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2134 - accuracy: 0.9215 - val_loss: 0.9762 - val_accuracy: 0.7250\n",
            "Epoch 266/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.2019 - accuracy: 0.9240 - val_loss: 1.1052 - val_accuracy: 0.7246\n",
            "Epoch 267/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.2152 - accuracy: 0.9142 - val_loss: 1.0336 - val_accuracy: 0.6913\n",
            "Epoch 268/300\n",
            "100/100 [==============================] - 11s 108ms/step - loss: 0.2077 - accuracy: 0.9229 - val_loss: 1.0802 - val_accuracy: 0.7017\n",
            "Epoch 269/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.2045 - accuracy: 0.9246 - val_loss: 49958.4648 - val_accuracy: 0.6913\n",
            "Epoch 270/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.2200 - accuracy: 0.9161 - val_loss: 494.3228 - val_accuracy: 0.7025\n",
            "Epoch 271/300\n",
            "100/100 [==============================] - 8s 85ms/step - loss: 0.2176 - accuracy: 0.9206 - val_loss: 85001.8750 - val_accuracy: 0.7079\n",
            "Epoch 272/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2091 - accuracy: 0.9215 - val_loss: 12209.2188 - val_accuracy: 0.7067\n",
            "Epoch 273/300\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 0.2014 - accuracy: 0.9296 - val_loss: 135398.6406 - val_accuracy: 0.7108\n",
            "Epoch 274/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.2065 - accuracy: 0.9225 - val_loss: 1.1018 - val_accuracy: 0.6938\n",
            "Epoch 275/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1965 - accuracy: 0.9237 - val_loss: 1.1603 - val_accuracy: 0.6958\n",
            "Epoch 276/300\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 0.1971 - accuracy: 0.9265 - val_loss: 1.1160 - val_accuracy: 0.7033\n",
            "Epoch 277/300\n",
            "100/100 [==============================] - 8s 81ms/step - loss: 0.1974 - accuracy: 0.9262 - val_loss: 1.1355 - val_accuracy: 0.7075\n",
            "Epoch 278/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.2110 - accuracy: 0.9242 - val_loss: 1.0495 - val_accuracy: 0.7133\n",
            "Epoch 279/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.2176 - accuracy: 0.9212 - val_loss: 0.9976 - val_accuracy: 0.7217\n",
            "Epoch 280/300\n",
            "100/100 [==============================] - 9s 85ms/step - loss: 0.1860 - accuracy: 0.9308 - val_loss: 0.9930 - val_accuracy: 0.7179\n",
            "Epoch 281/300\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 0.1957 - accuracy: 0.9296 - val_loss: 1.0510 - val_accuracy: 0.7079\n",
            "Epoch 282/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1829 - accuracy: 0.9292 - val_loss: 1.0514 - val_accuracy: 0.7017\n",
            "Epoch 283/300\n",
            "100/100 [==============================] - 8s 82ms/step - loss: 0.1994 - accuracy: 0.9252 - val_loss: 0.9760 - val_accuracy: 0.7125\n",
            "Epoch 284/300\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.1913 - accuracy: 0.9281 - val_loss: 1.7703 - val_accuracy: 0.7079\n",
            "Epoch 285/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1937 - accuracy: 0.9248 - val_loss: 4.8849 - val_accuracy: 0.6963\n",
            "Epoch 286/300\n",
            "100/100 [==============================] - 8s 77ms/step - loss: 0.1776 - accuracy: 0.9371 - val_loss: 1.0325 - val_accuracy: 0.7250\n",
            "Epoch 287/300\n",
            "100/100 [==============================] - 10s 97ms/step - loss: 0.1983 - accuracy: 0.9244 - val_loss: 1.0866 - val_accuracy: 0.7163\n",
            "Epoch 288/300\n",
            "100/100 [==============================] - 11s 112ms/step - loss: 0.2030 - accuracy: 0.9260 - val_loss: 1.2054 - val_accuracy: 0.7021\n",
            "Epoch 289/300\n",
            "100/100 [==============================] - 12s 121ms/step - loss: 0.1972 - accuracy: 0.9258 - val_loss: 1.0865 - val_accuracy: 0.7163\n",
            "Epoch 290/300\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 0.1939 - accuracy: 0.9315 - val_loss: 0.9906 - val_accuracy: 0.7104\n",
            "Epoch 291/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.1789 - accuracy: 0.9354 - val_loss: 0.9653 - val_accuracy: 0.7075\n",
            "Epoch 292/300\n",
            "100/100 [==============================] - 8s 79ms/step - loss: 0.1913 - accuracy: 0.9271 - val_loss: 1.1744 - val_accuracy: 0.7125\n",
            "Epoch 293/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1843 - accuracy: 0.9315 - val_loss: 1.1320 - val_accuracy: 0.7117\n",
            "Epoch 294/300\n",
            "100/100 [==============================] - 12s 117ms/step - loss: 0.2046 - accuracy: 0.9267 - val_loss: 1.0976 - val_accuracy: 0.7067\n",
            "Epoch 295/300\n",
            "100/100 [==============================] - 8s 83ms/step - loss: 0.1887 - accuracy: 0.9296 - val_loss: 1.0847 - val_accuracy: 0.7133\n",
            "Epoch 296/300\n",
            "100/100 [==============================] - 8s 78ms/step - loss: 0.1852 - accuracy: 0.9315 - val_loss: 1.1160 - val_accuracy: 0.7079\n",
            "Epoch 297/300\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 0.1735 - accuracy: 0.9356 - val_loss: 1.0671 - val_accuracy: 0.7096\n",
            "Epoch 298/300\n",
            "100/100 [==============================] - 11s 109ms/step - loss: 0.1816 - accuracy: 0.9338 - val_loss: 1.4703 - val_accuracy: 0.7117\n",
            "Epoch 299/300\n",
            "100/100 [==============================] - 8s 84ms/step - loss: 0.1702 - accuracy: 0.9342 - val_loss: 7.4265 - val_accuracy: 0.7179\n",
            "Epoch 300/300\n",
            "100/100 [==============================] - 9s 90ms/step - loss: 0.1822 - accuracy: 0.9325 - val_loss: 3.2296 - val_accuracy: 0.7262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "outputId": "8cf98601-12de-47c9-cc07-fd759d4c3a08",
        "id": "Y-k7NffXVmeX"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Writing code to evaluate the model performance on the test set\n",
        "\n",
        "# Plotting the accuracies\n",
        "\n",
        "dict_hist = history_model3.history\n",
        "\n",
        "list_ep = [i for i in range(1, 301)]\n",
        "\n",
        "plt.figure(figsize = (8, 8))\n",
        "\n",
        "plt.plot(list_ep, dict_hist['accuracy'], ls = '--', label = 'accuracy')\n",
        "\n",
        "plt.plot(list_ep, dict_hist['val_accuracy'], ls = '--', label = 'val_accuracy')\n",
        "\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix and generate a classification report for the model\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "test_set = datagen_test.flow_from_directory(folder_path + \"test\",\n",
        "                                                              target_size = (img_size,img_size),\n",
        "                                                              color_mode = 'grayscale',\n",
        "                                                              batch_size = 128,\n",
        "                                                              class_mode = 'categorical',\n",
        "                                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n",
        "                                                              shuffle = True)\n",
        "test_images, test_labels = next(test_set)\n",
        "\n",
        "# Write the name of the chosen model to predict\n",
        "pred = model3.predict(test_images)\n",
        "pred = np.argmax(pred, axis = 1)\n",
        "y_true = np.argmax(test_labels, axis = 1)\n",
        "\n",
        "# Printing the classification report\n",
        "#_____________\n",
        "print(classification_report(y_true, pred))\n",
        "\n",
        "\n",
        "# Plotting the heatmap using confusion matrix\n",
        "cm = confusion_matrix(y_true, pred)\n",
        "plt.figure(figsize = (8, 5))\n",
        "sns.heatmap(cm, annot = True,  fmt = '.0f', xticklabels = ['happy', 'sad', 'neutral', 'surprise'], yticklabels = ['happy', 'sad', 'neutral', 'surprise'])\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 691
        },
        "id": "XKg_LzvhV1c4",
        "outputId": "df54880b-b41f-4035-b450-ee4e8712e70f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 128 images belonging to 4 classes.\n",
            "4/4 [==============================] - 1s 14ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.78      0.85        32\n",
            "           1       0.57      0.62      0.60        32\n",
            "           2       0.56      0.62      0.59        32\n",
            "           3       0.97      0.91      0.94        32\n",
            "\n",
            "    accuracy                           0.73       128\n",
            "   macro avg       0.75      0.73      0.74       128\n",
            "weighted avg       0.75      0.73      0.74       128\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s_baiF_KllW"
      },
      "source": [
        "## **Conclusion and Insight:**\n",
        "**After training and testing different models and implementing some others the best performance one was the improved model3 with the specific learning rate selected 0.000110599529645911 obtained using Bayessian Optimization and this will be used for the solution proposed. It can show the improving in the metrics getting an accuracy of up to 0.95 and in the confussion matrix that the classification improve. It was proposed at the beggining to use transfer learning and possible aggregate models but the VGG and resnet did not perform as good as the model3, they were under 0.55 accuracy, so they won't be chosen to aggregate to the model3 as it will decrease the overall performance. Therefore only model3 was selected. Maybe a potential issue of the not so good performance of VGG and resnet (eventhought that this time converged) is the dataset that is small and no requires a higher complexity model and besides of the resolution of the images and some images that should not belong to the groups. The model3 performance could be improved using more images and adding them to the dataset and retrain to try to improve its performance. Other point to improve could be the quality of the images and to have computing power to keep training the model to test and improves the performance. It can see in the metrics the big improvement the model3 has now. And with the neutral and sad is the bigger misclassification that need to be reduced in future training of the model. the f-1 score greatly improved. This model3 will be the one selected for the final solution proposed for our task of Facial Emotion Recognition.**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "gpuClass": "premium",
      "collapsed_sections": [
        "J7NKTPgdEsgt"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}